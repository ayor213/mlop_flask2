2022-10-14 16:57:02,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-14 16:57:02,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-14 16:57:02,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-14 16:57:02,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-14 16:57:04,304:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-14 16:58:48,165:INFO:PyCaret RegressionExperiment
2022-10-14 16:58:48,167:INFO:Logging name: reg-default-name
2022-10-14 16:58:48,167:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-14 16:58:48,167:INFO:version 3.0.0.rc4
2022-10-14 16:58:48,167:INFO:Initializing setup()
2022-10-14 16:58:48,167:INFO:self.USI: 10ac
2022-10-14 16:58:48,167:INFO:self.variable_keys: {'idx', 'exp_id', 'exp_name_log', 'data', 'y_test', 'logging_param', 'pipeline', '_all_models', 'target_param', '_all_models_internal', 'y', '_all_metrics', 'fold_shuffle_param', 'html_param', 'variable_keys', 'transform_target_param', 'master_model_container', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'X_test', 'fold_groups_param', 'log_plots_param', 'display_container', 'seed', 'X_train', '_available_plots', '_gpu_n_jobs_param', 'memory', 'y_train', 'fold_generator', 'transform_target_method_param', 'X', 'USI'}
2022-10-14 16:58:48,167:INFO:Checking environment
2022-10-14 16:58:48,167:INFO:python_version: 3.9.7
2022-10-14 16:58:48,167:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-14 16:58:48,167:INFO:machine: x86_64
2022-10-14 16:58:48,168:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-14 16:58:48,168:INFO:Memory: svmem(total=8589934592, available=2638471168, percent=69.3, used=4803727360, free=43106304, active=2597199872, inactive=2594213888, wired=2206527488)
2022-10-14 16:58:48,168:INFO:Physical Core: 2
2022-10-14 16:58:48,168:INFO:Logical Core: 4
2022-10-14 16:58:48,168:INFO:Checking libraries
2022-10-14 16:58:48,168:INFO:System:
2022-10-14 16:58:48,168:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-14 16:58:48,168:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-14 16:58:48,168:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-14 16:58:48,168:INFO:PyCaret required dependencies:
2022-10-14 16:58:48,168:INFO:                 pip: 21.2.4
2022-10-14 16:58:48,168:INFO:          setuptools: 58.0.4
2022-10-14 16:58:48,169:INFO:             pycaret: 3.0.0rc4
2022-10-14 16:58:48,169:INFO:             IPython: 7.29.0
2022-10-14 16:58:48,169:INFO:          ipywidgets: 7.6.5
2022-10-14 16:58:48,169:INFO:                tqdm: 4.62.3
2022-10-14 16:58:48,169:INFO:               numpy: 1.22.4
2022-10-14 16:58:48,169:INFO:              pandas: 1.4.4
2022-10-14 16:58:48,169:INFO:              jinja2: 3.1.2
2022-10-14 16:58:48,169:INFO:               scipy: 1.8.1
2022-10-14 16:58:48,169:INFO:              joblib: 1.1.0
2022-10-14 16:58:48,169:INFO:             sklearn: 1.0.2
2022-10-14 16:58:48,169:INFO:                pyod: 1.0.5
2022-10-14 16:58:48,169:INFO:            imblearn: 0.9.0
2022-10-14 16:58:48,169:INFO:   category_encoders: 2.5.1.post0
2022-10-14 16:58:48,170:INFO:            lightgbm: 3.3.2
2022-10-14 16:58:48,170:INFO:               numba: 0.55.2
2022-10-14 16:58:48,170:INFO:            requests: 2.28.1
2022-10-14 16:58:48,171:INFO:          matplotlib: 3.4.3
2022-10-14 16:58:48,172:INFO:          scikitplot: 0.3.7
2022-10-14 16:58:48,173:INFO:         yellowbrick: 1.4
2022-10-14 16:58:48,173:INFO:              plotly: 5.5.0
2022-10-14 16:58:48,174:INFO:             kaleido: 0.2.1
2022-10-14 16:58:48,174:INFO:         statsmodels: 0.13.2
2022-10-14 16:58:48,174:INFO:              sktime: 0.13.4
2022-10-14 16:58:48,174:INFO:               tbats: 1.1.1
2022-10-14 16:58:48,174:INFO:            pmdarima: 1.8.5
2022-10-14 16:58:48,174:INFO:              psutil: 5.9.2
2022-10-14 16:58:48,174:INFO:PyCaret optional dependencies:
2022-10-14 16:58:48,188:INFO:                shap: 0.41.0
2022-10-14 16:58:48,188:INFO:           interpret: Not installed
2022-10-14 16:58:48,188:INFO:                umap: Not installed
2022-10-14 16:58:48,189:INFO:    pandas_profiling: Not installed
2022-10-14 16:58:48,189:INFO:  explainerdashboard: Not installed
2022-10-14 16:58:48,189:INFO:             autoviz: Not installed
2022-10-14 16:58:48,189:INFO:           fairlearn: Not installed
2022-10-14 16:58:48,189:INFO:             xgboost: Not installed
2022-10-14 16:58:48,189:INFO:            catboost: 1.1
2022-10-14 16:58:48,189:INFO:              kmodes: Not installed
2022-10-14 16:58:48,189:INFO:             mlxtend: Not installed
2022-10-14 16:58:48,189:INFO:       statsforecast: 1.1.1
2022-10-14 16:58:48,189:INFO:        tune_sklearn: Not installed
2022-10-14 16:58:48,189:INFO:                 ray: Not installed
2022-10-14 16:58:48,189:INFO:            hyperopt: Not installed
2022-10-14 16:58:48,189:INFO:              optuna: Not installed
2022-10-14 16:58:48,189:INFO:               skopt: Not installed
2022-10-14 16:58:48,189:INFO:              mlflow: 1.29.0
2022-10-14 16:58:48,189:INFO:              gradio: Not installed
2022-10-14 16:58:48,190:INFO:             fastapi: Not installed
2022-10-14 16:58:48,190:INFO:             uvicorn: Not installed
2022-10-14 16:58:48,190:INFO:              m2cgen: Not installed
2022-10-14 16:58:48,190:INFO:           evidently: Not installed
2022-10-14 16:58:48,190:INFO:                nltk: 3.6.5
2022-10-14 16:58:48,190:INFO:            pyLDAvis: Not installed
2022-10-14 16:58:48,190:INFO:              gensim: Not installed
2022-10-14 16:58:48,190:INFO:               spacy: Not installed
2022-10-14 16:58:48,190:INFO:           wordcloud: Not installed
2022-10-14 16:58:48,190:INFO:            textblob: Not installed
2022-10-14 16:58:48,190:INFO:               fugue: Not installed
2022-10-14 16:58:48,190:INFO:           streamlit: Not installed
2022-10-14 16:58:48,190:INFO:             prophet: 1.1.1
2022-10-14 16:58:48,190:INFO:None
2022-10-14 16:58:48,191:INFO:Set up data.
2022-10-14 16:58:48,205:INFO:Set up train/test split.
2022-10-14 16:58:48,218:INFO:Set up index.
2022-10-14 16:58:48,220:INFO:Set up folding strategy.
2022-10-14 16:58:48,220:INFO:Assigning column types.
2022-10-14 16:58:48,226:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-14 16:58:48,227:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-14 16:58:48,237:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-14 16:58:48,247:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-14 16:58:48,355:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-14 16:58:48,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-14 16:58:48,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-14 17:00:49,889:INFO:PyCaret RegressionExperiment
2022-10-14 17:00:49,889:INFO:Logging name: reg-default-name
2022-10-14 17:00:49,890:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-14 17:00:49,890:INFO:version 3.0.0.rc4
2022-10-14 17:00:49,890:INFO:Initializing setup()
2022-10-14 17:00:49,890:INFO:self.USI: 7c7f
2022-10-14 17:00:49,890:INFO:self.variable_keys: {'idx', 'exp_id', 'exp_name_log', 'data', 'y_test', 'logging_param', 'pipeline', '_all_models', 'target_param', '_all_models_internal', 'y', '_all_metrics', 'fold_shuffle_param', 'html_param', 'variable_keys', 'transform_target_param', 'master_model_container', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'X_test', 'fold_groups_param', 'log_plots_param', 'display_container', 'seed', 'X_train', '_available_plots', '_gpu_n_jobs_param', 'memory', 'y_train', 'fold_generator', 'transform_target_method_param', 'X', 'USI'}
2022-10-14 17:00:49,890:INFO:Checking environment
2022-10-14 17:00:49,890:INFO:python_version: 3.9.7
2022-10-14 17:00:49,891:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-14 17:00:49,891:INFO:machine: x86_64
2022-10-14 17:00:49,892:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:00:49,892:INFO:Memory: svmem(total=8589934592, available=2659471360, percent=69.0, used=4820893696, free=27742208, active=2634186752, inactive=2624282624, wired=2186706944)
2022-10-14 17:00:49,892:INFO:Physical Core: 2
2022-10-14 17:00:49,893:INFO:Logical Core: 4
2022-10-14 17:00:49,893:INFO:Checking libraries
2022-10-14 17:00:49,893:INFO:System:
2022-10-14 17:00:49,893:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-14 17:00:49,893:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-14 17:00:49,893:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:00:49,893:INFO:PyCaret required dependencies:
2022-10-14 17:00:49,893:INFO:                 pip: 21.2.4
2022-10-14 17:00:49,893:INFO:          setuptools: 58.0.4
2022-10-14 17:00:49,894:INFO:             pycaret: 3.0.0rc4
2022-10-14 17:00:49,894:INFO:             IPython: 7.29.0
2022-10-14 17:00:49,894:INFO:          ipywidgets: 7.6.5
2022-10-14 17:00:49,894:INFO:                tqdm: 4.62.3
2022-10-14 17:00:49,894:INFO:               numpy: 1.22.4
2022-10-14 17:00:49,894:INFO:              pandas: 1.4.4
2022-10-14 17:00:49,894:INFO:              jinja2: 3.1.2
2022-10-14 17:00:49,894:INFO:               scipy: 1.8.1
2022-10-14 17:00:49,894:INFO:              joblib: 1.1.0
2022-10-14 17:00:49,894:INFO:             sklearn: 1.0.2
2022-10-14 17:00:49,894:INFO:                pyod: 1.0.5
2022-10-14 17:00:49,894:INFO:            imblearn: 0.9.0
2022-10-14 17:00:49,894:INFO:   category_encoders: 2.5.1.post0
2022-10-14 17:00:49,895:INFO:            lightgbm: 3.3.2
2022-10-14 17:00:49,895:INFO:               numba: 0.55.2
2022-10-14 17:00:49,895:INFO:            requests: 2.28.1
2022-10-14 17:00:49,895:INFO:          matplotlib: 3.4.3
2022-10-14 17:00:49,895:INFO:          scikitplot: 0.3.7
2022-10-14 17:00:49,895:INFO:         yellowbrick: 1.4
2022-10-14 17:00:49,895:INFO:              plotly: 5.5.0
2022-10-14 17:00:49,895:INFO:             kaleido: 0.2.1
2022-10-14 17:00:49,895:INFO:         statsmodels: 0.13.2
2022-10-14 17:00:49,895:INFO:              sktime: 0.13.4
2022-10-14 17:00:49,895:INFO:               tbats: 1.1.1
2022-10-14 17:00:49,895:INFO:            pmdarima: 1.8.5
2022-10-14 17:00:49,895:INFO:              psutil: 5.9.2
2022-10-14 17:00:49,896:INFO:PyCaret optional dependencies:
2022-10-14 17:00:49,896:INFO:                shap: 0.41.0
2022-10-14 17:00:49,896:INFO:           interpret: Not installed
2022-10-14 17:00:49,896:INFO:                umap: Not installed
2022-10-14 17:00:49,896:INFO:    pandas_profiling: Not installed
2022-10-14 17:00:49,896:INFO:  explainerdashboard: Not installed
2022-10-14 17:00:49,896:INFO:             autoviz: Not installed
2022-10-14 17:00:49,896:INFO:           fairlearn: Not installed
2022-10-14 17:00:49,896:INFO:             xgboost: Not installed
2022-10-14 17:00:49,897:INFO:            catboost: 1.1
2022-10-14 17:00:49,897:INFO:              kmodes: Not installed
2022-10-14 17:00:49,897:INFO:             mlxtend: Not installed
2022-10-14 17:00:49,897:INFO:       statsforecast: 1.1.1
2022-10-14 17:00:49,897:INFO:        tune_sklearn: Not installed
2022-10-14 17:00:49,897:INFO:                 ray: Not installed
2022-10-14 17:00:49,897:INFO:            hyperopt: Not installed
2022-10-14 17:00:49,897:INFO:              optuna: Not installed
2022-10-14 17:00:49,897:INFO:               skopt: Not installed
2022-10-14 17:00:49,897:INFO:              mlflow: 1.29.0
2022-10-14 17:00:49,897:INFO:              gradio: Not installed
2022-10-14 17:00:49,897:INFO:             fastapi: Not installed
2022-10-14 17:00:49,897:INFO:             uvicorn: Not installed
2022-10-14 17:00:49,897:INFO:              m2cgen: Not installed
2022-10-14 17:00:49,897:INFO:           evidently: Not installed
2022-10-14 17:00:49,897:INFO:                nltk: 3.6.5
2022-10-14 17:00:49,897:INFO:            pyLDAvis: Not installed
2022-10-14 17:00:49,897:INFO:              gensim: Not installed
2022-10-14 17:00:49,897:INFO:               spacy: Not installed
2022-10-14 17:00:49,897:INFO:           wordcloud: Not installed
2022-10-14 17:00:49,898:INFO:            textblob: Not installed
2022-10-14 17:00:49,898:INFO:               fugue: Not installed
2022-10-14 17:00:49,898:INFO:           streamlit: Not installed
2022-10-14 17:00:49,898:INFO:             prophet: 1.1.1
2022-10-14 17:00:49,898:INFO:None
2022-10-14 17:00:49,898:INFO:Set up data.
2022-10-14 17:00:49,913:INFO:Set up train/test split.
2022-10-14 17:00:49,921:INFO:Set up index.
2022-10-14 17:00:49,922:INFO:Set up folding strategy.
2022-10-14 17:00:49,922:INFO:Assigning column types.
2022-10-14 17:00:49,929:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-14 17:00:49,930:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-14 17:00:49,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-14 17:00:49,948:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-14 17:00:50,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-14 17:00:50,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-14 17:00:50,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-14 17:04:43,282:INFO:PyCaret RegressionExperiment
2022-10-14 17:04:43,287:INFO:Logging name: reg-default-name
2022-10-14 17:04:43,287:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-14 17:04:43,287:INFO:version 3.0.0.rc4
2022-10-14 17:04:43,287:INFO:Initializing setup()
2022-10-14 17:04:43,287:INFO:self.USI: b712
2022-10-14 17:04:43,287:INFO:self.variable_keys: {'idx', 'exp_id', 'exp_name_log', 'data', 'y_test', 'logging_param', 'pipeline', '_all_models', 'target_param', '_all_models_internal', 'y', '_all_metrics', 'fold_shuffle_param', 'html_param', 'variable_keys', 'transform_target_param', 'master_model_container', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'X_test', 'fold_groups_param', 'log_plots_param', 'display_container', 'seed', 'X_train', '_available_plots', '_gpu_n_jobs_param', 'memory', 'y_train', 'fold_generator', 'transform_target_method_param', 'X', 'USI'}
2022-10-14 17:04:43,287:INFO:Checking environment
2022-10-14 17:04:43,288:INFO:python_version: 3.9.7
2022-10-14 17:04:43,288:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-14 17:04:43,288:INFO:machine: x86_64
2022-10-14 17:04:43,288:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:04:43,288:INFO:Memory: svmem(total=8589934592, available=2236502016, percent=74.0, used=4456341504, free=32059392, active=2207014912, inactive=2201419776, wired=2249326592)
2022-10-14 17:04:43,288:INFO:Physical Core: 2
2022-10-14 17:04:43,288:INFO:Logical Core: 4
2022-10-14 17:04:43,289:INFO:Checking libraries
2022-10-14 17:04:43,289:INFO:System:
2022-10-14 17:04:43,289:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-14 17:04:43,289:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-14 17:04:43,289:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:04:43,289:INFO:PyCaret required dependencies:
2022-10-14 17:04:43,289:INFO:                 pip: 21.2.4
2022-10-14 17:04:43,289:INFO:          setuptools: 58.0.4
2022-10-14 17:04:43,289:INFO:             pycaret: 3.0.0rc4
2022-10-14 17:04:43,289:INFO:             IPython: 7.29.0
2022-10-14 17:04:43,290:INFO:          ipywidgets: 7.6.5
2022-10-14 17:04:43,290:INFO:                tqdm: 4.62.3
2022-10-14 17:04:43,290:INFO:               numpy: 1.22.4
2022-10-14 17:04:43,290:INFO:              pandas: 1.4.4
2022-10-14 17:04:43,290:INFO:              jinja2: 3.1.2
2022-10-14 17:04:43,290:INFO:               scipy: 1.8.1
2022-10-14 17:04:43,290:INFO:              joblib: 1.1.0
2022-10-14 17:04:43,290:INFO:             sklearn: 1.0.2
2022-10-14 17:04:43,290:INFO:                pyod: 1.0.5
2022-10-14 17:04:43,290:INFO:            imblearn: 0.9.0
2022-10-14 17:04:43,290:INFO:   category_encoders: 2.5.1.post0
2022-10-14 17:04:43,290:INFO:            lightgbm: 3.3.2
2022-10-14 17:04:43,290:INFO:               numba: 0.55.2
2022-10-14 17:04:43,291:INFO:            requests: 2.28.1
2022-10-14 17:04:43,291:INFO:          matplotlib: 3.4.3
2022-10-14 17:04:43,291:INFO:          scikitplot: 0.3.7
2022-10-14 17:04:43,291:INFO:         yellowbrick: 1.4
2022-10-14 17:04:43,292:INFO:              plotly: 5.5.0
2022-10-14 17:04:43,292:INFO:             kaleido: 0.2.1
2022-10-14 17:04:43,292:INFO:         statsmodels: 0.13.2
2022-10-14 17:04:43,292:INFO:              sktime: 0.13.4
2022-10-14 17:04:43,292:INFO:               tbats: 1.1.1
2022-10-14 17:04:43,294:INFO:            pmdarima: 1.8.5
2022-10-14 17:04:43,294:INFO:              psutil: 5.9.2
2022-10-14 17:04:43,294:INFO:PyCaret optional dependencies:
2022-10-14 17:04:43,296:INFO:                shap: 0.41.0
2022-10-14 17:04:43,297:INFO:           interpret: Not installed
2022-10-14 17:04:43,297:INFO:                umap: Not installed
2022-10-14 17:04:43,297:INFO:    pandas_profiling: Not installed
2022-10-14 17:04:43,297:INFO:  explainerdashboard: Not installed
2022-10-14 17:04:43,297:INFO:             autoviz: Not installed
2022-10-14 17:04:43,297:INFO:           fairlearn: Not installed
2022-10-14 17:04:43,297:INFO:             xgboost: Not installed
2022-10-14 17:04:43,297:INFO:            catboost: 1.1
2022-10-14 17:04:43,297:INFO:              kmodes: Not installed
2022-10-14 17:04:43,297:INFO:             mlxtend: Not installed
2022-10-14 17:04:43,298:INFO:       statsforecast: 1.1.1
2022-10-14 17:04:43,298:INFO:        tune_sklearn: Not installed
2022-10-14 17:04:43,298:INFO:                 ray: Not installed
2022-10-14 17:04:43,298:INFO:            hyperopt: Not installed
2022-10-14 17:04:43,298:INFO:              optuna: Not installed
2022-10-14 17:04:43,298:INFO:               skopt: Not installed
2022-10-14 17:04:43,298:INFO:              mlflow: 1.29.0
2022-10-14 17:04:43,299:INFO:              gradio: Not installed
2022-10-14 17:04:43,300:INFO:             fastapi: Not installed
2022-10-14 17:04:43,300:INFO:             uvicorn: Not installed
2022-10-14 17:04:43,300:INFO:              m2cgen: Not installed
2022-10-14 17:04:43,300:INFO:           evidently: Not installed
2022-10-14 17:04:43,300:INFO:                nltk: 3.6.5
2022-10-14 17:04:43,300:INFO:            pyLDAvis: Not installed
2022-10-14 17:04:43,300:INFO:              gensim: Not installed
2022-10-14 17:04:43,300:INFO:               spacy: Not installed
2022-10-14 17:04:43,300:INFO:           wordcloud: Not installed
2022-10-14 17:04:43,300:INFO:            textblob: Not installed
2022-10-14 17:04:43,301:INFO:               fugue: Not installed
2022-10-14 17:04:43,301:INFO:           streamlit: Not installed
2022-10-14 17:04:43,301:INFO:             prophet: 1.1.1
2022-10-14 17:04:43,301:INFO:None
2022-10-14 17:04:43,301:INFO:Set up data.
2022-10-14 17:04:43,318:INFO:Set up train/test split.
2022-10-14 17:04:43,328:INFO:Set up index.
2022-10-14 17:04:43,328:INFO:Set up folding strategy.
2022-10-14 17:04:43,329:INFO:Assigning column types.
2022-10-14 17:04:43,333:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-14 17:04:43,334:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-14 17:04:43,341:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-14 17:04:43,348:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-14 17:04:43,435:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-14 17:04:43,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-14 17:04:43,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-14 17:05:12,932:INFO:PyCaret RegressionExperiment
2022-10-14 17:05:12,934:INFO:Logging name: reg-default-name
2022-10-14 17:05:12,934:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-14 17:05:12,934:INFO:version 3.0.0.rc4
2022-10-14 17:05:12,934:INFO:Initializing setup()
2022-10-14 17:05:12,935:INFO:self.USI: 819d
2022-10-14 17:05:12,935:INFO:self.variable_keys: {'idx', 'exp_id', 'exp_name_log', 'data', 'y_test', 'logging_param', 'pipeline', '_all_models', 'target_param', '_all_models_internal', 'y', '_all_metrics', 'fold_shuffle_param', 'html_param', 'variable_keys', 'transform_target_param', 'master_model_container', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'X_test', 'fold_groups_param', 'log_plots_param', 'display_container', 'seed', 'X_train', '_available_plots', '_gpu_n_jobs_param', 'memory', 'y_train', 'fold_generator', 'transform_target_method_param', 'X', 'USI'}
2022-10-14 17:05:12,935:INFO:Checking environment
2022-10-14 17:05:12,935:INFO:python_version: 3.9.7
2022-10-14 17:05:12,935:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-14 17:05:12,935:INFO:machine: x86_64
2022-10-14 17:05:12,935:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:05:12,935:INFO:Memory: svmem(total=8589934592, available=2206355456, percent=74.3, used=4419706880, free=36020224, active=2172076032, inactive=2168901632, wired=2247630848)
2022-10-14 17:05:12,936:INFO:Physical Core: 2
2022-10-14 17:05:12,936:INFO:Logical Core: 4
2022-10-14 17:05:12,936:INFO:Checking libraries
2022-10-14 17:05:12,936:INFO:System:
2022-10-14 17:05:12,936:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-14 17:05:12,936:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-14 17:05:12,936:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:05:12,936:INFO:PyCaret required dependencies:
2022-10-14 17:05:12,936:INFO:                 pip: 21.2.4
2022-10-14 17:05:12,936:INFO:          setuptools: 58.0.4
2022-10-14 17:05:12,936:INFO:             pycaret: 3.0.0rc4
2022-10-14 17:05:12,936:INFO:             IPython: 7.29.0
2022-10-14 17:05:12,936:INFO:          ipywidgets: 7.6.5
2022-10-14 17:05:12,936:INFO:                tqdm: 4.62.3
2022-10-14 17:05:12,936:INFO:               numpy: 1.22.4
2022-10-14 17:05:12,936:INFO:              pandas: 1.4.4
2022-10-14 17:05:12,936:INFO:              jinja2: 3.1.2
2022-10-14 17:05:12,937:INFO:               scipy: 1.8.1
2022-10-14 17:05:12,937:INFO:              joblib: 1.1.0
2022-10-14 17:05:12,937:INFO:             sklearn: 1.0.2
2022-10-14 17:05:12,937:INFO:                pyod: 1.0.5
2022-10-14 17:05:12,937:INFO:            imblearn: 0.9.0
2022-10-14 17:05:12,937:INFO:   category_encoders: 2.5.1.post0
2022-10-14 17:05:12,937:INFO:            lightgbm: 3.3.2
2022-10-14 17:05:12,937:INFO:               numba: 0.55.2
2022-10-14 17:05:12,937:INFO:            requests: 2.28.1
2022-10-14 17:05:12,937:INFO:          matplotlib: 3.4.3
2022-10-14 17:05:12,937:INFO:          scikitplot: 0.3.7
2022-10-14 17:05:12,937:INFO:         yellowbrick: 1.4
2022-10-14 17:05:12,937:INFO:              plotly: 5.5.0
2022-10-14 17:05:12,937:INFO:             kaleido: 0.2.1
2022-10-14 17:05:12,937:INFO:         statsmodels: 0.13.2
2022-10-14 17:05:12,937:INFO:              sktime: 0.13.4
2022-10-14 17:05:12,938:INFO:               tbats: 1.1.1
2022-10-14 17:05:12,939:INFO:            pmdarima: 1.8.5
2022-10-14 17:05:12,943:INFO:              psutil: 5.9.2
2022-10-14 17:05:12,943:INFO:PyCaret optional dependencies:
2022-10-14 17:05:12,944:INFO:                shap: 0.41.0
2022-10-14 17:05:12,944:INFO:           interpret: Not installed
2022-10-14 17:05:12,944:INFO:                umap: Not installed
2022-10-14 17:05:12,944:INFO:    pandas_profiling: Not installed
2022-10-14 17:05:12,944:INFO:  explainerdashboard: Not installed
2022-10-14 17:05:12,944:INFO:             autoviz: Not installed
2022-10-14 17:05:12,944:INFO:           fairlearn: Not installed
2022-10-14 17:05:12,944:INFO:             xgboost: Not installed
2022-10-14 17:05:12,944:INFO:            catboost: 1.1
2022-10-14 17:05:12,944:INFO:              kmodes: Not installed
2022-10-14 17:05:12,945:INFO:             mlxtend: Not installed
2022-10-14 17:05:12,945:INFO:       statsforecast: 1.1.1
2022-10-14 17:05:12,945:INFO:        tune_sklearn: Not installed
2022-10-14 17:05:12,945:INFO:                 ray: Not installed
2022-10-14 17:05:12,945:INFO:            hyperopt: Not installed
2022-10-14 17:05:12,945:INFO:              optuna: Not installed
2022-10-14 17:05:12,945:INFO:               skopt: Not installed
2022-10-14 17:05:12,945:INFO:              mlflow: 1.29.0
2022-10-14 17:05:12,946:INFO:              gradio: Not installed
2022-10-14 17:05:12,946:INFO:             fastapi: Not installed
2022-10-14 17:05:12,946:INFO:             uvicorn: Not installed
2022-10-14 17:05:12,946:INFO:              m2cgen: Not installed
2022-10-14 17:05:12,946:INFO:           evidently: Not installed
2022-10-14 17:05:12,946:INFO:                nltk: 3.6.5
2022-10-14 17:05:12,946:INFO:            pyLDAvis: Not installed
2022-10-14 17:05:12,946:INFO:              gensim: Not installed
2022-10-14 17:05:12,946:INFO:               spacy: Not installed
2022-10-14 17:05:12,946:INFO:           wordcloud: Not installed
2022-10-14 17:05:12,946:INFO:            textblob: Not installed
2022-10-14 17:05:12,946:INFO:               fugue: Not installed
2022-10-14 17:05:12,946:INFO:           streamlit: Not installed
2022-10-14 17:05:12,946:INFO:             prophet: 1.1.1
2022-10-14 17:05:12,946:INFO:None
2022-10-14 17:05:12,947:INFO:Set up data.
2022-10-14 17:05:12,959:INFO:Set up train/test split.
2022-10-14 17:05:12,969:INFO:Set up index.
2022-10-14 17:05:12,969:INFO:Set up folding strategy.
2022-10-14 17:05:12,970:INFO:Assigning column types.
2022-10-14 17:05:12,974:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-14 17:05:12,974:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-14 17:05:12,981:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-14 17:05:12,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-14 17:05:13,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-14 17:05:13,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-14 17:05:13,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-14 17:05:31,710:INFO:PyCaret RegressionExperiment
2022-10-14 17:05:31,713:INFO:Logging name: reg-default-name
2022-10-14 17:05:31,713:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-14 17:05:31,714:INFO:version 3.0.0.rc4
2022-10-14 17:05:31,714:INFO:Initializing setup()
2022-10-14 17:05:31,715:INFO:self.USI: ea9d
2022-10-14 17:05:31,716:INFO:self.variable_keys: {'idx', 'exp_id', 'exp_name_log', 'data', 'y_test', 'logging_param', 'pipeline', '_all_models', 'target_param', '_all_models_internal', 'y', '_all_metrics', 'fold_shuffle_param', 'html_param', 'variable_keys', 'transform_target_param', 'master_model_container', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'X_test', 'fold_groups_param', 'log_plots_param', 'display_container', 'seed', 'X_train', '_available_plots', '_gpu_n_jobs_param', 'memory', 'y_train', 'fold_generator', 'transform_target_method_param', 'X', 'USI'}
2022-10-14 17:05:31,716:INFO:Checking environment
2022-10-14 17:05:31,716:INFO:python_version: 3.9.7
2022-10-14 17:05:31,717:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-14 17:05:31,717:INFO:machine: x86_64
2022-10-14 17:05:31,717:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:05:31,717:INFO:Memory: svmem(total=8589934592, available=2184794112, percent=74.6, used=4417961984, free=15065088, active=2171621376, inactive=2168856576, wired=2246340608)
2022-10-14 17:05:31,717:INFO:Physical Core: 2
2022-10-14 17:05:31,718:INFO:Logical Core: 4
2022-10-14 17:05:31,718:INFO:Checking libraries
2022-10-14 17:05:31,718:INFO:System:
2022-10-14 17:05:31,718:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-14 17:05:31,718:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-14 17:05:31,718:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-14 17:05:31,718:INFO:PyCaret required dependencies:
2022-10-14 17:05:31,719:INFO:                 pip: 21.2.4
2022-10-14 17:05:31,719:INFO:          setuptools: 58.0.4
2022-10-14 17:05:31,719:INFO:             pycaret: 3.0.0rc4
2022-10-14 17:05:31,719:INFO:             IPython: 7.29.0
2022-10-14 17:05:31,719:INFO:          ipywidgets: 7.6.5
2022-10-14 17:05:31,722:INFO:                tqdm: 4.62.3
2022-10-14 17:05:31,722:INFO:               numpy: 1.22.4
2022-10-14 17:05:31,722:INFO:              pandas: 1.4.4
2022-10-14 17:05:31,722:INFO:              jinja2: 3.1.2
2022-10-14 17:05:31,723:INFO:               scipy: 1.8.1
2022-10-14 17:05:31,723:INFO:              joblib: 1.1.0
2022-10-14 17:05:31,723:INFO:             sklearn: 1.0.2
2022-10-14 17:05:31,723:INFO:                pyod: 1.0.5
2022-10-14 17:05:31,723:INFO:            imblearn: 0.9.0
2022-10-14 17:05:31,723:INFO:   category_encoders: 2.5.1.post0
2022-10-14 17:05:31,723:INFO:            lightgbm: 3.3.2
2022-10-14 17:05:31,723:INFO:               numba: 0.55.2
2022-10-14 17:05:31,723:INFO:            requests: 2.28.1
2022-10-14 17:05:31,723:INFO:          matplotlib: 3.4.3
2022-10-14 17:05:31,723:INFO:          scikitplot: 0.3.7
2022-10-14 17:05:31,723:INFO:         yellowbrick: 1.4
2022-10-14 17:05:31,724:INFO:              plotly: 5.5.0
2022-10-14 17:05:31,724:INFO:             kaleido: 0.2.1
2022-10-14 17:05:31,724:INFO:         statsmodels: 0.13.2
2022-10-14 17:05:31,724:INFO:              sktime: 0.13.4
2022-10-14 17:05:31,724:INFO:               tbats: 1.1.1
2022-10-14 17:05:31,725:INFO:            pmdarima: 1.8.5
2022-10-14 17:05:31,725:INFO:              psutil: 5.9.2
2022-10-14 17:05:31,725:INFO:PyCaret optional dependencies:
2022-10-14 17:05:31,725:INFO:                shap: 0.41.0
2022-10-14 17:05:31,725:INFO:           interpret: Not installed
2022-10-14 17:05:31,725:INFO:                umap: Not installed
2022-10-14 17:05:31,725:INFO:    pandas_profiling: Not installed
2022-10-14 17:05:31,725:INFO:  explainerdashboard: Not installed
2022-10-14 17:05:31,726:INFO:             autoviz: Not installed
2022-10-14 17:05:31,726:INFO:           fairlearn: Not installed
2022-10-14 17:05:31,726:INFO:             xgboost: Not installed
2022-10-14 17:05:31,726:INFO:            catboost: 1.1
2022-10-14 17:05:31,726:INFO:              kmodes: Not installed
2022-10-14 17:05:31,726:INFO:             mlxtend: Not installed
2022-10-14 17:05:31,726:INFO:       statsforecast: 1.1.1
2022-10-14 17:05:31,726:INFO:        tune_sklearn: Not installed
2022-10-14 17:05:31,726:INFO:                 ray: Not installed
2022-10-14 17:05:31,726:INFO:            hyperopt: Not installed
2022-10-14 17:05:31,726:INFO:              optuna: Not installed
2022-10-14 17:05:31,727:INFO:               skopt: Not installed
2022-10-14 17:05:31,727:INFO:              mlflow: 1.29.0
2022-10-14 17:05:31,727:INFO:              gradio: Not installed
2022-10-14 17:05:31,727:INFO:             fastapi: Not installed
2022-10-14 17:05:31,727:INFO:             uvicorn: Not installed
2022-10-14 17:05:31,727:INFO:              m2cgen: Not installed
2022-10-14 17:05:31,727:INFO:           evidently: Not installed
2022-10-14 17:05:31,727:INFO:                nltk: 3.6.5
2022-10-14 17:05:31,727:INFO:            pyLDAvis: Not installed
2022-10-14 17:05:31,727:INFO:              gensim: Not installed
2022-10-14 17:05:31,727:INFO:               spacy: Not installed
2022-10-14 17:05:31,727:INFO:           wordcloud: Not installed
2022-10-14 17:05:31,727:INFO:            textblob: Not installed
2022-10-14 17:05:31,727:INFO:               fugue: Not installed
2022-10-14 17:05:31,728:INFO:           streamlit: Not installed
2022-10-14 17:05:31,728:INFO:             prophet: 1.1.1
2022-10-14 17:05:31,728:INFO:None
2022-10-14 17:05:31,728:INFO:Set up data.
2022-10-14 17:05:31,741:INFO:Set up train/test split.
2022-10-14 17:05:31,747:INFO:Set up index.
2022-10-14 17:05:31,748:INFO:Set up folding strategy.
2022-10-14 17:05:31,748:INFO:Assigning column types.
2022-10-14 17:05:31,754:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-14 17:05:31,755:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-14 17:05:31,761:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-14 17:05:31,769:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-14 17:05:31,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-14 17:05:31,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-14 17:05:31,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-20 13:46:28,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:46:28,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:46:28,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:46:28,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:46:31,582:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 13:46:33,171:INFO:Initializing load_model()
2022-10-20 13:46:33,172:INFO:load_model(model_name=MLOps_Pipeline, platform=None, authentication=None, verbose=True)
2022-10-20 13:58:15,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:58:15,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:58:15,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:58:15,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 13:58:18,511:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 13:58:20,026:INFO:Initializing load_model()
2022-10-20 13:58:20,026:INFO:load_model(model_name=MLOps_Pipeline, platform=None, authentication=None, verbose=True)
2022-10-20 14:00:43,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:43,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:43,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:43,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:46,465:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:00:58,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:58,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:00:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:01:00,948:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:05:10,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:05:10,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:05:10,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:05:10,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:05:13,131:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:06:12,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:12,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:12,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:12,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:14,695:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:06:54,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:54,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:54,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:54,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:06:57,194:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:09:33,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:09:33,620:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:09:33,620:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:09:33,620:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:09:36,175:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:12:38,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:12:38,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:12:38,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:12:38,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:12:40,894:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-20 14:24:05,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:24:05,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:24:05,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:24:05,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-20 14:24:07,990:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:36:13,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:36:13,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:36:13,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:36:13,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:36:16,859:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:38:23,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:38:23,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:38:23,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:38:23,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:38:25,468:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:39:07,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:39:07,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:39:07,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:39:07,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:39:09,295:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:40:33,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:40:33,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:40:33,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:40:33,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:40:35,449:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:41:04,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:04,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:04,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:04,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:07,119:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:41:48,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:48,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:48,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:48,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:41:50,757:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 11:44:37,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:44:37,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:44:37,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:44:37,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 11:44:40,142:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 12:27:28,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:27:28,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:27:28,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:27:28,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:27:31,061:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 12:29:26,561:INFO:PyCaret RegressionExperiment
2022-10-21 12:29:26,563:INFO:Logging name: reg-default-name
2022-10-21 12:29:26,563:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:29:26,563:INFO:version 3.0.0.rc4
2022-10-21 12:29:26,564:INFO:Initializing setup()
2022-10-21 12:29:26,564:INFO:self.USI: 76f1
2022-10-21 12:29:26,564:INFO:self.variable_keys: {'pipeline', 'USI', 'X', 'exp_name_log', 'memory', '_gpu_n_jobs_param', 'idx', 'X_test', '_all_models_internal', '_all_metrics', 'logging_param', 'gpu_param', 'master_model_container', 'transform_target_method_param', 'html_param', 'seed', 'log_plots_param', 'y', '_all_models', 'X_train', 'fold_generator', 'fold_shuffle_param', 'target_param', 'transform_target_param', '_ml_usecase', 'data', 'display_container', 'n_jobs_param', 'y_test', 'fold_groups_param', 'variable_keys', 'y_train', '_available_plots', 'exp_id'}
2022-10-21 12:29:26,564:INFO:Checking environment
2022-10-21 12:29:26,564:INFO:python_version: 3.9.7
2022-10-21 12:29:26,565:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:29:26,565:INFO:machine: x86_64
2022-10-21 12:29:26,565:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:29:26,565:INFO:Memory: svmem(total=8589934592, available=2134220800, percent=75.2, used=3981713408, free=15867904, active=2123329536, inactive=2117636096, wired=1858383872)
2022-10-21 12:29:26,565:INFO:Physical Core: 2
2022-10-21 12:29:26,565:INFO:Logical Core: 4
2022-10-21 12:29:26,565:INFO:Checking libraries
2022-10-21 12:29:26,565:INFO:System:
2022-10-21 12:29:26,565:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:29:26,565:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:29:26,565:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:29:26,565:INFO:PyCaret required dependencies:
2022-10-21 12:29:26,565:INFO:                 pip: 21.2.4
2022-10-21 12:29:26,565:INFO:          setuptools: 58.0.4
2022-10-21 12:29:26,565:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:29:26,566:INFO:             IPython: 7.29.0
2022-10-21 12:29:26,566:INFO:          ipywidgets: 7.6.5
2022-10-21 12:29:26,566:INFO:                tqdm: 4.62.3
2022-10-21 12:29:26,566:INFO:               numpy: 1.22.4
2022-10-21 12:29:26,566:INFO:              pandas: 1.4.4
2022-10-21 12:29:26,566:INFO:              jinja2: 3.1.2
2022-10-21 12:29:26,566:INFO:               scipy: 1.8.1
2022-10-21 12:29:26,566:INFO:              joblib: 1.1.0
2022-10-21 12:29:26,566:INFO:             sklearn: 1.0.2
2022-10-21 12:29:26,566:INFO:                pyod: 1.0.5
2022-10-21 12:29:26,566:INFO:            imblearn: 0.9.0
2022-10-21 12:29:26,566:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:29:26,566:INFO:            lightgbm: 3.3.2
2022-10-21 12:29:26,566:INFO:               numba: 0.55.2
2022-10-21 12:29:26,566:INFO:            requests: 2.28.1
2022-10-21 12:29:26,566:INFO:          matplotlib: 3.4.3
2022-10-21 12:29:26,566:INFO:          scikitplot: 0.3.7
2022-10-21 12:29:26,566:INFO:         yellowbrick: 1.4
2022-10-21 12:29:26,566:INFO:              plotly: 5.5.0
2022-10-21 12:29:26,567:INFO:             kaleido: 0.2.1
2022-10-21 12:29:26,567:INFO:         statsmodels: 0.13.2
2022-10-21 12:29:26,567:INFO:              sktime: 0.13.4
2022-10-21 12:29:26,567:INFO:               tbats: 1.1.1
2022-10-21 12:29:26,568:INFO:            pmdarima: 1.8.5
2022-10-21 12:29:26,568:INFO:              psutil: 5.9.2
2022-10-21 12:29:26,568:INFO:PyCaret optional dependencies:
2022-10-21 12:29:26,577:INFO:                shap: 0.41.0
2022-10-21 12:29:26,578:INFO:           interpret: Not installed
2022-10-21 12:29:26,578:INFO:                umap: Not installed
2022-10-21 12:29:26,578:INFO:    pandas_profiling: Not installed
2022-10-21 12:29:26,578:INFO:  explainerdashboard: Not installed
2022-10-21 12:29:26,578:INFO:             autoviz: Not installed
2022-10-21 12:29:26,578:INFO:           fairlearn: Not installed
2022-10-21 12:29:26,578:INFO:             xgboost: Not installed
2022-10-21 12:29:26,579:INFO:            catboost: 1.1
2022-10-21 12:29:26,579:INFO:              kmodes: Not installed
2022-10-21 12:29:26,579:INFO:             mlxtend: Not installed
2022-10-21 12:29:26,579:INFO:       statsforecast: 1.1.1
2022-10-21 12:29:26,579:INFO:        tune_sklearn: Not installed
2022-10-21 12:29:26,579:INFO:                 ray: Not installed
2022-10-21 12:29:26,579:INFO:            hyperopt: Not installed
2022-10-21 12:29:26,579:INFO:              optuna: Not installed
2022-10-21 12:29:26,579:INFO:               skopt: Not installed
2022-10-21 12:29:26,582:INFO:              mlflow: 1.29.0
2022-10-21 12:29:26,582:INFO:              gradio: Not installed
2022-10-21 12:29:26,582:INFO:             fastapi: Not installed
2022-10-21 12:29:26,582:INFO:             uvicorn: Not installed
2022-10-21 12:29:26,582:INFO:              m2cgen: Not installed
2022-10-21 12:29:26,582:INFO:           evidently: Not installed
2022-10-21 12:29:26,582:INFO:                nltk: 3.6.5
2022-10-21 12:29:26,582:INFO:            pyLDAvis: Not installed
2022-10-21 12:29:26,582:INFO:              gensim: Not installed
2022-10-21 12:29:26,582:INFO:               spacy: Not installed
2022-10-21 12:29:26,582:INFO:           wordcloud: Not installed
2022-10-21 12:29:26,582:INFO:            textblob: Not installed
2022-10-21 12:29:26,582:INFO:               fugue: Not installed
2022-10-21 12:29:26,582:INFO:           streamlit: Not installed
2022-10-21 12:29:26,582:INFO:             prophet: 1.1.1
2022-10-21 12:29:26,582:INFO:None
2022-10-21 12:29:26,582:INFO:Set up data.
2022-10-21 12:29:26,606:INFO:Set up train/test split.
2022-10-21 12:29:26,627:INFO:Set up index.
2022-10-21 12:29:26,629:INFO:Set up folding strategy.
2022-10-21 12:29:26,629:INFO:Assigning column types.
2022-10-21 12:29:26,709:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:29:26,710:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:29:26,733:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:29:26,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:29:27,374:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:29:27,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:29:27,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:30:52,272:INFO:PyCaret RegressionExperiment
2022-10-21 12:30:52,273:INFO:Logging name: reg-default-name
2022-10-21 12:30:52,273:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:30:52,273:INFO:version 3.0.0.rc4
2022-10-21 12:30:52,274:INFO:Initializing setup()
2022-10-21 12:30:52,274:INFO:self.USI: b74d
2022-10-21 12:30:52,274:INFO:self.variable_keys: {'pipeline', 'USI', 'X', 'exp_name_log', 'memory', '_gpu_n_jobs_param', 'idx', 'X_test', '_all_models_internal', '_all_metrics', 'logging_param', 'gpu_param', 'master_model_container', 'transform_target_method_param', 'html_param', 'seed', 'log_plots_param', 'y', '_all_models', 'X_train', 'fold_generator', 'fold_shuffle_param', 'target_param', 'transform_target_param', '_ml_usecase', 'data', 'display_container', 'n_jobs_param', 'y_test', 'fold_groups_param', 'variable_keys', 'y_train', '_available_plots', 'exp_id'}
2022-10-21 12:30:52,274:INFO:Checking environment
2022-10-21 12:30:52,274:INFO:python_version: 3.9.7
2022-10-21 12:30:52,275:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:30:52,275:INFO:machine: x86_64
2022-10-21 12:30:52,275:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:30:52,275:INFO:Memory: svmem(total=8589934592, available=2372382720, percent=72.4, used=4132909056, free=168919040, active=2205200384, inactive=2196938752, wired=1927708672)
2022-10-21 12:30:52,275:INFO:Physical Core: 2
2022-10-21 12:30:52,275:INFO:Logical Core: 4
2022-10-21 12:30:52,275:INFO:Checking libraries
2022-10-21 12:30:52,275:INFO:System:
2022-10-21 12:30:52,275:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:30:52,276:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:30:52,276:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:30:52,276:INFO:PyCaret required dependencies:
2022-10-21 12:30:52,276:INFO:                 pip: 21.2.4
2022-10-21 12:30:52,276:INFO:          setuptools: 58.0.4
2022-10-21 12:30:52,276:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:30:52,276:INFO:             IPython: 7.29.0
2022-10-21 12:30:52,276:INFO:          ipywidgets: 7.6.5
2022-10-21 12:30:52,276:INFO:                tqdm: 4.62.3
2022-10-21 12:30:52,276:INFO:               numpy: 1.22.4
2022-10-21 12:30:52,276:INFO:              pandas: 1.4.4
2022-10-21 12:30:52,276:INFO:              jinja2: 3.1.2
2022-10-21 12:30:52,277:INFO:               scipy: 1.8.1
2022-10-21 12:30:52,277:INFO:              joblib: 1.1.0
2022-10-21 12:30:52,277:INFO:             sklearn: 1.0.2
2022-10-21 12:30:52,277:INFO:                pyod: 1.0.5
2022-10-21 12:30:52,277:INFO:            imblearn: 0.9.0
2022-10-21 12:30:52,277:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:30:52,277:INFO:            lightgbm: 3.3.2
2022-10-21 12:30:52,277:INFO:               numba: 0.55.2
2022-10-21 12:30:52,277:INFO:            requests: 2.28.1
2022-10-21 12:30:52,278:INFO:          matplotlib: 3.4.3
2022-10-21 12:30:52,278:INFO:          scikitplot: 0.3.7
2022-10-21 12:30:52,278:INFO:         yellowbrick: 1.4
2022-10-21 12:30:52,278:INFO:              plotly: 5.5.0
2022-10-21 12:30:52,278:INFO:             kaleido: 0.2.1
2022-10-21 12:30:52,279:INFO:         statsmodels: 0.13.2
2022-10-21 12:30:52,279:INFO:              sktime: 0.13.4
2022-10-21 12:30:52,279:INFO:               tbats: 1.1.1
2022-10-21 12:30:52,279:INFO:            pmdarima: 1.8.5
2022-10-21 12:30:52,279:INFO:              psutil: 5.9.2
2022-10-21 12:30:52,279:INFO:PyCaret optional dependencies:
2022-10-21 12:30:52,280:INFO:                shap: 0.41.0
2022-10-21 12:30:52,280:INFO:           interpret: Not installed
2022-10-21 12:30:52,280:INFO:                umap: Not installed
2022-10-21 12:30:52,280:INFO:    pandas_profiling: Not installed
2022-10-21 12:30:52,280:INFO:  explainerdashboard: Not installed
2022-10-21 12:30:52,280:INFO:             autoviz: Not installed
2022-10-21 12:30:52,280:INFO:           fairlearn: Not installed
2022-10-21 12:30:52,280:INFO:             xgboost: Not installed
2022-10-21 12:30:52,280:INFO:            catboost: 1.1
2022-10-21 12:30:52,280:INFO:              kmodes: Not installed
2022-10-21 12:30:52,280:INFO:             mlxtend: Not installed
2022-10-21 12:30:52,280:INFO:       statsforecast: 1.1.1
2022-10-21 12:30:52,280:INFO:        tune_sklearn: Not installed
2022-10-21 12:30:52,280:INFO:                 ray: Not installed
2022-10-21 12:30:52,280:INFO:            hyperopt: Not installed
2022-10-21 12:30:52,280:INFO:              optuna: Not installed
2022-10-21 12:30:52,281:INFO:               skopt: Not installed
2022-10-21 12:30:52,281:INFO:              mlflow: 1.29.0
2022-10-21 12:30:52,281:INFO:              gradio: Not installed
2022-10-21 12:30:52,281:INFO:             fastapi: Not installed
2022-10-21 12:30:52,281:INFO:             uvicorn: Not installed
2022-10-21 12:30:52,281:INFO:              m2cgen: Not installed
2022-10-21 12:30:52,281:INFO:           evidently: Not installed
2022-10-21 12:30:52,286:INFO:                nltk: 3.6.5
2022-10-21 12:30:52,286:INFO:            pyLDAvis: Not installed
2022-10-21 12:30:52,286:INFO:              gensim: Not installed
2022-10-21 12:30:52,287:INFO:               spacy: Not installed
2022-10-21 12:30:52,287:INFO:           wordcloud: Not installed
2022-10-21 12:30:52,287:INFO:            textblob: Not installed
2022-10-21 12:30:52,287:INFO:               fugue: Not installed
2022-10-21 12:30:52,287:INFO:           streamlit: Not installed
2022-10-21 12:30:52,287:INFO:             prophet: 1.1.1
2022-10-21 12:30:52,287:INFO:None
2022-10-21 12:30:52,287:INFO:Set up data.
2022-10-21 12:30:52,304:INFO:Set up train/test split.
2022-10-21 12:30:52,325:INFO:Set up index.
2022-10-21 12:30:52,325:INFO:Set up folding strategy.
2022-10-21 12:30:52,325:INFO:Assigning column types.
2022-10-21 12:30:52,339:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:30:52,340:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:30:52,362:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:30:52,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:30:52,625:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:30:53,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:30:53,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:31:17,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:31:17,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:31:17,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:31:17,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:31:20,311:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 12:31:21,281:INFO:PyCaret RegressionExperiment
2022-10-21 12:31:21,282:INFO:Logging name: reg-default-name
2022-10-21 12:31:21,282:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:31:21,282:INFO:version 3.0.0.rc4
2022-10-21 12:31:21,282:INFO:Initializing setup()
2022-10-21 12:31:21,282:INFO:self.USI: 2308
2022-10-21 12:31:21,282:INFO:self.variable_keys: {'variable_keys', '_available_plots', 'n_jobs_param', 'y_test', 'fold_generator', 'transform_target_method_param', 'log_plots_param', 'idx', '_gpu_n_jobs_param', 'pipeline', 'y_train', 'transform_target_param', 'USI', 'fold_shuffle_param', 'X_train', '_all_models', 'html_param', 'logging_param', 'memory', 'y', 'X_test', 'seed', '_all_models_internal', 'X', 'exp_name_log', 'master_model_container', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_param', 'data', '_all_metrics', 'display_container', '_ml_usecase'}
2022-10-21 12:31:21,282:INFO:Checking environment
2022-10-21 12:31:21,282:INFO:python_version: 3.9.7
2022-10-21 12:31:21,282:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:31:21,283:INFO:machine: x86_64
2022-10-21 12:31:21,283:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:31:21,283:INFO:Memory: svmem(total=8589934592, available=2310197248, percent=73.1, used=4234559488, free=20979712, active=2290040832, inactive=2238517248, wired=1944518656)
2022-10-21 12:31:21,283:INFO:Physical Core: 2
2022-10-21 12:31:21,283:INFO:Logical Core: 4
2022-10-21 12:31:21,283:INFO:Checking libraries
2022-10-21 12:31:21,283:INFO:System:
2022-10-21 12:31:21,283:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:31:21,283:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:31:21,283:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:31:21,283:INFO:PyCaret required dependencies:
2022-10-21 12:31:21,283:INFO:                 pip: 21.2.4
2022-10-21 12:31:21,284:INFO:          setuptools: 58.0.4
2022-10-21 12:31:21,284:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:31:21,284:INFO:             IPython: 7.29.0
2022-10-21 12:31:21,284:INFO:          ipywidgets: 7.6.5
2022-10-21 12:31:21,284:INFO:                tqdm: 4.62.3
2022-10-21 12:31:21,284:INFO:               numpy: 1.22.4
2022-10-21 12:31:21,284:INFO:              pandas: 1.4.4
2022-10-21 12:31:21,284:INFO:              jinja2: 3.1.2
2022-10-21 12:31:21,284:INFO:               scipy: 1.8.1
2022-10-21 12:31:21,284:INFO:              joblib: 1.1.0
2022-10-21 12:31:21,284:INFO:             sklearn: 1.0.2
2022-10-21 12:31:21,285:INFO:                pyod: 1.0.5
2022-10-21 12:31:21,285:INFO:            imblearn: 0.9.0
2022-10-21 12:31:21,285:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:31:21,285:INFO:            lightgbm: 3.3.2
2022-10-21 12:31:21,285:INFO:               numba: 0.55.2
2022-10-21 12:31:21,286:INFO:            requests: 2.28.1
2022-10-21 12:31:21,286:INFO:          matplotlib: 3.4.3
2022-10-21 12:31:21,286:INFO:          scikitplot: 0.3.7
2022-10-21 12:31:21,286:INFO:         yellowbrick: 1.4
2022-10-21 12:31:21,286:INFO:              plotly: 5.5.0
2022-10-21 12:31:21,286:INFO:             kaleido: 0.2.1
2022-10-21 12:31:21,286:INFO:         statsmodels: 0.13.2
2022-10-21 12:31:21,286:INFO:              sktime: 0.13.4
2022-10-21 12:31:21,286:INFO:               tbats: 1.1.1
2022-10-21 12:31:21,286:INFO:            pmdarima: 1.8.5
2022-10-21 12:31:21,286:INFO:              psutil: 5.9.2
2022-10-21 12:31:21,286:INFO:PyCaret optional dependencies:
2022-10-21 12:31:21,296:INFO:                shap: 0.41.0
2022-10-21 12:31:21,296:INFO:           interpret: Not installed
2022-10-21 12:31:21,296:INFO:                umap: Not installed
2022-10-21 12:31:21,296:INFO:    pandas_profiling: Not installed
2022-10-21 12:31:21,296:INFO:  explainerdashboard: Not installed
2022-10-21 12:31:21,296:INFO:             autoviz: Not installed
2022-10-21 12:31:21,296:INFO:           fairlearn: Not installed
2022-10-21 12:31:21,296:INFO:             xgboost: Not installed
2022-10-21 12:31:21,296:INFO:            catboost: 1.1
2022-10-21 12:31:21,296:INFO:              kmodes: Not installed
2022-10-21 12:31:21,296:INFO:             mlxtend: Not installed
2022-10-21 12:31:21,296:INFO:       statsforecast: 1.1.1
2022-10-21 12:31:21,296:INFO:        tune_sklearn: Not installed
2022-10-21 12:31:21,296:INFO:                 ray: Not installed
2022-10-21 12:31:21,297:INFO:            hyperopt: Not installed
2022-10-21 12:31:21,297:INFO:              optuna: Not installed
2022-10-21 12:31:21,297:INFO:               skopt: Not installed
2022-10-21 12:31:21,297:INFO:              mlflow: 1.29.0
2022-10-21 12:31:21,297:INFO:              gradio: Not installed
2022-10-21 12:31:21,297:INFO:             fastapi: Not installed
2022-10-21 12:31:21,297:INFO:             uvicorn: Not installed
2022-10-21 12:31:21,297:INFO:              m2cgen: Not installed
2022-10-21 12:31:21,297:INFO:           evidently: Not installed
2022-10-21 12:31:21,297:INFO:                nltk: 3.6.5
2022-10-21 12:31:21,297:INFO:            pyLDAvis: Not installed
2022-10-21 12:31:21,297:INFO:              gensim: Not installed
2022-10-21 12:31:21,297:INFO:               spacy: Not installed
2022-10-21 12:31:21,297:INFO:           wordcloud: Not installed
2022-10-21 12:31:21,297:INFO:            textblob: Not installed
2022-10-21 12:31:21,297:INFO:               fugue: Not installed
2022-10-21 12:31:21,297:INFO:           streamlit: Not installed
2022-10-21 12:31:21,297:INFO:             prophet: 1.1.1
2022-10-21 12:31:21,297:INFO:None
2022-10-21 12:31:21,297:INFO:Set up data.
2022-10-21 12:31:21,309:INFO:Set up train/test split.
2022-10-21 12:31:21,316:INFO:Set up index.
2022-10-21 12:31:21,316:INFO:Set up folding strategy.
2022-10-21 12:31:21,316:INFO:Assigning column types.
2022-10-21 12:31:21,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:31:21,323:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:31:21,330:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:31:21,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:31:21,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:31:21,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:31:21,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:31:31,500:INFO:PyCaret RegressionExperiment
2022-10-21 12:31:31,500:INFO:Logging name: reg-default-name
2022-10-21 12:31:31,500:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:31:31,500:INFO:version 3.0.0.rc4
2022-10-21 12:31:31,500:INFO:Initializing setup()
2022-10-21 12:31:31,500:INFO:self.USI: 09e8
2022-10-21 12:31:31,500:INFO:self.variable_keys: {'variable_keys', '_available_plots', 'n_jobs_param', 'y_test', 'fold_generator', 'transform_target_method_param', 'log_plots_param', 'idx', '_gpu_n_jobs_param', 'pipeline', 'y_train', 'transform_target_param', 'USI', 'fold_shuffle_param', 'X_train', '_all_models', 'html_param', 'logging_param', 'memory', 'y', 'X_test', 'seed', '_all_models_internal', 'X', 'exp_name_log', 'master_model_container', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_param', 'data', '_all_metrics', 'display_container', '_ml_usecase'}
2022-10-21 12:31:31,500:INFO:Checking environment
2022-10-21 12:31:31,501:INFO:python_version: 3.9.7
2022-10-21 12:31:31,501:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:31:31,505:INFO:machine: x86_64
2022-10-21 12:31:31,506:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:31:31,506:INFO:Memory: svmem(total=8589934592, available=2313994240, percent=73.1, used=4229959680, free=20656128, active=2293370880, inactive=2280755200, wired=1936588800)
2022-10-21 12:31:31,506:INFO:Physical Core: 2
2022-10-21 12:31:31,506:INFO:Logical Core: 4
2022-10-21 12:31:31,506:INFO:Checking libraries
2022-10-21 12:31:31,506:INFO:System:
2022-10-21 12:31:31,506:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:31:31,506:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:31:31,506:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:31:31,506:INFO:PyCaret required dependencies:
2022-10-21 12:31:31,506:INFO:                 pip: 21.2.4
2022-10-21 12:31:31,506:INFO:          setuptools: 58.0.4
2022-10-21 12:31:31,507:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:31:31,507:INFO:             IPython: 7.29.0
2022-10-21 12:31:31,507:INFO:          ipywidgets: 7.6.5
2022-10-21 12:31:31,507:INFO:                tqdm: 4.62.3
2022-10-21 12:31:31,507:INFO:               numpy: 1.22.4
2022-10-21 12:31:31,507:INFO:              pandas: 1.4.4
2022-10-21 12:31:31,507:INFO:              jinja2: 3.1.2
2022-10-21 12:31:31,507:INFO:               scipy: 1.8.1
2022-10-21 12:31:31,507:INFO:              joblib: 1.1.0
2022-10-21 12:31:31,507:INFO:             sklearn: 1.0.2
2022-10-21 12:31:31,507:INFO:                pyod: 1.0.5
2022-10-21 12:31:31,507:INFO:            imblearn: 0.9.0
2022-10-21 12:31:31,507:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:31:31,507:INFO:            lightgbm: 3.3.2
2022-10-21 12:31:31,507:INFO:               numba: 0.55.2
2022-10-21 12:31:31,507:INFO:            requests: 2.28.1
2022-10-21 12:31:31,507:INFO:          matplotlib: 3.4.3
2022-10-21 12:31:31,507:INFO:          scikitplot: 0.3.7
2022-10-21 12:31:31,507:INFO:         yellowbrick: 1.4
2022-10-21 12:31:31,508:INFO:              plotly: 5.5.0
2022-10-21 12:31:31,508:INFO:             kaleido: 0.2.1
2022-10-21 12:31:31,508:INFO:         statsmodels: 0.13.2
2022-10-21 12:31:31,508:INFO:              sktime: 0.13.4
2022-10-21 12:31:31,508:INFO:               tbats: 1.1.1
2022-10-21 12:31:31,508:INFO:            pmdarima: 1.8.5
2022-10-21 12:31:31,508:INFO:              psutil: 5.9.2
2022-10-21 12:31:31,508:INFO:PyCaret optional dependencies:
2022-10-21 12:31:31,508:INFO:                shap: 0.41.0
2022-10-21 12:31:31,508:INFO:           interpret: Not installed
2022-10-21 12:31:31,508:INFO:                umap: Not installed
2022-10-21 12:31:31,508:INFO:    pandas_profiling: Not installed
2022-10-21 12:31:31,508:INFO:  explainerdashboard: Not installed
2022-10-21 12:31:31,508:INFO:             autoviz: Not installed
2022-10-21 12:31:31,509:INFO:           fairlearn: Not installed
2022-10-21 12:31:31,509:INFO:             xgboost: Not installed
2022-10-21 12:31:31,509:INFO:            catboost: 1.1
2022-10-21 12:31:31,509:INFO:              kmodes: Not installed
2022-10-21 12:31:31,509:INFO:             mlxtend: Not installed
2022-10-21 12:31:31,509:INFO:       statsforecast: 1.1.1
2022-10-21 12:31:31,510:INFO:        tune_sklearn: Not installed
2022-10-21 12:31:31,510:INFO:                 ray: Not installed
2022-10-21 12:31:31,510:INFO:            hyperopt: Not installed
2022-10-21 12:31:31,510:INFO:              optuna: Not installed
2022-10-21 12:31:31,510:INFO:               skopt: Not installed
2022-10-21 12:31:31,510:INFO:              mlflow: 1.29.0
2022-10-21 12:31:31,513:INFO:              gradio: Not installed
2022-10-21 12:31:31,513:INFO:             fastapi: Not installed
2022-10-21 12:31:31,513:INFO:             uvicorn: Not installed
2022-10-21 12:31:31,514:INFO:              m2cgen: Not installed
2022-10-21 12:31:31,514:INFO:           evidently: Not installed
2022-10-21 12:31:31,514:INFO:                nltk: 3.6.5
2022-10-21 12:31:31,514:INFO:            pyLDAvis: Not installed
2022-10-21 12:31:31,514:INFO:              gensim: Not installed
2022-10-21 12:31:31,514:INFO:               spacy: Not installed
2022-10-21 12:31:31,514:INFO:           wordcloud: Not installed
2022-10-21 12:31:31,514:INFO:            textblob: Not installed
2022-10-21 12:31:31,514:INFO:               fugue: Not installed
2022-10-21 12:31:31,514:INFO:           streamlit: Not installed
2022-10-21 12:31:31,514:INFO:             prophet: 1.1.1
2022-10-21 12:31:31,514:INFO:None
2022-10-21 12:31:31,514:INFO:Set up data.
2022-10-21 12:31:31,529:INFO:Set up train/test split.
2022-10-21 12:31:31,548:INFO:Set up index.
2022-10-21 12:31:31,553:INFO:Set up folding strategy.
2022-10-21 12:31:31,553:INFO:Assigning column types.
2022-10-21 12:31:31,564:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:31:31,564:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:31:31,601:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:31:31,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:31:31,768:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:31:32,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:31:32,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:33:01,878:INFO:PyCaret RegressionExperiment
2022-10-21 12:33:01,879:INFO:Logging name: reg-default-name
2022-10-21 12:33:01,879:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:33:01,879:INFO:version 3.0.0.rc4
2022-10-21 12:33:01,879:INFO:Initializing setup()
2022-10-21 12:33:01,879:INFO:self.USI: 1055
2022-10-21 12:33:01,879:INFO:self.variable_keys: {'variable_keys', '_available_plots', 'n_jobs_param', 'y_test', 'fold_generator', 'transform_target_method_param', 'log_plots_param', 'idx', '_gpu_n_jobs_param', 'pipeline', 'y_train', 'transform_target_param', 'USI', 'fold_shuffle_param', 'X_train', '_all_models', 'html_param', 'logging_param', 'memory', 'y', 'X_test', 'seed', '_all_models_internal', 'X', 'exp_name_log', 'master_model_container', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_param', 'data', '_all_metrics', 'display_container', '_ml_usecase'}
2022-10-21 12:33:01,880:INFO:Checking environment
2022-10-21 12:33:01,880:INFO:python_version: 3.9.7
2022-10-21 12:33:01,880:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:33:01,880:INFO:machine: x86_64
2022-10-21 12:33:01,880:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:33:01,880:INFO:Memory: svmem(total=8589934592, available=2362884096, percent=72.5, used=4270772224, free=29306880, active=2335350784, inactive=2329452544, wired=1935421440)
2022-10-21 12:33:01,880:INFO:Physical Core: 2
2022-10-21 12:33:01,880:INFO:Logical Core: 4
2022-10-21 12:33:01,880:INFO:Checking libraries
2022-10-21 12:33:01,880:INFO:System:
2022-10-21 12:33:01,880:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:33:01,881:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:33:01,881:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:33:01,881:INFO:PyCaret required dependencies:
2022-10-21 12:33:01,881:INFO:                 pip: 21.2.4
2022-10-21 12:33:01,881:INFO:          setuptools: 58.0.4
2022-10-21 12:33:01,881:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:33:01,881:INFO:             IPython: 7.29.0
2022-10-21 12:33:01,881:INFO:          ipywidgets: 7.6.5
2022-10-21 12:33:01,881:INFO:                tqdm: 4.62.3
2022-10-21 12:33:01,881:INFO:               numpy: 1.22.4
2022-10-21 12:33:01,881:INFO:              pandas: 1.4.4
2022-10-21 12:33:01,881:INFO:              jinja2: 3.1.2
2022-10-21 12:33:01,881:INFO:               scipy: 1.8.1
2022-10-21 12:33:01,881:INFO:              joblib: 1.1.0
2022-10-21 12:33:01,882:INFO:             sklearn: 1.0.2
2022-10-21 12:33:01,882:INFO:                pyod: 1.0.5
2022-10-21 12:33:01,882:INFO:            imblearn: 0.9.0
2022-10-21 12:33:01,882:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:33:01,882:INFO:            lightgbm: 3.3.2
2022-10-21 12:33:01,882:INFO:               numba: 0.55.2
2022-10-21 12:33:01,882:INFO:            requests: 2.28.1
2022-10-21 12:33:01,884:INFO:          matplotlib: 3.4.3
2022-10-21 12:33:01,885:INFO:          scikitplot: 0.3.7
2022-10-21 12:33:01,885:INFO:         yellowbrick: 1.4
2022-10-21 12:33:01,885:INFO:              plotly: 5.5.0
2022-10-21 12:33:01,885:INFO:             kaleido: 0.2.1
2022-10-21 12:33:01,885:INFO:         statsmodels: 0.13.2
2022-10-21 12:33:01,885:INFO:              sktime: 0.13.4
2022-10-21 12:33:01,885:INFO:               tbats: 1.1.1
2022-10-21 12:33:01,886:INFO:            pmdarima: 1.8.5
2022-10-21 12:33:01,886:INFO:              psutil: 5.9.2
2022-10-21 12:33:01,886:INFO:PyCaret optional dependencies:
2022-10-21 12:33:01,886:INFO:                shap: 0.41.0
2022-10-21 12:33:01,886:INFO:           interpret: Not installed
2022-10-21 12:33:01,886:INFO:                umap: Not installed
2022-10-21 12:33:01,886:INFO:    pandas_profiling: Not installed
2022-10-21 12:33:01,886:INFO:  explainerdashboard: Not installed
2022-10-21 12:33:01,886:INFO:             autoviz: Not installed
2022-10-21 12:33:01,886:INFO:           fairlearn: Not installed
2022-10-21 12:33:01,886:INFO:             xgboost: Not installed
2022-10-21 12:33:01,887:INFO:            catboost: 1.1
2022-10-21 12:33:01,887:INFO:              kmodes: Not installed
2022-10-21 12:33:01,887:INFO:             mlxtend: Not installed
2022-10-21 12:33:01,887:INFO:       statsforecast: 1.1.1
2022-10-21 12:33:01,887:INFO:        tune_sklearn: Not installed
2022-10-21 12:33:01,887:INFO:                 ray: Not installed
2022-10-21 12:33:01,887:INFO:            hyperopt: Not installed
2022-10-21 12:33:01,887:INFO:              optuna: Not installed
2022-10-21 12:33:01,887:INFO:               skopt: Not installed
2022-10-21 12:33:01,887:INFO:              mlflow: 1.29.0
2022-10-21 12:33:01,887:INFO:              gradio: Not installed
2022-10-21 12:33:01,887:INFO:             fastapi: Not installed
2022-10-21 12:33:01,887:INFO:             uvicorn: Not installed
2022-10-21 12:33:01,887:INFO:              m2cgen: Not installed
2022-10-21 12:33:01,887:INFO:           evidently: Not installed
2022-10-21 12:33:01,887:INFO:                nltk: 3.6.5
2022-10-21 12:33:01,888:INFO:            pyLDAvis: Not installed
2022-10-21 12:33:01,888:INFO:              gensim: Not installed
2022-10-21 12:33:01,888:INFO:               spacy: Not installed
2022-10-21 12:33:01,888:INFO:           wordcloud: Not installed
2022-10-21 12:33:01,888:INFO:            textblob: Not installed
2022-10-21 12:33:01,888:INFO:               fugue: Not installed
2022-10-21 12:33:01,888:INFO:           streamlit: Not installed
2022-10-21 12:33:01,888:INFO:             prophet: 1.1.1
2022-10-21 12:33:01,888:INFO:None
2022-10-21 12:33:01,888:INFO:Set up data.
2022-10-21 12:33:01,899:INFO:Set up train/test split.
2022-10-21 12:33:01,910:INFO:Set up index.
2022-10-21 12:33:01,911:INFO:Set up folding strategy.
2022-10-21 12:33:01,911:INFO:Assigning column types.
2022-10-21 12:33:01,919:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:33:01,920:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:33:01,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:33:01,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:33:02,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:33:02,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:33:02,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:33:47,247:INFO:PyCaret RegressionExperiment
2022-10-21 12:33:47,247:INFO:Logging name: reg-default-name
2022-10-21 12:33:47,247:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:33:47,248:INFO:version 3.0.0.rc4
2022-10-21 12:33:47,248:INFO:Initializing setup()
2022-10-21 12:33:47,248:INFO:self.USI: f11e
2022-10-21 12:33:47,248:INFO:self.variable_keys: {'variable_keys', '_available_plots', 'n_jobs_param', 'y_test', 'fold_generator', 'transform_target_method_param', 'log_plots_param', 'idx', '_gpu_n_jobs_param', 'pipeline', 'y_train', 'transform_target_param', 'USI', 'fold_shuffle_param', 'X_train', '_all_models', 'html_param', 'logging_param', 'memory', 'y', 'X_test', 'seed', '_all_models_internal', 'X', 'exp_name_log', 'master_model_container', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_param', 'data', '_all_metrics', 'display_container', '_ml_usecase'}
2022-10-21 12:33:47,248:INFO:Checking environment
2022-10-21 12:33:47,248:INFO:python_version: 3.9.7
2022-10-21 12:33:47,248:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:33:47,248:INFO:machine: x86_64
2022-10-21 12:33:47,248:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:33:47,248:INFO:Memory: svmem(total=8589934592, available=2398851072, percent=72.1, used=4230324224, free=55967744, active=2348007424, inactive=2337087488, wired=1882316800)
2022-10-21 12:33:47,249:INFO:Physical Core: 2
2022-10-21 12:33:47,249:INFO:Logical Core: 4
2022-10-21 12:33:47,249:INFO:Checking libraries
2022-10-21 12:33:47,249:INFO:System:
2022-10-21 12:33:47,249:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:33:47,249:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:33:47,249:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:33:47,249:INFO:PyCaret required dependencies:
2022-10-21 12:33:47,249:INFO:                 pip: 21.2.4
2022-10-21 12:33:47,249:INFO:          setuptools: 58.0.4
2022-10-21 12:33:47,250:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:33:47,250:INFO:             IPython: 7.29.0
2022-10-21 12:33:47,250:INFO:          ipywidgets: 7.6.5
2022-10-21 12:33:47,250:INFO:                tqdm: 4.62.3
2022-10-21 12:33:47,250:INFO:               numpy: 1.22.4
2022-10-21 12:33:47,250:INFO:              pandas: 1.4.4
2022-10-21 12:33:47,250:INFO:              jinja2: 3.1.2
2022-10-21 12:33:47,250:INFO:               scipy: 1.8.1
2022-10-21 12:33:47,250:INFO:              joblib: 1.1.0
2022-10-21 12:33:47,251:INFO:             sklearn: 1.0.2
2022-10-21 12:33:47,251:INFO:                pyod: 1.0.5
2022-10-21 12:33:47,251:INFO:            imblearn: 0.9.0
2022-10-21 12:33:47,251:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:33:47,251:INFO:            lightgbm: 3.3.2
2022-10-21 12:33:47,251:INFO:               numba: 0.55.2
2022-10-21 12:33:47,251:INFO:            requests: 2.28.1
2022-10-21 12:33:47,252:INFO:          matplotlib: 3.4.3
2022-10-21 12:33:47,252:INFO:          scikitplot: 0.3.7
2022-10-21 12:33:47,252:INFO:         yellowbrick: 1.4
2022-10-21 12:33:47,252:INFO:              plotly: 5.5.0
2022-10-21 12:33:47,252:INFO:             kaleido: 0.2.1
2022-10-21 12:33:47,253:INFO:         statsmodels: 0.13.2
2022-10-21 12:33:47,253:INFO:              sktime: 0.13.4
2022-10-21 12:33:47,253:INFO:               tbats: 1.1.1
2022-10-21 12:33:47,253:INFO:            pmdarima: 1.8.5
2022-10-21 12:33:47,255:INFO:              psutil: 5.9.2
2022-10-21 12:33:47,255:INFO:PyCaret optional dependencies:
2022-10-21 12:33:47,255:INFO:                shap: 0.41.0
2022-10-21 12:33:47,256:INFO:           interpret: Not installed
2022-10-21 12:33:47,256:INFO:                umap: Not installed
2022-10-21 12:33:47,256:INFO:    pandas_profiling: Not installed
2022-10-21 12:33:47,256:INFO:  explainerdashboard: Not installed
2022-10-21 12:33:47,256:INFO:             autoviz: Not installed
2022-10-21 12:33:47,256:INFO:           fairlearn: Not installed
2022-10-21 12:33:47,256:INFO:             xgboost: Not installed
2022-10-21 12:33:47,256:INFO:            catboost: 1.1
2022-10-21 12:33:47,256:INFO:              kmodes: Not installed
2022-10-21 12:33:47,256:INFO:             mlxtend: Not installed
2022-10-21 12:33:47,256:INFO:       statsforecast: 1.1.1
2022-10-21 12:33:47,256:INFO:        tune_sklearn: Not installed
2022-10-21 12:33:47,256:INFO:                 ray: Not installed
2022-10-21 12:33:47,256:INFO:            hyperopt: Not installed
2022-10-21 12:33:47,256:INFO:              optuna: Not installed
2022-10-21 12:33:47,256:INFO:               skopt: Not installed
2022-10-21 12:33:47,257:INFO:              mlflow: 1.29.0
2022-10-21 12:33:47,257:INFO:              gradio: Not installed
2022-10-21 12:33:47,257:INFO:             fastapi: Not installed
2022-10-21 12:33:47,257:INFO:             uvicorn: Not installed
2022-10-21 12:33:47,257:INFO:              m2cgen: Not installed
2022-10-21 12:33:47,257:INFO:           evidently: Not installed
2022-10-21 12:33:47,257:INFO:                nltk: 3.6.5
2022-10-21 12:33:47,257:INFO:            pyLDAvis: Not installed
2022-10-21 12:33:47,257:INFO:              gensim: Not installed
2022-10-21 12:33:47,257:INFO:               spacy: Not installed
2022-10-21 12:33:47,257:INFO:           wordcloud: Not installed
2022-10-21 12:33:47,257:INFO:            textblob: Not installed
2022-10-21 12:33:47,258:INFO:               fugue: Not installed
2022-10-21 12:33:47,258:INFO:           streamlit: Not installed
2022-10-21 12:33:47,259:INFO:             prophet: 1.1.1
2022-10-21 12:33:47,259:INFO:None
2022-10-21 12:33:47,259:INFO:Set up data.
2022-10-21 12:33:47,277:INFO:Set up train/test split.
2022-10-21 12:33:47,291:INFO:Set up index.
2022-10-21 12:33:47,293:INFO:Set up folding strategy.
2022-10-21 12:33:47,293:INFO:Assigning column types.
2022-10-21 12:33:47,321:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:33:47,322:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:33:47,352:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:33:47,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:33:47,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:33:48,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:33:48,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:38:06,441:INFO:PyCaret RegressionExperiment
2022-10-21 12:38:06,442:INFO:Logging name: reg-default-name
2022-10-21 12:38:06,442:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:38:06,442:INFO:version 3.0.0.rc4
2022-10-21 12:38:06,442:INFO:Initializing setup()
2022-10-21 12:38:06,442:INFO:self.USI: 7bdc
2022-10-21 12:38:06,442:INFO:self.variable_keys: {'variable_keys', '_available_plots', 'n_jobs_param', 'y_test', 'fold_generator', 'transform_target_method_param', 'log_plots_param', 'idx', '_gpu_n_jobs_param', 'pipeline', 'y_train', 'transform_target_param', 'USI', 'fold_shuffle_param', 'X_train', '_all_models', 'html_param', 'logging_param', 'memory', 'y', 'X_test', 'seed', '_all_models_internal', 'X', 'exp_name_log', 'master_model_container', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_param', 'data', '_all_metrics', 'display_container', '_ml_usecase'}
2022-10-21 12:38:06,442:INFO:Checking environment
2022-10-21 12:38:06,442:INFO:python_version: 3.9.7
2022-10-21 12:38:06,442:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:38:06,442:INFO:machine: x86_64
2022-10-21 12:38:06,442:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:38:06,443:INFO:Memory: svmem(total=8589934592, available=2296901632, percent=73.3, used=4165808128, free=14921728, active=2284019712, inactive=2280251392, wired=1881788416)
2022-10-21 12:38:06,443:INFO:Physical Core: 2
2022-10-21 12:38:06,443:INFO:Logical Core: 4
2022-10-21 12:38:06,443:INFO:Checking libraries
2022-10-21 12:38:06,453:INFO:System:
2022-10-21 12:38:06,453:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:38:06,453:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:38:06,454:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:38:06,454:INFO:PyCaret required dependencies:
2022-10-21 12:38:06,454:INFO:                 pip: 21.2.4
2022-10-21 12:38:06,454:INFO:          setuptools: 58.0.4
2022-10-21 12:38:06,454:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:38:06,454:INFO:             IPython: 7.29.0
2022-10-21 12:38:06,454:INFO:          ipywidgets: 7.6.5
2022-10-21 12:38:06,454:INFO:                tqdm: 4.62.3
2022-10-21 12:38:06,454:INFO:               numpy: 1.22.4
2022-10-21 12:38:06,454:INFO:              pandas: 1.4.4
2022-10-21 12:38:06,454:INFO:              jinja2: 3.1.2
2022-10-21 12:38:06,454:INFO:               scipy: 1.8.1
2022-10-21 12:38:06,454:INFO:              joblib: 1.1.0
2022-10-21 12:38:06,454:INFO:             sklearn: 1.0.2
2022-10-21 12:38:06,454:INFO:                pyod: 1.0.5
2022-10-21 12:38:06,454:INFO:            imblearn: 0.9.0
2022-10-21 12:38:06,454:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:38:06,455:INFO:            lightgbm: 3.3.2
2022-10-21 12:38:06,455:INFO:               numba: 0.55.2
2022-10-21 12:38:06,455:INFO:            requests: 2.28.1
2022-10-21 12:38:06,455:INFO:          matplotlib: 3.4.3
2022-10-21 12:38:06,455:INFO:          scikitplot: 0.3.7
2022-10-21 12:38:06,455:INFO:         yellowbrick: 1.4
2022-10-21 12:38:06,455:INFO:              plotly: 5.5.0
2022-10-21 12:38:06,455:INFO:             kaleido: 0.2.1
2022-10-21 12:38:06,455:INFO:         statsmodels: 0.13.2
2022-10-21 12:38:06,455:INFO:              sktime: 0.13.4
2022-10-21 12:38:06,455:INFO:               tbats: 1.1.1
2022-10-21 12:38:06,455:INFO:            pmdarima: 1.8.5
2022-10-21 12:38:06,455:INFO:              psutil: 5.9.2
2022-10-21 12:38:06,455:INFO:PyCaret optional dependencies:
2022-10-21 12:38:06,455:INFO:                shap: 0.41.0
2022-10-21 12:38:06,455:INFO:           interpret: Not installed
2022-10-21 12:38:06,455:INFO:                umap: Not installed
2022-10-21 12:38:06,455:INFO:    pandas_profiling: Not installed
2022-10-21 12:38:06,455:INFO:  explainerdashboard: Not installed
2022-10-21 12:38:06,456:INFO:             autoviz: Not installed
2022-10-21 12:38:06,456:INFO:           fairlearn: Not installed
2022-10-21 12:38:06,456:INFO:             xgboost: Not installed
2022-10-21 12:38:06,456:INFO:            catboost: 1.1
2022-10-21 12:38:06,456:INFO:              kmodes: Not installed
2022-10-21 12:38:06,456:INFO:             mlxtend: Not installed
2022-10-21 12:38:06,456:INFO:       statsforecast: 1.1.1
2022-10-21 12:38:06,456:INFO:        tune_sklearn: Not installed
2022-10-21 12:38:06,456:INFO:                 ray: Not installed
2022-10-21 12:38:06,456:INFO:            hyperopt: Not installed
2022-10-21 12:38:06,456:INFO:              optuna: Not installed
2022-10-21 12:38:06,456:INFO:               skopt: Not installed
2022-10-21 12:38:06,456:INFO:              mlflow: 1.29.0
2022-10-21 12:38:06,456:INFO:              gradio: Not installed
2022-10-21 12:38:06,456:INFO:             fastapi: Not installed
2022-10-21 12:38:06,456:INFO:             uvicorn: Not installed
2022-10-21 12:38:06,456:INFO:              m2cgen: Not installed
2022-10-21 12:38:06,456:INFO:           evidently: Not installed
2022-10-21 12:38:06,456:INFO:                nltk: 3.6.5
2022-10-21 12:38:06,456:INFO:            pyLDAvis: Not installed
2022-10-21 12:38:06,457:INFO:              gensim: Not installed
2022-10-21 12:38:06,457:INFO:               spacy: Not installed
2022-10-21 12:38:06,457:INFO:           wordcloud: Not installed
2022-10-21 12:38:06,457:INFO:            textblob: Not installed
2022-10-21 12:38:06,457:INFO:               fugue: Not installed
2022-10-21 12:38:06,457:INFO:           streamlit: Not installed
2022-10-21 12:38:06,457:INFO:             prophet: 1.1.1
2022-10-21 12:38:06,457:INFO:None
2022-10-21 12:38:06,457:INFO:Set up data.
2022-10-21 12:38:06,471:INFO:Set up train/test split.
2022-10-21 12:38:06,486:INFO:Set up index.
2022-10-21 12:38:06,487:INFO:Set up folding strategy.
2022-10-21 12:38:06,487:INFO:Assigning column types.
2022-10-21 12:38:06,502:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:38:06,502:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:38:06,515:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:38:06,525:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:38:06,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:38:07,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:38:07,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 12:45:36,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:45:36,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:45:36,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:45:36,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 12:45:38,796:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 12:45:39,778:INFO:PyCaret RegressionExperiment
2022-10-21 12:45:39,779:INFO:Logging name: reg-default-name
2022-10-21 12:45:39,779:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 12:45:39,779:INFO:version 3.0.0.rc4
2022-10-21 12:45:39,779:INFO:Initializing setup()
2022-10-21 12:45:39,779:INFO:self.USI: b1b3
2022-10-21 12:45:39,779:INFO:self.variable_keys: {'X_train', 'n_jobs_param', 'seed', '_available_plots', 'html_param', 'fold_generator', '_all_models_internal', 'X_test', 'fold_groups_param', 'gpu_param', 'fold_shuffle_param', '_all_models', 'exp_id', '_gpu_n_jobs_param', 'data', 'X', 'log_plots_param', 'y_test', 'exp_name_log', '_ml_usecase', 'USI', 'transform_target_param', 'y_train', 'variable_keys', '_all_metrics', 'pipeline', 'y', 'idx', 'target_param', 'master_model_container', 'memory', 'display_container', 'logging_param', 'transform_target_method_param'}
2022-10-21 12:45:39,779:INFO:Checking environment
2022-10-21 12:45:39,779:INFO:python_version: 3.9.7
2022-10-21 12:45:39,779:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 12:45:39,779:INFO:machine: x86_64
2022-10-21 12:45:39,779:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:45:39,779:INFO:Memory: svmem(total=8589934592, available=2234859520, percent=74.0, used=4077637632, free=17285120, active=2219188224, inactive=2195013632, wired=1858449408)
2022-10-21 12:45:39,779:INFO:Physical Core: 2
2022-10-21 12:45:39,779:INFO:Logical Core: 4
2022-10-21 12:45:39,779:INFO:Checking libraries
2022-10-21 12:45:39,780:INFO:System:
2022-10-21 12:45:39,780:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 12:45:39,780:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 12:45:39,780:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 12:45:39,780:INFO:PyCaret required dependencies:
2022-10-21 12:45:39,780:INFO:                 pip: 21.2.4
2022-10-21 12:45:39,780:INFO:          setuptools: 58.0.4
2022-10-21 12:45:39,780:INFO:             pycaret: 3.0.0rc4
2022-10-21 12:45:39,780:INFO:             IPython: 7.29.0
2022-10-21 12:45:39,780:INFO:          ipywidgets: 7.6.5
2022-10-21 12:45:39,780:INFO:                tqdm: 4.62.3
2022-10-21 12:45:39,781:INFO:               numpy: 1.22.4
2022-10-21 12:45:39,781:INFO:              pandas: 1.4.4
2022-10-21 12:45:39,781:INFO:              jinja2: 3.1.2
2022-10-21 12:45:39,781:INFO:               scipy: 1.8.1
2022-10-21 12:45:39,781:INFO:              joblib: 1.1.0
2022-10-21 12:45:39,781:INFO:             sklearn: 1.0.2
2022-10-21 12:45:39,781:INFO:                pyod: 1.0.5
2022-10-21 12:45:39,781:INFO:            imblearn: 0.9.0
2022-10-21 12:45:39,782:INFO:   category_encoders: 2.5.1.post0
2022-10-21 12:45:39,782:INFO:            lightgbm: 3.3.2
2022-10-21 12:45:39,782:INFO:               numba: 0.55.2
2022-10-21 12:45:39,782:INFO:            requests: 2.28.1
2022-10-21 12:45:39,782:INFO:          matplotlib: 3.4.3
2022-10-21 12:45:39,782:INFO:          scikitplot: 0.3.7
2022-10-21 12:45:39,782:INFO:         yellowbrick: 1.4
2022-10-21 12:45:39,782:INFO:              plotly: 5.5.0
2022-10-21 12:45:39,782:INFO:             kaleido: 0.2.1
2022-10-21 12:45:39,782:INFO:         statsmodels: 0.13.2
2022-10-21 12:45:39,783:INFO:              sktime: 0.13.4
2022-10-21 12:45:39,783:INFO:               tbats: 1.1.1
2022-10-21 12:45:39,783:INFO:            pmdarima: 1.8.5
2022-10-21 12:45:39,783:INFO:              psutil: 5.9.2
2022-10-21 12:45:39,783:INFO:PyCaret optional dependencies:
2022-10-21 12:45:39,789:INFO:                shap: 0.41.0
2022-10-21 12:45:39,789:INFO:           interpret: Not installed
2022-10-21 12:45:39,789:INFO:                umap: Not installed
2022-10-21 12:45:39,789:INFO:    pandas_profiling: Not installed
2022-10-21 12:45:39,789:INFO:  explainerdashboard: Not installed
2022-10-21 12:45:39,789:INFO:             autoviz: Not installed
2022-10-21 12:45:39,790:INFO:           fairlearn: Not installed
2022-10-21 12:45:39,790:INFO:             xgboost: Not installed
2022-10-21 12:45:39,790:INFO:            catboost: 1.1
2022-10-21 12:45:39,790:INFO:              kmodes: Not installed
2022-10-21 12:45:39,790:INFO:             mlxtend: Not installed
2022-10-21 12:45:39,790:INFO:       statsforecast: 1.1.1
2022-10-21 12:45:39,790:INFO:        tune_sklearn: Not installed
2022-10-21 12:45:39,791:INFO:                 ray: Not installed
2022-10-21 12:45:39,791:INFO:            hyperopt: Not installed
2022-10-21 12:45:39,791:INFO:              optuna: Not installed
2022-10-21 12:45:39,791:INFO:               skopt: Not installed
2022-10-21 12:45:39,791:INFO:              mlflow: 1.29.0
2022-10-21 12:45:39,791:INFO:              gradio: Not installed
2022-10-21 12:45:39,791:INFO:             fastapi: Not installed
2022-10-21 12:45:39,791:INFO:             uvicorn: Not installed
2022-10-21 12:45:39,791:INFO:              m2cgen: Not installed
2022-10-21 12:45:39,791:INFO:           evidently: Not installed
2022-10-21 12:45:39,791:INFO:                nltk: 3.6.5
2022-10-21 12:45:39,791:INFO:            pyLDAvis: Not installed
2022-10-21 12:45:39,791:INFO:              gensim: Not installed
2022-10-21 12:45:39,791:INFO:               spacy: Not installed
2022-10-21 12:45:39,791:INFO:           wordcloud: Not installed
2022-10-21 12:45:39,791:INFO:            textblob: Not installed
2022-10-21 12:45:39,791:INFO:               fugue: Not installed
2022-10-21 12:45:39,791:INFO:           streamlit: Not installed
2022-10-21 12:45:39,791:INFO:             prophet: 1.1.1
2022-10-21 12:45:39,791:INFO:None
2022-10-21 12:45:39,792:INFO:Set up data.
2022-10-21 12:45:39,801:INFO:Set up train/test split.
2022-10-21 12:45:39,808:INFO:Set up index.
2022-10-21 12:45:39,808:INFO:Set up folding strategy.
2022-10-21 12:45:39,808:INFO:Assigning column types.
2022-10-21 12:45:39,813:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 12:45:39,813:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 12:45:39,823:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 12:45:39,830:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 12:45:39,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 12:45:40,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 12:45:40,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:38,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:09:38,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:09:38,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:09:38,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:09:41,243:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:09:41,885:INFO:PyCaret RegressionExperiment
2022-10-21 13:09:41,885:INFO:Logging name: reg-default-name
2022-10-21 13:09:41,885:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 13:09:41,886:INFO:version 3.0.0.rc4
2022-10-21 13:09:41,886:INFO:Initializing setup()
2022-10-21 13:09:41,886:INFO:self.USI: fca3
2022-10-21 13:09:41,886:INFO:self.variable_keys: {'display_container', '_ml_usecase', 'seed', 'USI', 'target_param', 'fold_groups_param', 'X_test', 'master_model_container', 'y_train', 'y_test', 'idx', 'pipeline', '_all_metrics', 'X', 'exp_name_log', '_available_plots', 'transform_target_method_param', 'transform_target_param', 'fold_generator', 'n_jobs_param', 'memory', 'variable_keys', '_gpu_n_jobs_param', '_all_models', 'html_param', 'gpu_param', 'X_train', 'fold_shuffle_param', 'exp_id', '_all_models_internal', 'log_plots_param', 'logging_param', 'data', 'y'}
2022-10-21 13:09:41,886:INFO:Checking environment
2022-10-21 13:09:41,886:INFO:python_version: 3.9.7
2022-10-21 13:09:41,886:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 13:09:41,886:INFO:machine: x86_64
2022-10-21 13:09:41,886:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 13:09:41,886:INFO:Memory: svmem(total=8589934592, available=2390249472, percent=72.2, used=4211392512, free=17530880, active=2374217728, inactive=2332016640, wired=1837174784)
2022-10-21 13:09:41,886:INFO:Physical Core: 2
2022-10-21 13:09:41,887:INFO:Logical Core: 4
2022-10-21 13:09:41,887:INFO:Checking libraries
2022-10-21 13:09:41,887:INFO:System:
2022-10-21 13:09:41,887:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 13:09:41,887:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 13:09:41,887:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 13:09:41,887:INFO:PyCaret required dependencies:
2022-10-21 13:09:41,887:INFO:                 pip: 21.2.4
2022-10-21 13:09:41,887:INFO:          setuptools: 58.0.4
2022-10-21 13:09:41,887:INFO:             pycaret: 3.0.0rc4
2022-10-21 13:09:41,887:INFO:             IPython: 7.29.0
2022-10-21 13:09:41,887:INFO:          ipywidgets: 7.6.5
2022-10-21 13:09:41,888:INFO:                tqdm: 4.62.3
2022-10-21 13:09:41,888:INFO:               numpy: 1.22.4
2022-10-21 13:09:41,888:INFO:              pandas: 1.4.4
2022-10-21 13:09:41,888:INFO:              jinja2: 3.1.2
2022-10-21 13:09:41,888:INFO:               scipy: 1.8.1
2022-10-21 13:09:41,888:INFO:              joblib: 1.1.0
2022-10-21 13:09:41,888:INFO:             sklearn: 1.0.2
2022-10-21 13:09:41,888:INFO:                pyod: 1.0.5
2022-10-21 13:09:41,888:INFO:            imblearn: 0.9.0
2022-10-21 13:09:41,888:INFO:   category_encoders: 2.5.1.post0
2022-10-21 13:09:41,888:INFO:            lightgbm: 3.3.2
2022-10-21 13:09:41,888:INFO:               numba: 0.55.2
2022-10-21 13:09:41,888:INFO:            requests: 2.28.1
2022-10-21 13:09:41,888:INFO:          matplotlib: 3.4.3
2022-10-21 13:09:41,888:INFO:          scikitplot: 0.3.7
2022-10-21 13:09:41,888:INFO:         yellowbrick: 1.4
2022-10-21 13:09:41,888:INFO:              plotly: 5.5.0
2022-10-21 13:09:41,888:INFO:             kaleido: 0.2.1
2022-10-21 13:09:41,888:INFO:         statsmodels: 0.13.2
2022-10-21 13:09:41,888:INFO:              sktime: 0.13.4
2022-10-21 13:09:41,889:INFO:               tbats: 1.1.1
2022-10-21 13:09:41,889:INFO:            pmdarima: 1.8.5
2022-10-21 13:09:41,889:INFO:              psutil: 5.9.2
2022-10-21 13:09:41,889:INFO:PyCaret optional dependencies:
2022-10-21 13:09:41,903:INFO:                shap: 0.41.0
2022-10-21 13:09:41,903:INFO:           interpret: Not installed
2022-10-21 13:09:41,903:INFO:                umap: Not installed
2022-10-21 13:09:41,903:INFO:    pandas_profiling: Not installed
2022-10-21 13:09:41,903:INFO:  explainerdashboard: Not installed
2022-10-21 13:09:41,904:INFO:             autoviz: Not installed
2022-10-21 13:09:41,904:INFO:           fairlearn: Not installed
2022-10-21 13:09:41,904:INFO:             xgboost: Not installed
2022-10-21 13:09:41,904:INFO:            catboost: 1.1
2022-10-21 13:09:41,904:INFO:              kmodes: Not installed
2022-10-21 13:09:41,904:INFO:             mlxtend: Not installed
2022-10-21 13:09:41,904:INFO:       statsforecast: 1.1.1
2022-10-21 13:09:41,904:INFO:        tune_sklearn: Not installed
2022-10-21 13:09:41,904:INFO:                 ray: Not installed
2022-10-21 13:09:41,904:INFO:            hyperopt: Not installed
2022-10-21 13:09:41,904:INFO:              optuna: Not installed
2022-10-21 13:09:41,904:INFO:               skopt: Not installed
2022-10-21 13:09:41,904:INFO:              mlflow: 1.29.0
2022-10-21 13:09:41,904:INFO:              gradio: Not installed
2022-10-21 13:09:41,904:INFO:             fastapi: Not installed
2022-10-21 13:09:41,904:INFO:             uvicorn: Not installed
2022-10-21 13:09:41,904:INFO:              m2cgen: Not installed
2022-10-21 13:09:41,904:INFO:           evidently: Not installed
2022-10-21 13:09:41,905:INFO:                nltk: 3.6.5
2022-10-21 13:09:41,905:INFO:            pyLDAvis: Not installed
2022-10-21 13:09:41,905:INFO:              gensim: Not installed
2022-10-21 13:09:41,905:INFO:               spacy: Not installed
2022-10-21 13:09:41,905:INFO:           wordcloud: Not installed
2022-10-21 13:09:41,905:INFO:            textblob: Not installed
2022-10-21 13:09:41,905:INFO:               fugue: Not installed
2022-10-21 13:09:41,905:INFO:           streamlit: Not installed
2022-10-21 13:09:41,905:INFO:             prophet: 1.1.1
2022-10-21 13:09:41,905:INFO:None
2022-10-21 13:09:41,905:INFO:Set up data.
2022-10-21 13:09:41,919:INFO:Set up train/test split.
2022-10-21 13:09:41,930:INFO:Set up index.
2022-10-21 13:09:41,931:INFO:Set up folding strategy.
2022-10-21 13:09:41,931:INFO:Assigning column types.
2022-10-21 13:09:41,937:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 13:09:41,938:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 13:09:41,954:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:09:41,964:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:42,343:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:42,476:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,484:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,492:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,617:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:42,699:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:42,701:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-10-21 13:09:42,710:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,718:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:09:42,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:43,006:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:43,018:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:43,251:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:43,253:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-10-21 13:09:43,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:43,534:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:43,563:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:43,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:43,805:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:43,806:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-10-21 13:09:44,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:44,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:44,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:44,138:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:44,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:44,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:09:44,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:44,405:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:44,409:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-10-21 13:09:44,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:44,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:44,679:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:44,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:09:44,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:44,983:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:44,984:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-10-21 13:09:45,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:45,266:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:45,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:45,589:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:45,594:INFO:Preparing preprocessing pipeline...
2022-10-21 13:09:45,595:INFO:Set up simple imputation.
2022-10-21 13:09:45,605:INFO:Set up encoding of ordinal features.
2022-10-21 13:09:45,611:INFO:Set up encoding of categorical features.
2022-10-21 13:09:45,612:INFO:Set up polynomial features.
2022-10-21 13:09:45,612:INFO:Set up variance threshold.
2022-10-21 13:09:45,612:INFO:Set up feature normalization.
2022-10-21 13:09:46,121:INFO:Finished creating preprocessing pipeline.
2022-10-21 13:09:46,157:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2022-10-21 13:09:46,157:INFO:Creating final display dataframe.
2022-10-21 13:09:47,600:INFO:Setup display_container:                  Description             Value
0                 Session id               122
1                     Target           charges
2                Target type        Regression
3                 Data shape        (1338, 49)
4           Train data shape         (936, 49)
5            Test data shape         (402, 49)
6           Ordinal features                 2
7           Numeric features                 3
8       Categorical features                 3
9                 Preprocess              True
10           Imputation type            simple
11        Numeric imputation              mean
12    Categorical imputation          constant
13  Maximum one-hot encoding                 5
14           Encoding method              None
15       Polynomial features              True
16         Polynomial degree                 2
17    Low variance threshold                 0
18                 Normalize              True
19          Normalize method            zscore
20            Fold Generator             KFold
21               Fold Number                10
22                  CPU Jobs                -1
23                   Use GPU             False
24            Log Experiment             False
25           Experiment Name  reg-default-name
26                       USI              fca3
2022-10-21 13:09:48,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:48,155:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:48,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:09:48,420:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:09:48,437:INFO:setup() successfully completed in 6.56s...............
2022-10-21 13:09:48,438:INFO:Initializing compare_models()
2022-10-21 13:09:48,438:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-10-21 13:09:48,438:INFO:Checking exceptions
2022-10-21 13:09:48,444:INFO:Preparing display monitor
2022-10-21 13:09:48,911:INFO:Initializing Linear Regression
2022-10-21 13:09:48,911:INFO:Total runtime is 1.0232130686442057e-05 minutes
2022-10-21 13:09:48,919:INFO:SubProcess create_model() called ==================================
2022-10-21 13:09:48,926:INFO:Initializing create_model()
2022-10-21 13:09:48,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:09:48,926:INFO:Checking exceptions
2022-10-21 13:09:48,949:INFO:Importing libraries
2022-10-21 13:09:48,950:INFO:Copying training dataset
2022-10-21 13:09:48,956:INFO:Defining folds
2022-10-21 13:09:48,957:INFO:Declaring metric variables
2022-10-21 13:09:48,978:INFO:Importing untrained model
2022-10-21 13:09:49,002:INFO:Linear Regression Imported successfully
2022-10-21 13:09:49,069:INFO:Starting cross validation
2022-10-21 13:09:49,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:10,350:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:10,353:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:10,356:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:10,430:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:11,971:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:12,039:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:12,047:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:12,104:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:14,092:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:14,169:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:14,202:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:14,220:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:15,711:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:15,788:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:15,837:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:15,870:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:17,227:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:17,307:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:18,310:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:18,372:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

2022-10-21 13:10:18,893:INFO:Calculating mean and std
2022-10-21 13:10:18,901:INFO:Creating metrics dataframe
2022-10-21 13:10:18,913:INFO:Uploading results into container
2022-10-21 13:10:18,914:INFO:Uploading model into container now
2022-10-21 13:10:18,916:INFO:master_model_container: 1
2022-10-21 13:10:18,916:INFO:display_container: 2
2022-10-21 13:10:18,917:INFO:LinearRegression(n_jobs=-1)
2022-10-21 13:10:18,917:INFO:create_model() successfully completed......................................
2022-10-21 13:10:19,158:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:19,159:INFO:Creating metrics dataframe
2022-10-21 13:10:19,181:INFO:Initializing Lasso Regression
2022-10-21 13:10:19,181:INFO:Total runtime is 0.5045008818308512 minutes
2022-10-21 13:10:19,190:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:19,205:INFO:Initializing create_model()
2022-10-21 13:10:19,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:19,206:INFO:Checking exceptions
2022-10-21 13:10:19,210:INFO:Importing libraries
2022-10-21 13:10:19,210:INFO:Copying training dataset
2022-10-21 13:10:19,221:INFO:Defining folds
2022-10-21 13:10:19,222:INFO:Declaring metric variables
2022-10-21 13:10:19,316:INFO:Importing untrained model
2022-10-21 13:10:19,370:INFO:Lasso Regression Imported successfully
2022-10-21 13:10:19,472:INFO:Starting cross validation
2022-10-21 13:10:19,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:19,853:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e+09, tolerance: 1.200e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:19,865:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+09, tolerance: 1.211e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:19,874:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.925e+09, tolerance: 1.201e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:19,877:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.057e+09, tolerance: 1.200e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:20,481:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.622e+09, tolerance: 1.201e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:20,598:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e+09, tolerance: 1.242e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:20,600:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.006e+09, tolerance: 1.207e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:20,603:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.374e+09, tolerance: 1.231e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:21,062:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.154e+09, tolerance: 1.240e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:21,094:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.479e+09, tolerance: 1.261e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:10:21,281:INFO:Calculating mean and std
2022-10-21 13:10:21,283:INFO:Creating metrics dataframe
2022-10-21 13:10:21,289:INFO:Uploading results into container
2022-10-21 13:10:21,290:INFO:Uploading model into container now
2022-10-21 13:10:21,291:INFO:master_model_container: 2
2022-10-21 13:10:21,292:INFO:display_container: 2
2022-10-21 13:10:21,292:INFO:Lasso(random_state=122)
2022-10-21 13:10:21,293:INFO:create_model() successfully completed......................................
2022-10-21 13:10:21,479:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:21,480:INFO:Creating metrics dataframe
2022-10-21 13:10:21,505:INFO:Initializing Ridge Regression
2022-10-21 13:10:21,506:INFO:Total runtime is 0.5432479302088419 minutes
2022-10-21 13:10:21,544:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:21,547:INFO:Initializing create_model()
2022-10-21 13:10:21,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:21,549:INFO:Checking exceptions
2022-10-21 13:10:21,555:INFO:Importing libraries
2022-10-21 13:10:21,555:INFO:Copying training dataset
2022-10-21 13:10:21,606:INFO:Defining folds
2022-10-21 13:10:21,606:INFO:Declaring metric variables
2022-10-21 13:10:21,633:INFO:Importing untrained model
2022-10-21 13:10:21,652:INFO:Ridge Regression Imported successfully
2022-10-21 13:10:21,683:INFO:Starting cross validation
2022-10-21 13:10:21,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:22,790:INFO:Calculating mean and std
2022-10-21 13:10:22,794:INFO:Creating metrics dataframe
2022-10-21 13:10:22,800:INFO:Uploading results into container
2022-10-21 13:10:22,802:INFO:Uploading model into container now
2022-10-21 13:10:22,803:INFO:master_model_container: 3
2022-10-21 13:10:22,803:INFO:display_container: 2
2022-10-21 13:10:22,804:INFO:Ridge(random_state=122)
2022-10-21 13:10:22,804:INFO:create_model() successfully completed......................................
2022-10-21 13:10:23,173:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:23,173:INFO:Creating metrics dataframe
2022-10-21 13:10:23,203:INFO:Initializing Elastic Net
2022-10-21 13:10:23,204:INFO:Total runtime is 0.5715490659077962 minutes
2022-10-21 13:10:23,241:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:23,242:INFO:Initializing create_model()
2022-10-21 13:10:23,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:23,247:INFO:Checking exceptions
2022-10-21 13:10:23,250:INFO:Importing libraries
2022-10-21 13:10:23,250:INFO:Copying training dataset
2022-10-21 13:10:23,307:INFO:Defining folds
2022-10-21 13:10:23,315:INFO:Declaring metric variables
2022-10-21 13:10:23,323:INFO:Importing untrained model
2022-10-21 13:10:23,361:INFO:Elastic Net Imported successfully
2022-10-21 13:10:23,382:INFO:Starting cross validation
2022-10-21 13:10:23,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:24,586:INFO:Calculating mean and std
2022-10-21 13:10:24,589:INFO:Creating metrics dataframe
2022-10-21 13:10:24,599:INFO:Uploading results into container
2022-10-21 13:10:24,600:INFO:Uploading model into container now
2022-10-21 13:10:24,600:INFO:master_model_container: 4
2022-10-21 13:10:24,601:INFO:display_container: 2
2022-10-21 13:10:24,601:INFO:ElasticNet(random_state=122)
2022-10-21 13:10:24,601:INFO:create_model() successfully completed......................................
2022-10-21 13:10:24,784:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:24,785:INFO:Creating metrics dataframe
2022-10-21 13:10:24,806:INFO:Initializing Least Angle Regression
2022-10-21 13:10:24,806:INFO:Total runtime is 0.5982555150985718 minutes
2022-10-21 13:10:24,853:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:24,867:INFO:Initializing create_model()
2022-10-21 13:10:24,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:24,868:INFO:Checking exceptions
2022-10-21 13:10:24,871:INFO:Importing libraries
2022-10-21 13:10:24,872:INFO:Copying training dataset
2022-10-21 13:10:24,887:INFO:Defining folds
2022-10-21 13:10:24,888:INFO:Declaring metric variables
2022-10-21 13:10:24,913:INFO:Importing untrained model
2022-10-21 13:10:24,932:INFO:Least Angle Regression Imported successfully
2022-10-21 13:10:24,964:INFO:Starting cross validation
2022-10-21 13:10:24,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:25,254:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,255:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,259:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,275:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.030e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,277:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.030e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,277:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.471e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,279:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.972e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,280:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.748e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,282:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.562e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,282:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.508e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,283:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.125e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,283:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.147e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,284:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.036e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,285:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.850e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,286:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.656e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,286:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.656e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,287:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.947e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,288:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.212e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,289:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.145e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,289:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.327e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,295:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.947e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,296:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.009e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,297:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.479e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,297:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.434e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,298:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.185e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,298:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.174e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,298:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.614e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,298:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.082e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,299:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.068e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,299:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.860e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,299:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.786e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,299:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.624e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,299:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.369e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,300:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.378e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,300:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.010e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,300:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.810e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,300:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.085e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.432e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.374e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.372e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.365e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,302:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.855e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,302:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.914e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,304:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.041e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,307:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.293e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,308:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.410e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,311:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.240e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,311:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.129e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,312:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.588e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,313:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.063e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,314:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.961e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,314:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.731e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,315:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.191e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,315:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.070e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,318:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.931e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,320:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.043e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,320:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.077e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,322:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.773e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,324:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.360e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,327:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.311e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,327:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.093e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,327:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.826e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,327:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.823e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,328:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.813e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,328:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.048e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,329:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.025e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,329:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.610e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,329:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.916e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,330:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.131e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,330:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.036e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,330:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.490e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,331:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.645e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,331:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.818e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,331:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.280e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,331:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.464e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,332:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.066e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,332:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.016e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,332:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.685e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,332:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.704e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,315:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.240e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,333:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.234e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,333:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.882e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,333:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.830e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,334:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.804e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,334:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.027e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,334:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.777e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,334:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.767e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,334:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.466e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,335:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.122e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,335:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.238e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,335:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.047e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,335:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.226e-05, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,335:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.803e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,336:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.358e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,336:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.797e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,352:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.613e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,353:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.457e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,354:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.230e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,355:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.201e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,356:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.097e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,358:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.900e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,358:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.487e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,359:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.190e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,369:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.083e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,372:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.947e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,373:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.916e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,373:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.242e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,374:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.885e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,375:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.199e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,387:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.452e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,389:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.315e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,389:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.193e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,389:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.107e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,390:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.009e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,390:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.216e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,390:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=7.358e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,392:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=5.358e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,392:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.531e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,392:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.110e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,393:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.848e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,393:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.691e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,394:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.652e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,396:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.078e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,396:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.859e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,397:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.687e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,397:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.232e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,397:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.232e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,738:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,747:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,749:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.858e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,752:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=7.049e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,754:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.988e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,756:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.607e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,756:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.607e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,757:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.266e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,760:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.106e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,760:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.106e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,761:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.211e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,762:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.655e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,763:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.345e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,764:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.008e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,765:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.855e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,765:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.806e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,765:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.526e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,766:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.473e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,766:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.326e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,766:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.145e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,767:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.114e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,768:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.143e+01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,769:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,770:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.846e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,770:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.432e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,771:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.170e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,771:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.130e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,771:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.100e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,772:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.807e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,775:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=6.280e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,778:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.156e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,779:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.225e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,779:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.825e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,779:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.330e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,780:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.183e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,781:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.940e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,781:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.193e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,781:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.571e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,781:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.398e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,782:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.862e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,782:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.091e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,783:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.979e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,785:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.665e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,787:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.175e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,788:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.478e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,788:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.199e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,788:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.388e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,789:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.169e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,789:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.714e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,789:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.624e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,790:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.577e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,790:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.163e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,790:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.850e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,794:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.139e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,794:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.566e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,794:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.557e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,794:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.643e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,795:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.618e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,795:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.436e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,795:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.192e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,795:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.199e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,799:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.855e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,801:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.908e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,802:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.908e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,779:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.811e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,806:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.379e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,806:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.507e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,806:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.282e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,807:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.490e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,807:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.486e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,812:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.475e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,813:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.444e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,813:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.426e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,816:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.043e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,819:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:25,822:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.600e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,823:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.572e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,823:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.472e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,823:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.047e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,824:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.187e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,825:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.933e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,828:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.570e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,829:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.730e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,825:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.931e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,832:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.014e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,832:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.152e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,832:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.613e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,833:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.138e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,833:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.482e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,833:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.696e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,834:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.981e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,834:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.736e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,834:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.148e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,842:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.191e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,845:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.055e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,849:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.438e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,849:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.428e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,850:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.427e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,850:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.405e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,850:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.145e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,852:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.599e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,852:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.575e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,854:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.996e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,854:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.038e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,855:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.957e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,855:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.007e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,855:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.974e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,856:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.490e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,856:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.958e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,856:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.886e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,857:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.022e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,857:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.015e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,860:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.754e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,861:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.214e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,862:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.077e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,862:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.533e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,862:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.494e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,863:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.387e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,863:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.365e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,863:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.274e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,864:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.489e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,864:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.993e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:25,865:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.922e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,107:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:26,132:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:26,139:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.852e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,140:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.136e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,143:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.666e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,144:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.666e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,144:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.249e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,145:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.507e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,148:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.078e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,149:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.078e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,149:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.720e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,150:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.675e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,150:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.653e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,151:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.639e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,151:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.620e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,152:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.544e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,154:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.320e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,155:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.059e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,156:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.020e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,156:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.713e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,156:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.644e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,156:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.563e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,156:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.397e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,164:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.345e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,165:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=6.674e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,166:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.717e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,166:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.415e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,167:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.664e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,167:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.918e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,167:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.223e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,168:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.357e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,168:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.027e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,168:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.293e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,168:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.130e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,169:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.271e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,169:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.176e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,169:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.063e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,169:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.436e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,170:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.060e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,170:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.436e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,170:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.133e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,171:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.371e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,171:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.256e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,171:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.987e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,171:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.931e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,171:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.502e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,172:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.508e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,172:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.432e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,173:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.348e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,173:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.115e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,173:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=8.897e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,173:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=8.610e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,174:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.416e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,182:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.999e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,182:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.184e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,183:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.210e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,183:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.716e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,184:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.080e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,184:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.035e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,185:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.522e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,186:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.965e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,187:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.965e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,187:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.965e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,188:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.822e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,188:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.374e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,290:INFO:Calculating mean and std
2022-10-21 13:10:26,294:INFO:Creating metrics dataframe
2022-10-21 13:10:26,303:INFO:Uploading results into container
2022-10-21 13:10:26,305:INFO:Uploading model into container now
2022-10-21 13:10:26,305:INFO:master_model_container: 5
2022-10-21 13:10:26,306:INFO:display_container: 2
2022-10-21 13:10:26,308:INFO:Lars(random_state=122)
2022-10-21 13:10:26,308:INFO:create_model() successfully completed......................................
2022-10-21 13:10:26,483:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:26,483:INFO:Creating metrics dataframe
2022-10-21 13:10:26,505:INFO:Initializing Lasso Least Angle Regression
2022-10-21 13:10:26,505:INFO:Total runtime is 0.626574448744456 minutes
2022-10-21 13:10:26,534:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:26,535:INFO:Initializing create_model()
2022-10-21 13:10:26,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:26,535:INFO:Checking exceptions
2022-10-21 13:10:26,540:INFO:Importing libraries
2022-10-21 13:10:26,540:INFO:Copying training dataset
2022-10-21 13:10:26,564:INFO:Defining folds
2022-10-21 13:10:26,565:INFO:Declaring metric variables
2022-10-21 13:10:26,598:INFO:Importing untrained model
2022-10-21 13:10:26,615:INFO:Lasso Least Angle Regression Imported successfully
2022-10-21 13:10:26,663:INFO:Starting cross validation
2022-10-21 13:10:26,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:26,865:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:26,918:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.688e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,919:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.731e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,920:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.731e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,922:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.941e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,924:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.262e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,926:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.216e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,938:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:26,948:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.293e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,948:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.410e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,952:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.830e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,961:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.043e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,962:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.574e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,964:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.206e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,968:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:26,981:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:26,991:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.471e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,994:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.206e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,999:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.125e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:26,982:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.355e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,001:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.214e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,370:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:27,404:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.980e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,405:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.769e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,406:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.073e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,407:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.836e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,413:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.044e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,415:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=1.647e+00, previous alpha=1.480e+00, with an active set of 24 regressors.
  warnings.warn(

2022-10-21 13:10:27,449:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:27,450:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:27,454:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:27,455:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.570e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,463:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.348e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,463:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.225e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,464:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.348e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,465:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=1.323e+00, previous alpha=1.117e+00, with an active set of 27 regressors.
  warnings.warn(

2022-10-21 13:10:27,465:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.193e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,466:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.862e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,467:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.163e+00, previous alpha=4.862e+00, with an active set of 15 regressors.
  warnings.warn(

2022-10-21 13:10:27,491:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.992e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,494:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.992e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,495:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.933e+00, previous alpha=2.630e+00, with an active set of 18 regressors.
  warnings.warn(

2022-10-21 13:10:27,751:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:27,761:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.843e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,762:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.018e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,769:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.717e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,771:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.331e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,772:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=1.479e+00, previous alpha=1.249e+00, with an active set of 27 regressors.
  warnings.warn(

2022-10-21 13:10:27,818:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:10:27,835:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.759e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,839:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.371e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,852:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.529e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:10:27,853:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=1.413e+00, previous alpha=1.396e+00, with an active set of 24 regressors.
  warnings.warn(

2022-10-21 13:10:27,999:INFO:Calculating mean and std
2022-10-21 13:10:28,002:INFO:Creating metrics dataframe
2022-10-21 13:10:28,007:INFO:Uploading results into container
2022-10-21 13:10:28,010:INFO:Uploading model into container now
2022-10-21 13:10:28,012:INFO:master_model_container: 6
2022-10-21 13:10:28,012:INFO:display_container: 2
2022-10-21 13:10:28,014:INFO:LassoLars(random_state=122)
2022-10-21 13:10:28,014:INFO:create_model() successfully completed......................................
2022-10-21 13:10:28,182:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:28,183:INFO:Creating metrics dataframe
2022-10-21 13:10:28,214:INFO:Initializing Orthogonal Matching Pursuit
2022-10-21 13:10:28,218:INFO:Total runtime is 0.655124298731486 minutes
2022-10-21 13:10:28,270:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:28,270:INFO:Initializing create_model()
2022-10-21 13:10:28,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:28,271:INFO:Checking exceptions
2022-10-21 13:10:28,273:INFO:Importing libraries
2022-10-21 13:10:28,273:INFO:Copying training dataset
2022-10-21 13:10:28,307:INFO:Defining folds
2022-10-21 13:10:28,314:INFO:Declaring metric variables
2022-10-21 13:10:28,338:INFO:Importing untrained model
2022-10-21 13:10:28,352:INFO:Orthogonal Matching Pursuit Imported successfully
2022-10-21 13:10:28,400:INFO:Starting cross validation
2022-10-21 13:10:28,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:28,582:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:28,674:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:28,717:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:28,736:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,019:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,094:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,102:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,113:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,340:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,416:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:10:29,512:INFO:Calculating mean and std
2022-10-21 13:10:29,515:INFO:Creating metrics dataframe
2022-10-21 13:10:29,519:INFO:Uploading results into container
2022-10-21 13:10:29,520:INFO:Uploading model into container now
2022-10-21 13:10:29,522:INFO:master_model_container: 7
2022-10-21 13:10:29,522:INFO:display_container: 2
2022-10-21 13:10:29,523:INFO:OrthogonalMatchingPursuit()
2022-10-21 13:10:29,523:INFO:create_model() successfully completed......................................
2022-10-21 13:10:29,695:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:29,695:INFO:Creating metrics dataframe
2022-10-21 13:10:29,718:INFO:Initializing Bayesian Ridge
2022-10-21 13:10:29,718:INFO:Total runtime is 0.6801243662834168 minutes
2022-10-21 13:10:29,784:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:29,785:INFO:Initializing create_model()
2022-10-21 13:10:29,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:29,785:INFO:Checking exceptions
2022-10-21 13:10:29,790:INFO:Importing libraries
2022-10-21 13:10:29,790:INFO:Copying training dataset
2022-10-21 13:10:29,820:INFO:Defining folds
2022-10-21 13:10:29,821:INFO:Declaring metric variables
2022-10-21 13:10:29,839:INFO:Importing untrained model
2022-10-21 13:10:29,863:INFO:Bayesian Ridge Imported successfully
2022-10-21 13:10:29,903:INFO:Starting cross validation
2022-10-21 13:10:29,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:31,071:INFO:Calculating mean and std
2022-10-21 13:10:31,073:INFO:Creating metrics dataframe
2022-10-21 13:10:31,082:INFO:Uploading results into container
2022-10-21 13:10:31,083:INFO:Uploading model into container now
2022-10-21 13:10:31,084:INFO:master_model_container: 8
2022-10-21 13:10:31,084:INFO:display_container: 2
2022-10-21 13:10:31,085:INFO:BayesianRidge()
2022-10-21 13:10:31,085:INFO:create_model() successfully completed......................................
2022-10-21 13:10:31,255:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:31,256:INFO:Creating metrics dataframe
2022-10-21 13:10:31,291:INFO:Initializing Passive Aggressive Regressor
2022-10-21 13:10:31,294:INFO:Total runtime is 0.7063685178756715 minutes
2022-10-21 13:10:31,302:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:31,302:INFO:Initializing create_model()
2022-10-21 13:10:31,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:31,304:INFO:Checking exceptions
2022-10-21 13:10:31,307:INFO:Importing libraries
2022-10-21 13:10:31,307:INFO:Copying training dataset
2022-10-21 13:10:31,348:INFO:Defining folds
2022-10-21 13:10:31,350:INFO:Declaring metric variables
2022-10-21 13:10:31,373:INFO:Importing untrained model
2022-10-21 13:10:31,395:INFO:Passive Aggressive Regressor Imported successfully
2022-10-21 13:10:31,441:INFO:Starting cross validation
2022-10-21 13:10:31,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:33,713:INFO:Calculating mean and std
2022-10-21 13:10:33,716:INFO:Creating metrics dataframe
2022-10-21 13:10:33,720:INFO:Uploading results into container
2022-10-21 13:10:33,722:INFO:Uploading model into container now
2022-10-21 13:10:33,723:INFO:master_model_container: 9
2022-10-21 13:10:33,723:INFO:display_container: 2
2022-10-21 13:10:33,724:INFO:PassiveAggressiveRegressor(random_state=122)
2022-10-21 13:10:33,724:INFO:create_model() successfully completed......................................
2022-10-21 13:10:33,890:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:33,890:INFO:Creating metrics dataframe
2022-10-21 13:10:33,919:INFO:Initializing Huber Regressor
2022-10-21 13:10:33,919:INFO:Total runtime is 0.7501445968945821 minutes
2022-10-21 13:10:33,931:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:33,932:INFO:Initializing create_model()
2022-10-21 13:10:33,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:33,933:INFO:Checking exceptions
2022-10-21 13:10:33,937:INFO:Importing libraries
2022-10-21 13:10:33,937:INFO:Copying training dataset
2022-10-21 13:10:33,987:INFO:Defining folds
2022-10-21 13:10:33,987:INFO:Declaring metric variables
2022-10-21 13:10:34,017:INFO:Importing untrained model
2022-10-21 13:10:34,032:INFO:Huber Regressor Imported successfully
2022-10-21 13:10:34,084:INFO:Starting cross validation
2022-10-21 13:10:34,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:34,665:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:34,678:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:34,690:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:34,697:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,385:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,387:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,434:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,460:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,868:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,889:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:10:35,980:INFO:Calculating mean and std
2022-10-21 13:10:35,982:INFO:Creating metrics dataframe
2022-10-21 13:10:35,988:INFO:Uploading results into container
2022-10-21 13:10:35,989:INFO:Uploading model into container now
2022-10-21 13:10:35,990:INFO:master_model_container: 10
2022-10-21 13:10:35,991:INFO:display_container: 2
2022-10-21 13:10:35,991:INFO:HuberRegressor()
2022-10-21 13:10:35,991:INFO:create_model() successfully completed......................................
2022-10-21 13:10:36,162:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:36,162:INFO:Creating metrics dataframe
2022-10-21 13:10:36,185:INFO:Initializing K Neighbors Regressor
2022-10-21 13:10:36,185:INFO:Total runtime is 0.7879008293151856 minutes
2022-10-21 13:10:36,196:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:36,197:INFO:Initializing create_model()
2022-10-21 13:10:36,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:36,197:INFO:Checking exceptions
2022-10-21 13:10:36,202:INFO:Importing libraries
2022-10-21 13:10:36,202:INFO:Copying training dataset
2022-10-21 13:10:36,251:INFO:Defining folds
2022-10-21 13:10:36,251:INFO:Declaring metric variables
2022-10-21 13:10:36,273:INFO:Importing untrained model
2022-10-21 13:10:36,307:INFO:K Neighbors Regressor Imported successfully
2022-10-21 13:10:36,373:INFO:Starting cross validation
2022-10-21 13:10:36,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:37,587:INFO:Calculating mean and std
2022-10-21 13:10:37,589:INFO:Creating metrics dataframe
2022-10-21 13:10:37,596:INFO:Uploading results into container
2022-10-21 13:10:37,597:INFO:Uploading model into container now
2022-10-21 13:10:37,598:INFO:master_model_container: 11
2022-10-21 13:10:37,599:INFO:display_container: 2
2022-10-21 13:10:37,600:INFO:KNeighborsRegressor(n_jobs=-1)
2022-10-21 13:10:37,601:INFO:create_model() successfully completed......................................
2022-10-21 13:10:37,753:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:37,753:INFO:Creating metrics dataframe
2022-10-21 13:10:37,777:INFO:Initializing Decision Tree Regressor
2022-10-21 13:10:37,777:INFO:Total runtime is 0.814445161819458 minutes
2022-10-21 13:10:37,788:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:37,789:INFO:Initializing create_model()
2022-10-21 13:10:37,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:37,789:INFO:Checking exceptions
2022-10-21 13:10:37,823:INFO:Importing libraries
2022-10-21 13:10:37,824:INFO:Copying training dataset
2022-10-21 13:10:37,851:INFO:Defining folds
2022-10-21 13:10:37,851:INFO:Declaring metric variables
2022-10-21 13:10:37,871:INFO:Importing untrained model
2022-10-21 13:10:37,885:INFO:Decision Tree Regressor Imported successfully
2022-10-21 13:10:37,987:INFO:Starting cross validation
2022-10-21 13:10:37,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:39,267:INFO:Calculating mean and std
2022-10-21 13:10:39,269:INFO:Creating metrics dataframe
2022-10-21 13:10:39,277:INFO:Uploading results into container
2022-10-21 13:10:39,278:INFO:Uploading model into container now
2022-10-21 13:10:39,279:INFO:master_model_container: 12
2022-10-21 13:10:39,279:INFO:display_container: 2
2022-10-21 13:10:39,280:INFO:DecisionTreeRegressor(random_state=122)
2022-10-21 13:10:39,281:INFO:create_model() successfully completed......................................
2022-10-21 13:10:39,452:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:39,452:INFO:Creating metrics dataframe
2022-10-21 13:10:39,482:INFO:Initializing Random Forest Regressor
2022-10-21 13:10:39,482:INFO:Total runtime is 0.8428625663121542 minutes
2022-10-21 13:10:39,537:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:39,540:INFO:Initializing create_model()
2022-10-21 13:10:39,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:39,571:INFO:Checking exceptions
2022-10-21 13:10:39,583:INFO:Importing libraries
2022-10-21 13:10:39,583:INFO:Copying training dataset
2022-10-21 13:10:39,602:INFO:Defining folds
2022-10-21 13:10:39,605:INFO:Declaring metric variables
2022-10-21 13:10:39,623:INFO:Importing untrained model
2022-10-21 13:10:39,645:INFO:Random Forest Regressor Imported successfully
2022-10-21 13:10:39,778:INFO:Starting cross validation
2022-10-21 13:10:39,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:46,050:INFO:Calculating mean and std
2022-10-21 13:10:46,053:INFO:Creating metrics dataframe
2022-10-21 13:10:46,060:INFO:Uploading results into container
2022-10-21 13:10:46,062:INFO:Uploading model into container now
2022-10-21 13:10:46,064:INFO:master_model_container: 13
2022-10-21 13:10:46,064:INFO:display_container: 2
2022-10-21 13:10:46,065:INFO:RandomForestRegressor(n_jobs=-1, random_state=122)
2022-10-21 13:10:46,065:INFO:create_model() successfully completed......................................
2022-10-21 13:10:46,230:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:46,230:INFO:Creating metrics dataframe
2022-10-21 13:10:46,254:INFO:Initializing Extra Trees Regressor
2022-10-21 13:10:46,255:INFO:Total runtime is 0.9557352662086487 minutes
2022-10-21 13:10:46,267:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:46,367:INFO:Initializing create_model()
2022-10-21 13:10:46,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:46,367:INFO:Checking exceptions
2022-10-21 13:10:46,370:INFO:Importing libraries
2022-10-21 13:10:46,370:INFO:Copying training dataset
2022-10-21 13:10:46,420:INFO:Defining folds
2022-10-21 13:10:46,420:INFO:Declaring metric variables
2022-10-21 13:10:46,436:INFO:Importing untrained model
2022-10-21 13:10:46,452:INFO:Extra Trees Regressor Imported successfully
2022-10-21 13:10:46,501:INFO:Starting cross validation
2022-10-21 13:10:46,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:51,198:INFO:Calculating mean and std
2022-10-21 13:10:51,201:INFO:Creating metrics dataframe
2022-10-21 13:10:51,206:INFO:Uploading results into container
2022-10-21 13:10:51,207:INFO:Uploading model into container now
2022-10-21 13:10:51,208:INFO:master_model_container: 14
2022-10-21 13:10:51,209:INFO:display_container: 2
2022-10-21 13:10:51,209:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=122)
2022-10-21 13:10:51,210:INFO:create_model() successfully completed......................................
2022-10-21 13:10:51,401:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:51,402:INFO:Creating metrics dataframe
2022-10-21 13:10:51,435:INFO:Initializing AdaBoost Regressor
2022-10-21 13:10:51,436:INFO:Total runtime is 1.042082929611206 minutes
2022-10-21 13:10:51,506:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:51,507:INFO:Initializing create_model()
2022-10-21 13:10:51,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:51,507:INFO:Checking exceptions
2022-10-21 13:10:51,515:INFO:Importing libraries
2022-10-21 13:10:51,515:INFO:Copying training dataset
2022-10-21 13:10:51,548:INFO:Defining folds
2022-10-21 13:10:51,549:INFO:Declaring metric variables
2022-10-21 13:10:51,571:INFO:Importing untrained model
2022-10-21 13:10:51,586:INFO:AdaBoost Regressor Imported successfully
2022-10-21 13:10:51,615:INFO:Starting cross validation
2022-10-21 13:10:51,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:53,570:INFO:Calculating mean and std
2022-10-21 13:10:53,572:INFO:Creating metrics dataframe
2022-10-21 13:10:53,579:INFO:Uploading results into container
2022-10-21 13:10:53,580:INFO:Uploading model into container now
2022-10-21 13:10:53,581:INFO:master_model_container: 15
2022-10-21 13:10:53,581:INFO:display_container: 2
2022-10-21 13:10:53,582:INFO:AdaBoostRegressor(random_state=122)
2022-10-21 13:10:53,582:INFO:create_model() successfully completed......................................
2022-10-21 13:10:53,740:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:53,740:INFO:Creating metrics dataframe
2022-10-21 13:10:53,771:INFO:Initializing Gradient Boosting Regressor
2022-10-21 13:10:53,771:INFO:Total runtime is 1.0810027321179707 minutes
2022-10-21 13:10:53,800:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:53,802:INFO:Initializing create_model()
2022-10-21 13:10:53,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:53,808:INFO:Checking exceptions
2022-10-21 13:10:53,813:INFO:Importing libraries
2022-10-21 13:10:53,814:INFO:Copying training dataset
2022-10-21 13:10:53,839:INFO:Defining folds
2022-10-21 13:10:53,839:INFO:Declaring metric variables
2022-10-21 13:10:53,871:INFO:Importing untrained model
2022-10-21 13:10:53,899:INFO:Gradient Boosting Regressor Imported successfully
2022-10-21 13:10:53,962:INFO:Starting cross validation
2022-10-21 13:10:53,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:10:57,834:INFO:Calculating mean and std
2022-10-21 13:10:57,838:INFO:Creating metrics dataframe
2022-10-21 13:10:57,847:INFO:Uploading results into container
2022-10-21 13:10:57,848:INFO:Uploading model into container now
2022-10-21 13:10:57,852:INFO:master_model_container: 16
2022-10-21 13:10:57,852:INFO:display_container: 2
2022-10-21 13:10:57,855:INFO:GradientBoostingRegressor(random_state=122)
2022-10-21 13:10:57,855:INFO:create_model() successfully completed......................................
2022-10-21 13:10:58,064:INFO:SubProcess create_model() end ==================================
2022-10-21 13:10:58,064:INFO:Creating metrics dataframe
2022-10-21 13:10:58,091:INFO:Initializing Light Gradient Boosting Machine
2022-10-21 13:10:58,091:INFO:Total runtime is 1.1530125300089518 minutes
2022-10-21 13:10:58,154:INFO:SubProcess create_model() called ==================================
2022-10-21 13:10:58,156:INFO:Initializing create_model()
2022-10-21 13:10:58,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:10:58,173:INFO:Checking exceptions
2022-10-21 13:10:58,186:INFO:Importing libraries
2022-10-21 13:10:58,186:INFO:Copying training dataset
2022-10-21 13:10:58,202:INFO:Defining folds
2022-10-21 13:10:58,203:INFO:Declaring metric variables
2022-10-21 13:10:58,225:INFO:Importing untrained model
2022-10-21 13:10:58,260:INFO:Light Gradient Boosting Machine Imported successfully
2022-10-21 13:10:58,299:INFO:Starting cross validation
2022-10-21 13:10:58,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:11:03,389:INFO:Calculating mean and std
2022-10-21 13:11:03,411:INFO:Creating metrics dataframe
2022-10-21 13:11:03,416:INFO:Uploading results into container
2022-10-21 13:11:03,417:INFO:Uploading model into container now
2022-10-21 13:11:03,417:INFO:master_model_container: 17
2022-10-21 13:11:03,417:INFO:display_container: 2
2022-10-21 13:11:03,418:INFO:LGBMRegressor(random_state=122)
2022-10-21 13:11:03,418:INFO:create_model() successfully completed......................................
2022-10-21 13:11:03,585:INFO:SubProcess create_model() end ==================================
2022-10-21 13:11:03,585:INFO:Creating metrics dataframe
2022-10-21 13:11:03,616:INFO:Initializing CatBoost Regressor
2022-10-21 13:11:03,616:INFO:Total runtime is 1.2450944662094117 minutes
2022-10-21 13:11:03,629:INFO:SubProcess create_model() called ==================================
2022-10-21 13:11:03,631:INFO:Initializing create_model()
2022-10-21 13:11:03,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:11:03,632:INFO:Checking exceptions
2022-10-21 13:11:03,634:INFO:Importing libraries
2022-10-21 13:11:03,635:INFO:Copying training dataset
2022-10-21 13:11:03,705:INFO:Defining folds
2022-10-21 13:11:03,705:INFO:Declaring metric variables
2022-10-21 13:11:03,725:INFO:Importing untrained model
2022-10-21 13:11:03,784:INFO:CatBoost Regressor Imported successfully
2022-10-21 13:11:03,803:INFO:Starting cross validation
2022-10-21 13:11:03,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:11:43,960:INFO:Calculating mean and std
2022-10-21 13:11:43,964:INFO:Creating metrics dataframe
2022-10-21 13:11:43,969:INFO:Uploading results into container
2022-10-21 13:11:43,970:INFO:Uploading model into container now
2022-10-21 13:11:43,971:INFO:master_model_container: 18
2022-10-21 13:11:43,971:INFO:display_container: 2
2022-10-21 13:11:43,971:INFO:<catboost.core.CatBoostRegressor object at 0x7f86435974f0>
2022-10-21 13:11:43,971:INFO:create_model() successfully completed......................................
2022-10-21 13:11:44,163:INFO:SubProcess create_model() end ==================================
2022-10-21 13:11:44,164:INFO:Creating metrics dataframe
2022-10-21 13:11:44,190:INFO:Initializing Dummy Regressor
2022-10-21 13:11:44,191:INFO:Total runtime is 1.921339813868205 minutes
2022-10-21 13:11:44,238:INFO:SubProcess create_model() called ==================================
2022-10-21 13:11:44,239:INFO:Initializing create_model()
2022-10-21 13:11:44,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f865e240df0>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:11:44,239:INFO:Checking exceptions
2022-10-21 13:11:44,243:INFO:Importing libraries
2022-10-21 13:11:44,247:INFO:Copying training dataset
2022-10-21 13:11:44,263:INFO:Defining folds
2022-10-21 13:11:44,263:INFO:Declaring metric variables
2022-10-21 13:11:44,299:INFO:Importing untrained model
2022-10-21 13:11:44,348:INFO:Dummy Regressor Imported successfully
2022-10-21 13:11:44,390:INFO:Starting cross validation
2022-10-21 13:11:44,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:11:45,389:INFO:Calculating mean and std
2022-10-21 13:11:45,393:INFO:Creating metrics dataframe
2022-10-21 13:11:45,408:INFO:Uploading results into container
2022-10-21 13:11:45,409:INFO:Uploading model into container now
2022-10-21 13:11:45,414:INFO:master_model_container: 19
2022-10-21 13:11:45,414:INFO:display_container: 2
2022-10-21 13:11:45,415:INFO:DummyRegressor()
2022-10-21 13:11:45,415:INFO:create_model() successfully completed......................................
2022-10-21 13:11:45,781:INFO:SubProcess create_model() end ==================================
2022-10-21 13:11:45,781:INFO:Creating metrics dataframe
2022-10-21 13:11:45,973:INFO:Initializing create_model()
2022-10-21 13:11:45,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=GradientBoostingRegressor(random_state=122), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:11:45,973:INFO:Checking exceptions
2022-10-21 13:11:45,987:INFO:Importing libraries
2022-10-21 13:11:45,987:INFO:Copying training dataset
2022-10-21 13:11:46,003:INFO:Defining folds
2022-10-21 13:11:46,003:INFO:Declaring metric variables
2022-10-21 13:11:46,004:INFO:Importing untrained model
2022-10-21 13:11:46,004:INFO:Declaring custom model
2022-10-21 13:11:46,005:INFO:Gradient Boosting Regressor Imported successfully
2022-10-21 13:11:46,006:INFO:Cross validation set to False
2022-10-21 13:11:46,007:INFO:Fitting Model
2022-10-21 13:11:46,675:INFO:GradientBoostingRegressor(random_state=122)
2022-10-21 13:11:46,675:INFO:create_model() successfully completed......................................
2022-10-21 13:11:46,990:INFO:master_model_container: 19
2022-10-21 13:11:46,991:INFO:display_container: 2
2022-10-21 13:11:46,992:INFO:GradientBoostingRegressor(random_state=122)
2022-10-21 13:11:46,992:INFO:compare_models() successfully completed......................................
2022-10-21 13:11:47,002:INFO:Initializing evaluate_model()
2022-10-21 13:11:47,002:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=GradientBoostingRegressor(random_state=122), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2022-10-21 13:11:47,116:INFO:Initializing plot_model()
2022-10-21 13:11:47,117:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, system=True)
2022-10-21 13:11:47,119:INFO:Checking exceptions
2022-10-21 13:11:47,133:INFO:Preloading libraries
2022-10-21 13:11:47,202:INFO:Copying training dataset
2022-10-21 13:11:47,202:INFO:Plot type: pipeline
2022-10-21 13:11:47,786:INFO:Visual Rendered Successfully
2022-10-21 13:11:47,958:INFO:plot_model() successfully completed......................................
2022-10-21 13:11:48,032:INFO:Initializing predict_model()
2022-10-21 13:11:48,032:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, estimator=GradientBoostingRegressor(random_state=122), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f864317de50>)
2022-10-21 13:11:48,072:INFO:Checking exceptions
2022-10-21 13:11:48,073:INFO:Preloading libraries
2022-10-21 13:11:48,494:INFO:Initializing save_model()
2022-10-21 13:11:48,494:INFO:save_model(model=GradientBoostingRegressor(random_state=122), model_name=MLOps_Pipeline, prep_pipe_=Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-10-21 13:11:48,495:INFO:Adding model into prep_pipe
2022-10-21 13:11:48,524:INFO:MLOps_Pipeline.pkl saved in current working directory
2022-10-21 13:11:48,553:INFO:Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', GradientBoostingRegressor(random_state=122))])
2022-10-21 13:11:48,553:INFO:save_model() successfully completed......................................
2022-10-21 13:12:36,880:INFO:Initializing plot_model()
2022-10-21 13:12:36,882:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, system=True)
2022-10-21 13:12:36,883:INFO:Checking exceptions
2022-10-21 13:12:36,886:INFO:Preloading libraries
2022-10-21 13:12:36,903:INFO:Copying training dataset
2022-10-21 13:12:36,903:INFO:Plot type: parameter
2022-10-21 13:12:36,909:INFO:Visual Rendered Successfully
2022-10-21 13:12:37,111:INFO:plot_model() successfully completed......................................
2022-10-21 13:12:38,309:INFO:Initializing plot_model()
2022-10-21 13:12:38,309:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, system=True)
2022-10-21 13:12:38,309:INFO:Checking exceptions
2022-10-21 13:12:38,314:INFO:Preloading libraries
2022-10-21 13:12:38,335:INFO:Copying training dataset
2022-10-21 13:12:38,335:INFO:Plot type: residuals
2022-10-21 13:12:38,662:INFO:Fitting Model
2022-10-21 13:12:38,721:INFO:Scoring test/hold-out set
2022-10-21 13:12:39,804:INFO:Visual Rendered Successfully
2022-10-21 13:12:40,027:INFO:plot_model() successfully completed......................................
2022-10-21 13:12:41,134:INFO:Initializing plot_model()
2022-10-21 13:12:41,134:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, system=True)
2022-10-21 13:12:41,134:INFO:Checking exceptions
2022-10-21 13:12:41,138:INFO:Preloading libraries
2022-10-21 13:12:41,154:INFO:Copying training dataset
2022-10-21 13:12:41,154:INFO:Plot type: error
2022-10-21 13:12:41,333:INFO:Fitting Model
2022-10-21 13:12:41,334:INFO:Scoring test/hold-out set
2022-10-21 13:12:41,728:INFO:Visual Rendered Successfully
2022-10-21 13:12:41,920:INFO:plot_model() successfully completed......................................
2022-10-21 13:12:42,681:INFO:Initializing plot_model()
2022-10-21 13:12:42,682:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, system=True)
2022-10-21 13:12:42,682:INFO:Checking exceptions
2022-10-21 13:12:42,686:INFO:Preloading libraries
2022-10-21 13:12:42,702:INFO:Copying training dataset
2022-10-21 13:12:42,703:INFO:Plot type: cooks
2022-10-21 13:12:42,904:INFO:Fitting Model
2022-10-21 13:12:43,267:INFO:Visual Rendered Successfully
2022-10-21 13:12:43,401:INFO:plot_model() successfully completed......................................
2022-10-21 13:12:44,572:INFO:Initializing plot_model()
2022-10-21 13:12:44,572:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f865e1ae910>, system=True)
2022-10-21 13:12:44,572:INFO:Checking exceptions
2022-10-21 13:12:44,576:INFO:Preloading libraries
2022-10-21 13:12:44,590:INFO:Copying training dataset
2022-10-21 13:12:44,590:INFO:Plot type: rfe
2022-10-21 13:12:44,775:INFO:Fitting Model
2022-10-21 13:22:55,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:22:55,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:22:55,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:22:55,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:22:58,800:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:25:32,098:INFO:PyCaret RegressionExperiment
2022-10-21 13:25:32,100:INFO:Logging name: reg-default-name
2022-10-21 13:25:32,100:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 13:25:32,100:INFO:version 3.0.0.rc4
2022-10-21 13:25:32,100:INFO:Initializing setup()
2022-10-21 13:25:32,100:INFO:self.USI: 6151
2022-10-21 13:25:32,100:INFO:self.variable_keys: {'exp_id', 'n_jobs_param', 'fold_generator', 'X_train', 'gpu_param', 'memory', '_gpu_n_jobs_param', 'display_container', 'log_plots_param', 'pipeline', 'logging_param', 'X_test', 'y', 'X', 'exp_name_log', '_all_metrics', 'y_train', 'transform_target_param', '_available_plots', 'transform_target_method_param', 'variable_keys', 'USI', '_all_models', 'fold_shuffle_param', 'idx', '_ml_usecase', '_all_models_internal', 'y_test', 'fold_groups_param', 'master_model_container', 'target_param', 'seed', 'data', 'html_param'}
2022-10-21 13:25:32,101:INFO:Checking environment
2022-10-21 13:25:32,101:INFO:python_version: 3.9.7
2022-10-21 13:25:32,101:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 13:25:32,101:INFO:machine: x86_64
2022-10-21 13:25:32,101:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 13:25:32,102:INFO:Memory: svmem(total=8589934592, available=2345857024, percent=72.7, used=4179558400, free=15724544, active=2334695424, inactive=2324074496, wired=1844862976)
2022-10-21 13:25:32,102:INFO:Physical Core: 2
2022-10-21 13:25:32,102:INFO:Logical Core: 4
2022-10-21 13:25:32,102:INFO:Checking libraries
2022-10-21 13:25:32,102:INFO:System:
2022-10-21 13:25:32,102:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 13:25:32,102:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 13:25:32,102:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 13:25:32,103:INFO:PyCaret required dependencies:
2022-10-21 13:25:32,105:INFO:                 pip: 21.2.4
2022-10-21 13:25:32,105:INFO:          setuptools: 58.0.4
2022-10-21 13:25:32,105:INFO:             pycaret: 3.0.0rc4
2022-10-21 13:25:32,106:INFO:             IPython: 7.29.0
2022-10-21 13:25:32,106:INFO:          ipywidgets: 7.6.5
2022-10-21 13:25:32,106:INFO:                tqdm: 4.62.3
2022-10-21 13:25:32,106:INFO:               numpy: 1.22.4
2022-10-21 13:25:32,106:INFO:              pandas: 1.4.4
2022-10-21 13:25:32,106:INFO:              jinja2: 3.1.2
2022-10-21 13:25:32,106:INFO:               scipy: 1.8.1
2022-10-21 13:25:32,106:INFO:              joblib: 1.1.0
2022-10-21 13:25:32,106:INFO:             sklearn: 1.0.2
2022-10-21 13:25:32,107:INFO:                pyod: 1.0.5
2022-10-21 13:25:32,107:INFO:            imblearn: 0.9.0
2022-10-21 13:25:32,107:INFO:   category_encoders: 2.5.1.post0
2022-10-21 13:25:32,107:INFO:            lightgbm: 3.3.2
2022-10-21 13:25:32,107:INFO:               numba: 0.55.2
2022-10-21 13:25:32,107:INFO:            requests: 2.28.1
2022-10-21 13:25:32,107:INFO:          matplotlib: 3.4.3
2022-10-21 13:25:32,107:INFO:          scikitplot: 0.3.7
2022-10-21 13:25:32,107:INFO:         yellowbrick: 1.4
2022-10-21 13:25:32,107:INFO:              plotly: 5.5.0
2022-10-21 13:25:32,107:INFO:             kaleido: 0.2.1
2022-10-21 13:25:32,107:INFO:         statsmodels: 0.13.2
2022-10-21 13:25:32,108:INFO:              sktime: 0.13.4
2022-10-21 13:25:32,108:INFO:               tbats: 1.1.1
2022-10-21 13:25:32,108:INFO:            pmdarima: 1.8.5
2022-10-21 13:25:32,108:INFO:              psutil: 5.9.2
2022-10-21 13:25:32,108:INFO:PyCaret optional dependencies:
2022-10-21 13:25:32,124:INFO:                shap: 0.41.0
2022-10-21 13:25:32,124:INFO:           interpret: Not installed
2022-10-21 13:25:32,125:INFO:                umap: Not installed
2022-10-21 13:25:32,125:INFO:    pandas_profiling: Not installed
2022-10-21 13:25:32,125:INFO:  explainerdashboard: Not installed
2022-10-21 13:25:32,125:INFO:             autoviz: Not installed
2022-10-21 13:25:32,125:INFO:           fairlearn: Not installed
2022-10-21 13:25:32,125:INFO:             xgboost: Not installed
2022-10-21 13:25:32,125:INFO:            catboost: 1.1
2022-10-21 13:25:32,125:INFO:              kmodes: Not installed
2022-10-21 13:25:32,125:INFO:             mlxtend: Not installed
2022-10-21 13:25:32,125:INFO:       statsforecast: 1.1.1
2022-10-21 13:25:32,125:INFO:        tune_sklearn: Not installed
2022-10-21 13:25:32,125:INFO:                 ray: Not installed
2022-10-21 13:25:32,125:INFO:            hyperopt: Not installed
2022-10-21 13:25:32,125:INFO:              optuna: Not installed
2022-10-21 13:25:32,125:INFO:               skopt: Not installed
2022-10-21 13:25:32,126:INFO:              mlflow: 1.29.0
2022-10-21 13:25:32,126:INFO:              gradio: Not installed
2022-10-21 13:25:32,126:INFO:             fastapi: Not installed
2022-10-21 13:25:32,126:INFO:             uvicorn: Not installed
2022-10-21 13:25:32,126:INFO:              m2cgen: Not installed
2022-10-21 13:25:32,126:INFO:           evidently: Not installed
2022-10-21 13:25:32,126:INFO:                nltk: 3.6.5
2022-10-21 13:25:32,126:INFO:            pyLDAvis: Not installed
2022-10-21 13:25:32,126:INFO:              gensim: Not installed
2022-10-21 13:25:32,126:INFO:               spacy: Not installed
2022-10-21 13:25:32,126:INFO:           wordcloud: Not installed
2022-10-21 13:25:32,126:INFO:            textblob: Not installed
2022-10-21 13:25:32,126:INFO:               fugue: Not installed
2022-10-21 13:25:32,126:INFO:           streamlit: Not installed
2022-10-21 13:25:32,126:INFO:             prophet: 1.1.1
2022-10-21 13:25:32,127:INFO:None
2022-10-21 13:25:32,127:INFO:Set up data.
2022-10-21 13:25:32,142:INFO:Set up train/test split.
2022-10-21 13:25:32,157:INFO:Set up index.
2022-10-21 13:25:32,158:INFO:Set up folding strategy.
2022-10-21 13:25:32,158:INFO:Assigning column types.
2022-10-21 13:25:32,177:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 13:25:32,177:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,194:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:32,565:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:32,663:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,676:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,684:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:32,844:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:32,845:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-10-21 13:25:32,854:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:25:32,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:33,059:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:33,073:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:33,315:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:33,316:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-10-21 13:25:33,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,541:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:33,806:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:33,844:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:25:33,993:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:34,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:34,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:34,128:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:34,129:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-10-21 13:25:34,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:34,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:34,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:34,486:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:34,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:34,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:25:34,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:34,775:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:34,776:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-10-21 13:25:34,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:35,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:35,016:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:35,243:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:25:35,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:35,475:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:35,476:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-10-21 13:25:35,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:35,699:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:35,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:25:35,883:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:25:35,884:INFO:Preparing preprocessing pipeline...
2022-10-21 13:25:35,887:INFO:Set up simple imputation.
2022-10-21 13:25:35,892:INFO:Set up encoding of ordinal features.
2022-10-21 13:25:35,895:INFO:Set up encoding of categorical features.
2022-10-21 13:25:35,895:INFO:Set up polynomial features.
2022-10-21 13:25:35,895:INFO:Set up variance threshold.
2022-10-21 13:25:35,895:INFO:Set up binning of numerical features.
2022-10-21 13:25:35,897:INFO:Set up feature normalization.
2022-10-21 13:26:19,761:INFO:PyCaret RegressionExperiment
2022-10-21 13:26:19,763:INFO:Logging name: reg-default-name
2022-10-21 13:26:19,763:INFO:ML Usecase: MLUsecase.REGRESSION
2022-10-21 13:26:19,763:INFO:version 3.0.0.rc4
2022-10-21 13:26:19,763:INFO:Initializing setup()
2022-10-21 13:26:19,763:INFO:self.USI: d49b
2022-10-21 13:26:19,764:INFO:self.variable_keys: {'exp_id', 'n_jobs_param', 'fold_generator', 'X_train', 'gpu_param', 'memory', '_gpu_n_jobs_param', 'display_container', 'log_plots_param', 'pipeline', 'logging_param', 'X_test', 'y', 'X', 'exp_name_log', '_all_metrics', 'y_train', 'transform_target_param', '_available_plots', 'transform_target_method_param', 'variable_keys', 'USI', '_all_models', 'fold_shuffle_param', 'idx', '_ml_usecase', '_all_models_internal', 'y_test', 'fold_groups_param', 'master_model_container', 'target_param', 'seed', 'data', 'html_param'}
2022-10-21 13:26:19,764:INFO:Checking environment
2022-10-21 13:26:19,764:INFO:python_version: 3.9.7
2022-10-21 13:26:19,764:INFO:python_build: ('default', 'Sep 16 2021 08:50:36')
2022-10-21 13:26:19,764:INFO:machine: x86_64
2022-10-21 13:26:19,764:INFO:platform: macOS-10.16-x86_64-i386-64bit
2022-10-21 13:26:19,764:INFO:Memory: svmem(total=8589934592, available=2355232768, percent=72.6, used=4205633536, free=17555456, active=2338848768, inactive=2336817152, wired=1866784768)
2022-10-21 13:26:19,768:INFO:Physical Core: 2
2022-10-21 13:26:19,769:INFO:Logical Core: 4
2022-10-21 13:26:19,769:INFO:Checking libraries
2022-10-21 13:26:19,769:INFO:System:
2022-10-21 13:26:19,769:INFO:    python: 3.9.7 (default, Sep 16 2021, 08:50:36)  [Clang 10.0.0 ]
2022-10-21 13:26:19,769:INFO:executable: /Users/sage/opt/anaconda3/bin/python
2022-10-21 13:26:19,769:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2022-10-21 13:26:19,769:INFO:PyCaret required dependencies:
2022-10-21 13:26:19,769:INFO:                 pip: 21.2.4
2022-10-21 13:26:19,769:INFO:          setuptools: 58.0.4
2022-10-21 13:26:19,769:INFO:             pycaret: 3.0.0rc4
2022-10-21 13:26:19,769:INFO:             IPython: 7.29.0
2022-10-21 13:26:19,770:INFO:          ipywidgets: 7.6.5
2022-10-21 13:26:19,770:INFO:                tqdm: 4.62.3
2022-10-21 13:26:19,770:INFO:               numpy: 1.22.4
2022-10-21 13:26:19,770:INFO:              pandas: 1.4.4
2022-10-21 13:26:19,770:INFO:              jinja2: 3.1.2
2022-10-21 13:26:19,770:INFO:               scipy: 1.8.1
2022-10-21 13:26:19,770:INFO:              joblib: 1.1.0
2022-10-21 13:26:19,770:INFO:             sklearn: 1.0.2
2022-10-21 13:26:19,777:INFO:                pyod: 1.0.5
2022-10-21 13:26:19,778:INFO:            imblearn: 0.9.0
2022-10-21 13:26:19,778:INFO:   category_encoders: 2.5.1.post0
2022-10-21 13:26:19,778:INFO:            lightgbm: 3.3.2
2022-10-21 13:26:19,778:INFO:               numba: 0.55.2
2022-10-21 13:26:19,778:INFO:            requests: 2.28.1
2022-10-21 13:26:19,778:INFO:          matplotlib: 3.4.3
2022-10-21 13:26:19,778:INFO:          scikitplot: 0.3.7
2022-10-21 13:26:19,779:INFO:         yellowbrick: 1.4
2022-10-21 13:26:19,779:INFO:              plotly: 5.5.0
2022-10-21 13:26:19,779:INFO:             kaleido: 0.2.1
2022-10-21 13:26:19,779:INFO:         statsmodels: 0.13.2
2022-10-21 13:26:19,779:INFO:              sktime: 0.13.4
2022-10-21 13:26:19,779:INFO:               tbats: 1.1.1
2022-10-21 13:26:19,779:INFO:            pmdarima: 1.8.5
2022-10-21 13:26:19,779:INFO:              psutil: 5.9.2
2022-10-21 13:26:19,779:INFO:PyCaret optional dependencies:
2022-10-21 13:26:19,779:INFO:                shap: 0.41.0
2022-10-21 13:26:19,779:INFO:           interpret: Not installed
2022-10-21 13:26:19,779:INFO:                umap: Not installed
2022-10-21 13:26:19,779:INFO:    pandas_profiling: Not installed
2022-10-21 13:26:19,779:INFO:  explainerdashboard: Not installed
2022-10-21 13:26:19,779:INFO:             autoviz: Not installed
2022-10-21 13:26:19,780:INFO:           fairlearn: Not installed
2022-10-21 13:26:19,780:INFO:             xgboost: Not installed
2022-10-21 13:26:19,780:INFO:            catboost: 1.1
2022-10-21 13:26:19,780:INFO:              kmodes: Not installed
2022-10-21 13:26:19,780:INFO:             mlxtend: Not installed
2022-10-21 13:26:19,780:INFO:       statsforecast: 1.1.1
2022-10-21 13:26:19,780:INFO:        tune_sklearn: Not installed
2022-10-21 13:26:19,781:INFO:                 ray: Not installed
2022-10-21 13:26:19,781:INFO:            hyperopt: Not installed
2022-10-21 13:26:19,782:INFO:              optuna: Not installed
2022-10-21 13:26:19,782:INFO:               skopt: Not installed
2022-10-21 13:26:19,782:INFO:              mlflow: 1.29.0
2022-10-21 13:26:19,782:INFO:              gradio: Not installed
2022-10-21 13:26:19,782:INFO:             fastapi: Not installed
2022-10-21 13:26:19,782:INFO:             uvicorn: Not installed
2022-10-21 13:26:19,782:INFO:              m2cgen: Not installed
2022-10-21 13:26:19,782:INFO:           evidently: Not installed
2022-10-21 13:26:19,783:INFO:                nltk: 3.6.5
2022-10-21 13:26:19,783:INFO:            pyLDAvis: Not installed
2022-10-21 13:26:19,783:INFO:              gensim: Not installed
2022-10-21 13:26:19,783:INFO:               spacy: Not installed
2022-10-21 13:26:19,783:INFO:           wordcloud: Not installed
2022-10-21 13:26:19,783:INFO:            textblob: Not installed
2022-10-21 13:26:19,783:INFO:               fugue: Not installed
2022-10-21 13:26:19,783:INFO:           streamlit: Not installed
2022-10-21 13:26:19,783:INFO:             prophet: 1.1.1
2022-10-21 13:26:19,784:INFO:None
2022-10-21 13:26:19,784:INFO:Set up data.
2022-10-21 13:26:19,814:INFO:Set up train/test split.
2022-10-21 13:26:19,886:INFO:Set up index.
2022-10-21 13:26:19,887:INFO:Set up folding strategy.
2022-10-21 13:26:19,887:INFO:Assigning column types.
2022-10-21 13:26:19,895:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-10-21 13:26:19,895:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 13:26:19,908:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:26:19,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:20,375:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:20,378:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,391:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,634:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:20,636:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:20,638:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-10-21 13:26:20,650:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:20,896:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:20,906:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-10-21 13:26:20,914:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:21,073:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:21,074:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-10-21 13:26:21,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:21,267:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:21,289:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:21,702:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:21,710:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-10-21 13:26:21,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:21,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:21,978:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:22,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:22,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-10-21 13:26:22,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:22,245:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:22,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-10-21 13:26:22,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:22,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:22,545:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:22,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-10-21 13:26:22,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:22,844:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:22,845:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-10-21 13:26:23,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:23,201:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:23,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:23,423:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:23,426:INFO:Preparing preprocessing pipeline...
2022-10-21 13:26:23,427:INFO:Set up simple imputation.
2022-10-21 13:26:23,433:INFO:Set up encoding of ordinal features.
2022-10-21 13:26:23,440:INFO:Set up encoding of categorical features.
2022-10-21 13:26:23,440:INFO:Set up polynomial features.
2022-10-21 13:26:23,441:INFO:Set up variance threshold.
2022-10-21 13:26:23,441:INFO:Set up feature normalization.
2022-10-21 13:26:23,563:INFO:Finished creating preprocessing pipeline.
2022-10-21 13:26:23,590:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2022-10-21 13:26:23,590:INFO:Creating final display dataframe.
2022-10-21 13:26:24,086:INFO:Setup display_container:                  Description             Value
0                 Session id               122
1                     Target           charges
2                Target type        Regression
3                 Data shape        (1338, 49)
4           Train data shape         (936, 49)
5            Test data shape         (402, 49)
6           Ordinal features                 2
7           Numeric features                 3
8       Categorical features                 3
9                 Preprocess              True
10           Imputation type            simple
11        Numeric imputation              mean
12    Categorical imputation          constant
13  Maximum one-hot encoding                 5
14           Encoding method              None
15       Polynomial features              True
16         Polynomial degree                 2
17    Low variance threshold                 0
18                 Normalize              True
19          Normalize method            zscore
20            Fold Generator             KFold
21               Fold Number                10
22                  CPU Jobs                -1
23                   Use GPU             False
24            Log Experiment             False
25           Experiment Name  reg-default-name
26                       USI              d49b
2022-10-21 13:26:24,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:24,359:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:24,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-10-21 13:26:24,534:INFO:Soft dependency imported: catboost: 1.1
2022-10-21 13:26:24,547:INFO:setup() successfully completed in 4.79s...............
2022-10-21 13:26:24,547:INFO:Initializing compare_models()
2022-10-21 13:26:24,548:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-10-21 13:26:24,548:INFO:Checking exceptions
2022-10-21 13:26:24,550:INFO:Preparing display monitor
2022-10-21 13:26:24,786:INFO:Initializing Linear Regression
2022-10-21 13:26:24,788:INFO:Total runtime is 4.89195187886556e-05 minutes
2022-10-21 13:26:24,801:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:24,802:INFO:Initializing create_model()
2022-10-21 13:26:24,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:24,803:INFO:Checking exceptions
2022-10-21 13:26:24,811:INFO:Importing libraries
2022-10-21 13:26:24,811:INFO:Copying training dataset
2022-10-21 13:26:24,820:INFO:Defining folds
2022-10-21 13:26:24,821:INFO:Declaring metric variables
2022-10-21 13:26:24,877:INFO:Importing untrained model
2022-10-21 13:26:24,891:INFO:Linear Regression Imported successfully
2022-10-21 13:26:24,913:INFO:Starting cross validation
2022-10-21 13:26:24,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:40,972:INFO:Calculating mean and std
2022-10-21 13:26:40,978:INFO:Creating metrics dataframe
2022-10-21 13:26:40,989:INFO:Uploading results into container
2022-10-21 13:26:40,992:INFO:Uploading model into container now
2022-10-21 13:26:40,993:INFO:master_model_container: 1
2022-10-21 13:26:40,994:INFO:display_container: 2
2022-10-21 13:26:40,995:INFO:LinearRegression(n_jobs=-1)
2022-10-21 13:26:40,995:INFO:create_model() successfully completed......................................
2022-10-21 13:26:41,461:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:41,461:INFO:Creating metrics dataframe
2022-10-21 13:26:41,488:INFO:Initializing Lasso Regression
2022-10-21 13:26:41,488:INFO:Total runtime is 0.2783764322598775 minutes
2022-10-21 13:26:41,497:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:41,498:INFO:Initializing create_model()
2022-10-21 13:26:41,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:41,500:INFO:Checking exceptions
2022-10-21 13:26:41,503:INFO:Importing libraries
2022-10-21 13:26:41,504:INFO:Copying training dataset
2022-10-21 13:26:41,524:INFO:Defining folds
2022-10-21 13:26:41,524:INFO:Declaring metric variables
2022-10-21 13:26:41,557:INFO:Importing untrained model
2022-10-21 13:26:41,602:INFO:Lasso Regression Imported successfully
2022-10-21 13:26:41,643:INFO:Starting cross validation
2022-10-21 13:26:41,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:42,074:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.057e+09, tolerance: 1.200e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,075:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e+09, tolerance: 1.200e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,076:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.925e+09, tolerance: 1.201e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,076:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+09, tolerance: 1.211e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,512:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e+09, tolerance: 1.242e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,514:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.622e+09, tolerance: 1.201e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,520:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.374e+09, tolerance: 1.231e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,529:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.006e+09, tolerance: 1.207e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,747:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.154e+09, tolerance: 1.240e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,753:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.479e+09, tolerance: 1.261e+07
  model = cd_fast.enet_coordinate_descent(

2022-10-21 13:26:42,813:INFO:Calculating mean and std
2022-10-21 13:26:42,815:INFO:Creating metrics dataframe
2022-10-21 13:26:42,820:INFO:Uploading results into container
2022-10-21 13:26:42,821:INFO:Uploading model into container now
2022-10-21 13:26:42,823:INFO:master_model_container: 2
2022-10-21 13:26:42,823:INFO:display_container: 2
2022-10-21 13:26:42,824:INFO:Lasso(random_state=122)
2022-10-21 13:26:42,825:INFO:create_model() successfully completed......................................
2022-10-21 13:26:42,972:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:42,972:INFO:Creating metrics dataframe
2022-10-21 13:26:42,989:INFO:Initializing Ridge Regression
2022-10-21 13:26:42,989:INFO:Total runtime is 0.3033881346384684 minutes
2022-10-21 13:26:42,996:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:42,996:INFO:Initializing create_model()
2022-10-21 13:26:42,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:42,997:INFO:Checking exceptions
2022-10-21 13:26:43,001:INFO:Importing libraries
2022-10-21 13:26:43,001:INFO:Copying training dataset
2022-10-21 13:26:43,009:INFO:Defining folds
2022-10-21 13:26:43,009:INFO:Declaring metric variables
2022-10-21 13:26:43,040:INFO:Importing untrained model
2022-10-21 13:26:43,052:INFO:Ridge Regression Imported successfully
2022-10-21 13:26:43,115:INFO:Starting cross validation
2022-10-21 13:26:43,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:43,900:INFO:Calculating mean and std
2022-10-21 13:26:43,903:INFO:Creating metrics dataframe
2022-10-21 13:26:43,909:INFO:Uploading results into container
2022-10-21 13:26:43,910:INFO:Uploading model into container now
2022-10-21 13:26:43,911:INFO:master_model_container: 3
2022-10-21 13:26:43,911:INFO:display_container: 2
2022-10-21 13:26:43,912:INFO:Ridge(random_state=122)
2022-10-21 13:26:43,912:INFO:create_model() successfully completed......................................
2022-10-21 13:26:44,056:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:44,057:INFO:Creating metrics dataframe
2022-10-21 13:26:44,075:INFO:Initializing Elastic Net
2022-10-21 13:26:44,075:INFO:Total runtime is 0.3214994470278422 minutes
2022-10-21 13:26:44,081:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:44,082:INFO:Initializing create_model()
2022-10-21 13:26:44,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:44,082:INFO:Checking exceptions
2022-10-21 13:26:44,086:INFO:Importing libraries
2022-10-21 13:26:44,086:INFO:Copying training dataset
2022-10-21 13:26:44,111:INFO:Defining folds
2022-10-21 13:26:44,111:INFO:Declaring metric variables
2022-10-21 13:26:44,126:INFO:Importing untrained model
2022-10-21 13:26:44,135:INFO:Elastic Net Imported successfully
2022-10-21 13:26:44,153:INFO:Starting cross validation
2022-10-21 13:26:44,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:45,127:INFO:Calculating mean and std
2022-10-21 13:26:45,130:INFO:Creating metrics dataframe
2022-10-21 13:26:45,135:INFO:Uploading results into container
2022-10-21 13:26:45,135:INFO:Uploading model into container now
2022-10-21 13:26:45,136:INFO:master_model_container: 4
2022-10-21 13:26:45,137:INFO:display_container: 2
2022-10-21 13:26:45,138:INFO:ElasticNet(random_state=122)
2022-10-21 13:26:45,138:INFO:create_model() successfully completed......................................
2022-10-21 13:26:45,314:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:45,314:INFO:Creating metrics dataframe
2022-10-21 13:26:45,349:INFO:Initializing Least Angle Regression
2022-10-21 13:26:45,349:INFO:Total runtime is 0.3427326520284017 minutes
2022-10-21 13:26:45,360:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:45,361:INFO:Initializing create_model()
2022-10-21 13:26:45,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:45,361:INFO:Checking exceptions
2022-10-21 13:26:45,366:INFO:Importing libraries
2022-10-21 13:26:45,367:INFO:Copying training dataset
2022-10-21 13:26:45,599:INFO:Defining folds
2022-10-21 13:26:45,602:INFO:Declaring metric variables
2022-10-21 13:26:45,616:INFO:Importing untrained model
2022-10-21 13:26:45,630:INFO:Least Angle Regression Imported successfully
2022-10-21 13:26:45,651:INFO:Starting cross validation
2022-10-21 13:26:45,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:46,069:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,098:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.030e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,098:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.030e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,101:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.972e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,102:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.748e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,127:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.562e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,127:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.508e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,128:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.147e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,165:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,185:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.009e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,189:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.614e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,191:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.041e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,198:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,209:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.471e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,219:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.036e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,221:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.656e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.656e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.125e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,225:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.947e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,226:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.947e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,230:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.850e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,231:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.212e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,231:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.479e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,232:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.145e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,232:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.434e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,232:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.327e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,232:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.931e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,234:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.185e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,234:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.174e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,234:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.043e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,235:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.077e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,237:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.082e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,237:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.068e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,242:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.773e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,243:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.360e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,244:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.311e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,245:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.093e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,238:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.860e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,246:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.826e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,246:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.786e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,247:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.823e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,247:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.624e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,247:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.813e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,247:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.369e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,248:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.610e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,248:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.131e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,248:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.378e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,248:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.036e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,248:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.010e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,249:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.490e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,249:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.645e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,249:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.818e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,250:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.810e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,251:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.464e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,254:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.704e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,254:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.085e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,254:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.234e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,254:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.432e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,256:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.374e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,257:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.372e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,258:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.365e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,259:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.855e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,263:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.240e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,263:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.129e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,264:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.914e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,265:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.063e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,265:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.961e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,266:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.731e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,268:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.191e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,269:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.070e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,270:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.048e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,270:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.025e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.882e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.916e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,301:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.830e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,302:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.804e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,302:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.777e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,302:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.767e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,303:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.280e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,303:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.122e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,303:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.066e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,303:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.226e-05, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,312:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.016e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,312:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.685e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,316:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.466e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,316:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.238e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,317:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.047e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,318:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.803e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,318:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.358e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,318:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.797e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,326:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,347:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.293e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,349:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.410e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,357:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.588e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,360:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.240e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,364:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.027e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,365:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.613e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,366:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.457e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,379:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.230e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,379:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.201e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,380:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.097e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,381:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.900e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,382:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.487e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,382:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.190e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,383:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.083e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,384:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.947e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,385:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.916e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,385:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.242e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,402:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.885e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,402:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.199e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,403:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.452e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,477:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.315e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,478:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.193e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,478:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.107e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,479:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.009e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,479:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.216e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,480:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=7.358e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,480:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=5.358e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,481:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.531e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,481:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.110e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,481:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.848e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,482:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.691e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,482:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.652e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,483:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.078e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,489:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.859e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,490:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.687e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,490:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.232e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,490:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.232e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,764:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,774:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,776:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,780:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.266e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,782:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.858e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,782:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.143e+01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,785:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=7.049e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,786:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.225e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,787:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.988e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,791:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.607e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,791:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.607e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,792:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.106e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,793:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.106e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,795:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.211e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,798:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.655e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,798:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.345e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,799:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=6.280e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,799:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.193e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,800:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.008e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,800:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.855e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,800:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.862e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,801:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.806e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,801:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.526e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,802:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.156e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,802:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.473e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,802:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.326e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,802:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.145e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,802:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.979e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,803:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.114e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,803:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.846e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,804:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.432e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,807:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.170e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,808:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.130e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,808:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.100e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,809:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.807e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,809:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.825e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,816:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.330e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,819:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.183e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,820:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.388e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,824:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.163e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,841:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.855e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,844:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.940e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,845:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.571e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,845:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.398e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,846:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.908e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,847:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.908e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,847:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.091e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,848:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.665e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,849:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.175e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,849:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.478e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,849:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.199e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,850:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.169e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,851:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.714e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,851:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.624e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,852:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.577e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,852:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.850e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,853:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.139e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,882:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.566e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,882:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.811e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,882:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.557e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,883:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.643e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,883:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.600e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,883:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.618e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,883:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.379e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,883:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.436e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,883:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.507e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,884:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.192e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,884:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.282e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,884:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.490e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,884:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.199e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,884:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.572e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,885:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.486e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,885:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.475e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,886:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.444e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,890:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.426e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,891:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.043e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,897:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.472e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,898:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.047e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,898:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.187e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,899:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.933e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,899:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.931e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,899:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.014e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,914:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.152e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,914:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.613e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,915:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.138e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,920:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.482e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,920:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.696e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,923:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.981e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,923:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.736e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,930:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.148e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,986:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:46,994:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.570e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,996:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.730e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,998:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.191e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:46,999:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.055e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,004:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.438e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,004:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.428e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,006:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.427e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,006:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.405e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,006:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.145e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,010:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.599e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,010:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.575e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,011:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.996e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,012:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.038e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,012:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.957e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,013:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.007e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,013:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.974e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,013:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.490e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,013:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.958e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,014:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.886e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,014:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.022e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,014:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.015e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,015:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.754e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,016:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.214e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,016:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.077e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,016:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.533e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,017:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.494e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,017:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.387e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,018:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.365e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,019:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.274e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,019:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.489e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,020:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.993e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,020:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.922e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,192:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:47,197:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:47,199:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.852e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,203:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.666e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,204:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.666e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,206:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.249e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,208:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.507e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,209:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.717e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,209:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.136e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,210:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.918e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,211:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.357e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,211:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.027e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,212:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.078e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,212:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.078e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,212:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.720e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,212:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.436e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,213:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.436e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,213:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.371e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,214:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.931e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,214:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.508e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,215:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.675e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,215:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.432e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,215:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.653e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,215:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.348e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,215:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.115e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,216:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=8.897e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,216:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=8.610e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,216:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.416e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,216:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.639e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,217:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.620e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,217:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.999e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,217:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.544e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,218:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.184e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,218:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.210e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,219:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.716e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.714e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,219:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.080e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,219:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.320e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,219:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.035e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,220:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.522e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,220:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.965e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,220:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.059e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,222:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.965e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,223:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.020e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,223:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.965e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.713e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.822e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.644e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.374e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,224:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.563e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,225:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.397e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,225:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.345e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,226:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=6.674e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,226:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.415e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,226:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.664e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,227:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.223e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,230:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.293e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,230:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.130e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,230:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.271e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,231:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.176e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,231:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.063e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,232:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.060e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,232:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.133e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,233:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.256e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,233:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.987e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,234:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.502e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,345:INFO:Calculating mean and std
2022-10-21 13:26:47,349:INFO:Creating metrics dataframe
2022-10-21 13:26:47,356:INFO:Uploading results into container
2022-10-21 13:26:47,358:INFO:Uploading model into container now
2022-10-21 13:26:47,359:INFO:master_model_container: 5
2022-10-21 13:26:47,359:INFO:display_container: 2
2022-10-21 13:26:47,360:INFO:Lars(random_state=122)
2022-10-21 13:26:47,361:INFO:create_model() successfully completed......................................
2022-10-21 13:26:47,552:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:47,552:INFO:Creating metrics dataframe
2022-10-21 13:26:47,574:INFO:Initializing Lasso Least Angle Regression
2022-10-21 13:26:47,575:INFO:Total runtime is 0.37981905142466227 minutes
2022-10-21 13:26:47,580:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:47,581:INFO:Initializing create_model()
2022-10-21 13:26:47,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:47,581:INFO:Checking exceptions
2022-10-21 13:26:47,585:INFO:Importing libraries
2022-10-21 13:26:47,585:INFO:Copying training dataset
2022-10-21 13:26:47,620:INFO:Defining folds
2022-10-21 13:26:47,621:INFO:Declaring metric variables
2022-10-21 13:26:47,646:INFO:Importing untrained model
2022-10-21 13:26:47,681:INFO:Lasso Least Angle Regression Imported successfully
2022-10-21 13:26:47,738:INFO:Starting cross validation
2022-10-21 13:26:47,746:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:47,951:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:47,967:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.688e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,969:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.731e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,969:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.731e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,973:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.941e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,974:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.262e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,975:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.216e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,976:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:47,985:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:47,985:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.293e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,986:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.410e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,990:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:47,991:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.830e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,996:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.471e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:47,999:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.355e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,000:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.043e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,001:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.574e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,002:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.125e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,004:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.206e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,006:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.206e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,007:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.214e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,340:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:48,347:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.980e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,348:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.769e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,348:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.073e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,350:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.836e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,353:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.044e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,358:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=1.647e+00, previous alpha=1.480e+00, with an active set of 24 regressors.
  warnings.warn(

2022-10-21 13:26:48,364:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:48,378:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.225e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,379:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:48,380:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.193e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,380:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:48,381:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.862e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,382:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.163e+00, previous alpha=4.862e+00, with an active set of 15 regressors.
  warnings.warn(

2022-10-21 13:26:48,387:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.570e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,393:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.992e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,393:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.992e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,394:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.933e+00, previous alpha=2.630e+00, with an active set of 18 regressors.
  warnings.warn(

2022-10-21 13:26:48,395:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.348e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,396:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.348e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,397:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=1.323e+00, previous alpha=1.117e+00, with an active set of 27 regressors.
  warnings.warn(

2022-10-21 13:26:48,599:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:48,607:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.843e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,608:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.018e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,616:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.717e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,616:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-10-21 13:26:48,617:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.331e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,618:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=1.479e+00, previous alpha=1.249e+00, with an active set of 27 regressors.
  warnings.warn(

2022-10-21 13:26:48,625:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.759e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,627:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.371e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,630:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.529e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-10-21 13:26:48,631:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:682: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=1.413e+00, previous alpha=1.396e+00, with an active set of 24 regressors.
  warnings.warn(

2022-10-21 13:26:48,716:INFO:Calculating mean and std
2022-10-21 13:26:48,721:INFO:Creating metrics dataframe
2022-10-21 13:26:48,729:INFO:Uploading results into container
2022-10-21 13:26:48,732:INFO:Uploading model into container now
2022-10-21 13:26:48,733:INFO:master_model_container: 6
2022-10-21 13:26:48,733:INFO:display_container: 2
2022-10-21 13:26:48,734:INFO:LassoLars(random_state=122)
2022-10-21 13:26:48,734:INFO:create_model() successfully completed......................................
2022-10-21 13:26:48,952:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:48,953:INFO:Creating metrics dataframe
2022-10-21 13:26:48,992:INFO:Initializing Orthogonal Matching Pursuit
2022-10-21 13:26:48,992:INFO:Total runtime is 0.40344908634821575 minutes
2022-10-21 13:26:49,000:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:49,001:INFO:Initializing create_model()
2022-10-21 13:26:49,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:49,002:INFO:Checking exceptions
2022-10-21 13:26:49,040:INFO:Importing libraries
2022-10-21 13:26:49,040:INFO:Copying training dataset
2022-10-21 13:26:49,065:INFO:Defining folds
2022-10-21 13:26:49,066:INFO:Declaring metric variables
2022-10-21 13:26:49,098:INFO:Importing untrained model
2022-10-21 13:26:49,131:INFO:Orthogonal Matching Pursuit Imported successfully
2022-10-21 13:26:49,181:INFO:Starting cross validation
2022-10-21 13:26:49,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:49,365:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,386:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,404:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,407:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,635:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,650:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,665:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,674:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,808:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,819:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-10-21 13:26:49,866:INFO:Calculating mean and std
2022-10-21 13:26:49,870:INFO:Creating metrics dataframe
2022-10-21 13:26:49,876:INFO:Uploading results into container
2022-10-21 13:26:49,877:INFO:Uploading model into container now
2022-10-21 13:26:49,877:INFO:master_model_container: 7
2022-10-21 13:26:49,877:INFO:display_container: 2
2022-10-21 13:26:49,877:INFO:OrthogonalMatchingPursuit()
2022-10-21 13:26:49,878:INFO:create_model() successfully completed......................................
2022-10-21 13:26:50,009:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:50,010:INFO:Creating metrics dataframe
2022-10-21 13:26:50,030:INFO:Initializing Bayesian Ridge
2022-10-21 13:26:50,030:INFO:Total runtime is 0.42074170112609866 minutes
2022-10-21 13:26:50,037:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:50,038:INFO:Initializing create_model()
2022-10-21 13:26:50,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:50,038:INFO:Checking exceptions
2022-10-21 13:26:50,043:INFO:Importing libraries
2022-10-21 13:26:50,043:INFO:Copying training dataset
2022-10-21 13:26:50,052:INFO:Defining folds
2022-10-21 13:26:50,052:INFO:Declaring metric variables
2022-10-21 13:26:50,082:INFO:Importing untrained model
2022-10-21 13:26:50,108:INFO:Bayesian Ridge Imported successfully
2022-10-21 13:26:50,146:INFO:Starting cross validation
2022-10-21 13:26:50,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:50,870:INFO:Calculating mean and std
2022-10-21 13:26:50,873:INFO:Creating metrics dataframe
2022-10-21 13:26:50,878:INFO:Uploading results into container
2022-10-21 13:26:50,879:INFO:Uploading model into container now
2022-10-21 13:26:50,879:INFO:master_model_container: 8
2022-10-21 13:26:50,880:INFO:display_container: 2
2022-10-21 13:26:50,880:INFO:BayesianRidge()
2022-10-21 13:26:50,880:INFO:create_model() successfully completed......................................
2022-10-21 13:26:51,023:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:51,024:INFO:Creating metrics dataframe
2022-10-21 13:26:51,040:INFO:Initializing Passive Aggressive Regressor
2022-10-21 13:26:51,041:INFO:Total runtime is 0.43758473396301273 minutes
2022-10-21 13:26:51,049:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:51,049:INFO:Initializing create_model()
2022-10-21 13:26:51,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:51,049:INFO:Checking exceptions
2022-10-21 13:26:51,053:INFO:Importing libraries
2022-10-21 13:26:51,053:INFO:Copying training dataset
2022-10-21 13:26:51,074:INFO:Defining folds
2022-10-21 13:26:51,074:INFO:Declaring metric variables
2022-10-21 13:26:51,111:INFO:Importing untrained model
2022-10-21 13:26:51,132:INFO:Passive Aggressive Regressor Imported successfully
2022-10-21 13:26:51,199:INFO:Starting cross validation
2022-10-21 13:26:51,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:52,368:INFO:Calculating mean and std
2022-10-21 13:26:52,374:INFO:Creating metrics dataframe
2022-10-21 13:26:52,380:INFO:Uploading results into container
2022-10-21 13:26:52,381:INFO:Uploading model into container now
2022-10-21 13:26:52,381:INFO:master_model_container: 9
2022-10-21 13:26:52,382:INFO:display_container: 2
2022-10-21 13:26:52,382:INFO:PassiveAggressiveRegressor(random_state=122)
2022-10-21 13:26:52,383:INFO:create_model() successfully completed......................................
2022-10-21 13:26:52,527:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:52,527:INFO:Creating metrics dataframe
2022-10-21 13:26:52,544:INFO:Initializing Huber Regressor
2022-10-21 13:26:52,544:INFO:Total runtime is 0.46263968547185264 minutes
2022-10-21 13:26:52,550:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:52,551:INFO:Initializing create_model()
2022-10-21 13:26:52,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:52,551:INFO:Checking exceptions
2022-10-21 13:26:52,556:INFO:Importing libraries
2022-10-21 13:26:52,557:INFO:Copying training dataset
2022-10-21 13:26:52,564:INFO:Defining folds
2022-10-21 13:26:52,564:INFO:Declaring metric variables
2022-10-21 13:26:52,595:INFO:Importing untrained model
2022-10-21 13:26:52,643:INFO:Huber Regressor Imported successfully
2022-10-21 13:26:52,669:INFO:Starting cross validation
2022-10-21 13:26:52,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:53,094:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,097:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,110:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,122:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,580:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,603:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,653:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,752:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,976:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:53,985:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-10-21 13:26:54,031:INFO:Calculating mean and std
2022-10-21 13:26:54,033:INFO:Creating metrics dataframe
2022-10-21 13:26:54,039:INFO:Uploading results into container
2022-10-21 13:26:54,041:INFO:Uploading model into container now
2022-10-21 13:26:54,042:INFO:master_model_container: 10
2022-10-21 13:26:54,042:INFO:display_container: 2
2022-10-21 13:26:54,043:INFO:HuberRegressor()
2022-10-21 13:26:54,043:INFO:create_model() successfully completed......................................
2022-10-21 13:26:54,179:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:54,179:INFO:Creating metrics dataframe
2022-10-21 13:26:54,196:INFO:Initializing K Neighbors Regressor
2022-10-21 13:26:54,197:INFO:Total runtime is 0.4901867667833964 minutes
2022-10-21 13:26:54,203:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:54,204:INFO:Initializing create_model()
2022-10-21 13:26:54,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:54,204:INFO:Checking exceptions
2022-10-21 13:26:54,209:INFO:Importing libraries
2022-10-21 13:26:54,209:INFO:Copying training dataset
2022-10-21 13:26:54,218:INFO:Defining folds
2022-10-21 13:26:54,218:INFO:Declaring metric variables
2022-10-21 13:26:54,246:INFO:Importing untrained model
2022-10-21 13:26:54,278:INFO:K Neighbors Regressor Imported successfully
2022-10-21 13:26:54,296:INFO:Starting cross validation
2022-10-21 13:26:54,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:55,036:INFO:Calculating mean and std
2022-10-21 13:26:55,040:INFO:Creating metrics dataframe
2022-10-21 13:26:55,045:INFO:Uploading results into container
2022-10-21 13:26:55,046:INFO:Uploading model into container now
2022-10-21 13:26:55,047:INFO:master_model_container: 11
2022-10-21 13:26:55,047:INFO:display_container: 2
2022-10-21 13:26:55,047:INFO:KNeighborsRegressor(n_jobs=-1)
2022-10-21 13:26:55,048:INFO:create_model() successfully completed......................................
2022-10-21 13:26:55,204:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:55,204:INFO:Creating metrics dataframe
2022-10-21 13:26:55,278:INFO:Initializing Decision Tree Regressor
2022-10-21 13:26:55,279:INFO:Total runtime is 0.5082203030586243 minutes
2022-10-21 13:26:55,294:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:55,295:INFO:Initializing create_model()
2022-10-21 13:26:55,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:55,297:INFO:Checking exceptions
2022-10-21 13:26:55,301:INFO:Importing libraries
2022-10-21 13:26:55,303:INFO:Copying training dataset
2022-10-21 13:26:55,370:INFO:Defining folds
2022-10-21 13:26:55,370:INFO:Declaring metric variables
2022-10-21 13:26:55,381:INFO:Importing untrained model
2022-10-21 13:26:55,415:INFO:Decision Tree Regressor Imported successfully
2022-10-21 13:26:55,442:INFO:Starting cross validation
2022-10-21 13:26:55,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:26:56,473:INFO:Calculating mean and std
2022-10-21 13:26:56,475:INFO:Creating metrics dataframe
2022-10-21 13:26:56,479:INFO:Uploading results into container
2022-10-21 13:26:56,480:INFO:Uploading model into container now
2022-10-21 13:26:56,481:INFO:master_model_container: 12
2022-10-21 13:26:56,481:INFO:display_container: 2
2022-10-21 13:26:56,481:INFO:DecisionTreeRegressor(random_state=122)
2022-10-21 13:26:56,482:INFO:create_model() successfully completed......................................
2022-10-21 13:26:56,616:INFO:SubProcess create_model() end ==================================
2022-10-21 13:26:56,616:INFO:Creating metrics dataframe
2022-10-21 13:26:56,638:INFO:Initializing Random Forest Regressor
2022-10-21 13:26:56,638:INFO:Total runtime is 0.530874780813853 minutes
2022-10-21 13:26:56,646:INFO:SubProcess create_model() called ==================================
2022-10-21 13:26:56,647:INFO:Initializing create_model()
2022-10-21 13:26:56,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:26:56,647:INFO:Checking exceptions
2022-10-21 13:26:56,650:INFO:Importing libraries
2022-10-21 13:26:56,651:INFO:Copying training dataset
2022-10-21 13:26:56,660:INFO:Defining folds
2022-10-21 13:26:56,660:INFO:Declaring metric variables
2022-10-21 13:26:56,670:INFO:Importing untrained model
2022-10-21 13:26:56,679:INFO:Random Forest Regressor Imported successfully
2022-10-21 13:26:56,695:INFO:Starting cross validation
2022-10-21 13:26:56,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:01,792:INFO:Calculating mean and std
2022-10-21 13:27:01,794:INFO:Creating metrics dataframe
2022-10-21 13:27:01,798:INFO:Uploading results into container
2022-10-21 13:27:01,799:INFO:Uploading model into container now
2022-10-21 13:27:01,800:INFO:master_model_container: 13
2022-10-21 13:27:01,800:INFO:display_container: 2
2022-10-21 13:27:01,801:INFO:RandomForestRegressor(n_jobs=-1, random_state=122)
2022-10-21 13:27:01,801:INFO:create_model() successfully completed......................................
2022-10-21 13:27:01,946:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:01,946:INFO:Creating metrics dataframe
2022-10-21 13:27:01,963:INFO:Initializing Extra Trees Regressor
2022-10-21 13:27:01,964:INFO:Total runtime is 0.6196384191513062 minutes
2022-10-21 13:27:01,968:INFO:SubProcess create_model() called ==================================
2022-10-21 13:27:01,969:INFO:Initializing create_model()
2022-10-21 13:27:01,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:01,969:INFO:Checking exceptions
2022-10-21 13:27:01,973:INFO:Importing libraries
2022-10-21 13:27:01,974:INFO:Copying training dataset
2022-10-21 13:27:01,981:INFO:Defining folds
2022-10-21 13:27:01,982:INFO:Declaring metric variables
2022-10-21 13:27:02,018:INFO:Importing untrained model
2022-10-21 13:27:02,043:INFO:Extra Trees Regressor Imported successfully
2022-10-21 13:27:02,108:INFO:Starting cross validation
2022-10-21 13:27:02,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:05,907:INFO:Calculating mean and std
2022-10-21 13:27:05,909:INFO:Creating metrics dataframe
2022-10-21 13:27:05,914:INFO:Uploading results into container
2022-10-21 13:27:05,915:INFO:Uploading model into container now
2022-10-21 13:27:05,916:INFO:master_model_container: 14
2022-10-21 13:27:05,916:INFO:display_container: 2
2022-10-21 13:27:05,916:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=122)
2022-10-21 13:27:05,917:INFO:create_model() successfully completed......................................
2022-10-21 13:27:06,065:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:06,065:INFO:Creating metrics dataframe
2022-10-21 13:27:06,084:INFO:Initializing AdaBoost Regressor
2022-10-21 13:27:06,085:INFO:Total runtime is 0.6883297840754192 minutes
2022-10-21 13:27:06,096:INFO:SubProcess create_model() called ==================================
2022-10-21 13:27:06,097:INFO:Initializing create_model()
2022-10-21 13:27:06,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:06,097:INFO:Checking exceptions
2022-10-21 13:27:06,100:INFO:Importing libraries
2022-10-21 13:27:06,101:INFO:Copying training dataset
2022-10-21 13:27:06,114:INFO:Defining folds
2022-10-21 13:27:06,114:INFO:Declaring metric variables
2022-10-21 13:27:06,154:INFO:Importing untrained model
2022-10-21 13:27:06,171:INFO:AdaBoost Regressor Imported successfully
2022-10-21 13:27:06,210:INFO:Starting cross validation
2022-10-21 13:27:06,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:07,387:INFO:Calculating mean and std
2022-10-21 13:27:07,391:INFO:Creating metrics dataframe
2022-10-21 13:27:07,396:INFO:Uploading results into container
2022-10-21 13:27:07,397:INFO:Uploading model into container now
2022-10-21 13:27:07,397:INFO:master_model_container: 15
2022-10-21 13:27:07,398:INFO:display_container: 2
2022-10-21 13:27:07,398:INFO:AdaBoostRegressor(random_state=122)
2022-10-21 13:27:07,399:INFO:create_model() successfully completed......................................
2022-10-21 13:27:07,541:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:07,541:INFO:Creating metrics dataframe
2022-10-21 13:27:07,565:INFO:Initializing Gradient Boosting Regressor
2022-10-21 13:27:07,565:INFO:Total runtime is 0.7129913806915285 minutes
2022-10-21 13:27:07,575:INFO:SubProcess create_model() called ==================================
2022-10-21 13:27:07,575:INFO:Initializing create_model()
2022-10-21 13:27:07,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:07,575:INFO:Checking exceptions
2022-10-21 13:27:07,578:INFO:Importing libraries
2022-10-21 13:27:07,578:INFO:Copying training dataset
2022-10-21 13:27:07,591:INFO:Defining folds
2022-10-21 13:27:07,593:INFO:Declaring metric variables
2022-10-21 13:27:07,606:INFO:Importing untrained model
2022-10-21 13:27:07,623:INFO:Gradient Boosting Regressor Imported successfully
2022-10-21 13:27:07,647:INFO:Starting cross validation
2022-10-21 13:27:07,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:09,905:INFO:Calculating mean and std
2022-10-21 13:27:09,908:INFO:Creating metrics dataframe
2022-10-21 13:27:09,913:INFO:Uploading results into container
2022-10-21 13:27:09,913:INFO:Uploading model into container now
2022-10-21 13:27:09,914:INFO:master_model_container: 16
2022-10-21 13:27:09,914:INFO:display_container: 2
2022-10-21 13:27:09,915:INFO:GradientBoostingRegressor(random_state=122)
2022-10-21 13:27:09,915:INFO:create_model() successfully completed......................................
2022-10-21 13:27:10,052:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:10,053:INFO:Creating metrics dataframe
2022-10-21 13:27:10,081:INFO:Initializing Light Gradient Boosting Machine
2022-10-21 13:27:10,081:INFO:Total runtime is 0.7549317836761475 minutes
2022-10-21 13:27:10,086:INFO:SubProcess create_model() called ==================================
2022-10-21 13:27:10,088:INFO:Initializing create_model()
2022-10-21 13:27:10,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:10,092:INFO:Checking exceptions
2022-10-21 13:27:10,095:INFO:Importing libraries
2022-10-21 13:27:10,096:INFO:Copying training dataset
2022-10-21 13:27:10,113:INFO:Defining folds
2022-10-21 13:27:10,113:INFO:Declaring metric variables
2022-10-21 13:27:10,148:INFO:Importing untrained model
2022-10-21 13:27:10,154:INFO:Light Gradient Boosting Machine Imported successfully
2022-10-21 13:27:10,195:INFO:Starting cross validation
2022-10-21 13:27:10,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:13,819:INFO:Calculating mean and std
2022-10-21 13:27:13,825:INFO:Creating metrics dataframe
2022-10-21 13:27:13,829:INFO:Uploading results into container
2022-10-21 13:27:13,830:INFO:Uploading model into container now
2022-10-21 13:27:13,831:INFO:master_model_container: 17
2022-10-21 13:27:13,831:INFO:display_container: 2
2022-10-21 13:27:13,832:INFO:LGBMRegressor(random_state=122)
2022-10-21 13:27:13,832:INFO:create_model() successfully completed......................................
2022-10-21 13:27:13,965:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:13,966:INFO:Creating metrics dataframe
2022-10-21 13:27:13,984:INFO:Initializing CatBoost Regressor
2022-10-21 13:27:13,985:INFO:Total runtime is 0.8199852863947551 minutes
2022-10-21 13:27:13,992:INFO:SubProcess create_model() called ==================================
2022-10-21 13:27:13,993:INFO:Initializing create_model()
2022-10-21 13:27:13,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:13,994:INFO:Checking exceptions
2022-10-21 13:27:13,996:INFO:Importing libraries
2022-10-21 13:27:13,996:INFO:Copying training dataset
2022-10-21 13:27:14,006:INFO:Defining folds
2022-10-21 13:27:14,012:INFO:Declaring metric variables
2022-10-21 13:27:14,031:INFO:Importing untrained model
2022-10-21 13:27:14,064:INFO:CatBoost Regressor Imported successfully
2022-10-21 13:27:14,101:INFO:Starting cross validation
2022-10-21 13:27:14,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:41,298:INFO:Calculating mean and std
2022-10-21 13:27:41,302:INFO:Creating metrics dataframe
2022-10-21 13:27:41,309:INFO:Uploading results into container
2022-10-21 13:27:41,311:INFO:Uploading model into container now
2022-10-21 13:27:41,312:INFO:master_model_container: 18
2022-10-21 13:27:41,312:INFO:display_container: 2
2022-10-21 13:27:41,312:INFO:<catboost.core.CatBoostRegressor object at 0x7f91c59e96a0>
2022-10-21 13:27:41,312:INFO:create_model() successfully completed......................................
2022-10-21 13:27:41,514:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:41,515:INFO:Creating metrics dataframe
2022-10-21 13:27:41,538:INFO:Initializing Dummy Regressor
2022-10-21 13:27:41,538:INFO:Total runtime is 1.2792093833287557 minutes
2022-10-21 13:27:41,554:INFO:SubProcess create_model() called ==================================
2022-10-21 13:27:41,554:INFO:Initializing create_model()
2022-10-21 13:27:41,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f91c6c45f70>, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:41,554:INFO:Checking exceptions
2022-10-21 13:27:41,562:INFO:Importing libraries
2022-10-21 13:27:41,562:INFO:Copying training dataset
2022-10-21 13:27:41,599:INFO:Defining folds
2022-10-21 13:27:41,600:INFO:Declaring metric variables
2022-10-21 13:27:41,627:INFO:Importing untrained model
2022-10-21 13:27:41,658:INFO:Dummy Regressor Imported successfully
2022-10-21 13:27:41,727:INFO:Starting cross validation
2022-10-21 13:27:41,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-10-21 13:27:42,825:INFO:Calculating mean and std
2022-10-21 13:27:42,829:INFO:Creating metrics dataframe
2022-10-21 13:27:42,834:INFO:Uploading results into container
2022-10-21 13:27:42,835:INFO:Uploading model into container now
2022-10-21 13:27:42,837:INFO:master_model_container: 19
2022-10-21 13:27:42,837:INFO:display_container: 2
2022-10-21 13:27:42,837:INFO:DummyRegressor()
2022-10-21 13:27:42,837:INFO:create_model() successfully completed......................................
2022-10-21 13:27:43,026:INFO:SubProcess create_model() end ==================================
2022-10-21 13:27:43,026:INFO:Creating metrics dataframe
2022-10-21 13:27:43,084:INFO:Initializing create_model()
2022-10-21 13:27:43,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=GradientBoostingRegressor(random_state=122), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-10-21 13:27:43,086:INFO:Checking exceptions
2022-10-21 13:27:43,097:INFO:Importing libraries
2022-10-21 13:27:43,097:INFO:Copying training dataset
2022-10-21 13:27:43,103:INFO:Defining folds
2022-10-21 13:27:43,103:INFO:Declaring metric variables
2022-10-21 13:27:43,104:INFO:Importing untrained model
2022-10-21 13:27:43,104:INFO:Declaring custom model
2022-10-21 13:27:43,105:INFO:Gradient Boosting Regressor Imported successfully
2022-10-21 13:27:43,109:INFO:Cross validation set to False
2022-10-21 13:27:43,109:INFO:Fitting Model
2022-10-21 13:27:43,689:INFO:GradientBoostingRegressor(random_state=122)
2022-10-21 13:27:43,689:INFO:create_model() successfully completed......................................
2022-10-21 13:27:44,001:INFO:master_model_container: 19
2022-10-21 13:27:44,001:INFO:display_container: 2
2022-10-21 13:27:44,002:INFO:GradientBoostingRegressor(random_state=122)
2022-10-21 13:27:44,002:INFO:compare_models() successfully completed......................................
2022-10-21 13:27:44,004:INFO:Initializing evaluate_model()
2022-10-21 13:27:44,004:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=GradientBoostingRegressor(random_state=122), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2022-10-21 13:27:44,087:INFO:Initializing plot_model()
2022-10-21 13:27:44,088:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, system=True)
2022-10-21 13:27:44,088:INFO:Checking exceptions
2022-10-21 13:27:44,099:INFO:Preloading libraries
2022-10-21 13:27:44,181:INFO:Copying training dataset
2022-10-21 13:27:44,181:INFO:Plot type: pipeline
2022-10-21 13:27:44,871:INFO:Visual Rendered Successfully
2022-10-21 13:27:45,022:INFO:plot_model() successfully completed......................................
2022-10-21 13:27:45,028:INFO:Initializing predict_model()
2022-10-21 13:27:45,028:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, estimator=GradientBoostingRegressor(random_state=122), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f91c6650790>)
2022-10-21 13:27:45,029:INFO:Checking exceptions
2022-10-21 13:27:45,029:INFO:Preloading libraries
2022-10-21 13:27:45,495:INFO:Initializing save_model()
2022-10-21 13:27:45,496:INFO:save_model(model=GradientBoostingRegressor(random_state=122), model_name=MLOps_Pipeline, prep_pipe_=Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-10-21 13:27:45,496:INFO:Adding model into prep_pipe
2022-10-21 13:27:45,583:INFO:MLOps_Pipeline.pkl saved in current working directory
2022-10-21 13:27:45,661:INFO:Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', GradientBoostingRegressor(random_state=122))])
2022-10-21 13:27:45,662:INFO:save_model() successfully completed......................................
2022-10-21 13:29:47,186:INFO:Initializing plot_model()
2022-10-21 13:29:47,189:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=122), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f91dc7db340>, system=True)
2022-10-21 13:29:47,189:INFO:Checking exceptions
2022-10-21 13:29:47,226:INFO:Preloading libraries
2022-10-21 13:29:47,245:INFO:Copying training dataset
2022-10-21 13:29:47,245:INFO:Plot type: residuals
2022-10-21 13:29:47,674:INFO:Fitting Model
2022-10-21 13:29:47,727:INFO:Scoring test/hold-out set
2022-10-21 13:29:48,920:INFO:Visual Rendered Successfully
2022-10-21 13:29:49,292:INFO:plot_model() successfully completed......................................
2022-10-21 13:29:51,507:INFO:Initializing load_model()
2022-10-21 13:29:51,507:INFO:load_model(model_name=MLOps_Pipeline, platform=None, authentication=None, verbose=True)
2022-10-21 13:35:02,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:02,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:02,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:02,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:05,580:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:35:16,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:16,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:16,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:16,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:35:19,194:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:37:25,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:37:25,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:37:25,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:37:25,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:37:27,879:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:43:31,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:43:31,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:43:31,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:43:31,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:43:35,078:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:45:28,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:45:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:45:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:45:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:45:31,500:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:45:32,726:INFO:Initializing load_model()
2022-10-21 13:45:32,726:INFO:load_model(model_name=deployment_28042020, platform=None, authentication=None, verbose=True)
2022-10-21 13:46:38,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:46:38,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:46:38,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:46:38,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-10-21 13:46:41,259:INFO:Soft dependency imported: prophet: 1.1.1
2022-10-21 13:46:42,536:INFO:Initializing load_model()
2022-10-21 13:46:42,536:INFO:load_model(model_name=MLOps_Pipeline, platform=None, authentication=None, verbose=True)
2022-10-21 13:51:27,287:INFO:Initializing predict_model()
2022-10-21 13:51:27,293:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fba017e7c70>, estimator=Pipeline(memory=Memory(location=/var/folders/sg/8dmzq1nn0wl6qmndt2sf_m1r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('or...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', GradientBoostingRegressor(random_state=122))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=0, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fba017ab1f0>)
2022-10-21 13:51:27,293:INFO:Checking exceptions
2022-10-21 13:51:27,293:INFO:Preloading libraries
2022-10-21 13:51:27,297:INFO:Set up data.
2022-10-21 13:51:27,377:INFO:Set up index.
2022-10-21 13:51:27,650:WARNING:/Users/sage/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)

